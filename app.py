# å®Œæ•´ç‰ˆç¿»è¯‘åŠŸèƒ½é›†æˆåç«¯
# åŸºäºapp_with_translation.pyï¼Œæ·»åŠ å®Œæ•´çš„ç¿»è¯‘åŠŸèƒ½

from flask import Flask, request, jsonify, send_file, render_template, send_from_directory
from flask_cors import CORS
from flask_sqlalchemy import SQLAlchemy
from flask_jwt_extended import JWTManager, jwt_required, create_access_token, get_jwt_identity, get_jwt
from flask_socketio import SocketIO
from sqlalchemy import text
import os
import time
import base64
import re
import json
import math
import asyncio
import subprocess
import argparse
import sys
import uuid
from datetime import datetime, timedelta
from pathlib import Path
import requests
from urllib.parse import urljoin, urlparse, quote
from bs4 import BeautifulSoup
from werkzeug.security import generate_password_hash, check_password_hash
from werkzeug.utils import secure_filename
import sqlite3
import zipfile
import io
import tempfile
import shutil
from functools import wraps
from threading import Lock
from enum import Enum

# ========== çŠ¶æ€æœºå¯¼å…¥ ==========
# å®Œæ•´çš„çŠ¶æ€æœºå®šä¹‰åœ¨ state_machine.py ä¸­
from state_machine import (
    ProcessingStep,
    StateMachine,
    StateTransitionError,
    STATUS_DISPLAY,
    STATUS_COLORS,
    PROCESSING_STATES,
    PENDING_ACTION_STATES,
    COMPLETED_STATES,
    SKIPPABLE_STATES,
    WORKFLOW_PATHS,
    get_status_display,
    get_legacy_status,
    is_processing,
    is_pending_action,
    is_completed,
    is_failed,
)


# ========== åºŸå¼ƒçš„æšä¸¾ï¼ˆä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰==========

class MaterialStatus(str, Enum):
    """
    [å·²åºŸå¼ƒ] ææ–™çŠ¶æ€æšä¸¾

    è¯·ä½¿ç”¨ ProcessingStep æšä¸¾ä»£æ›¿ã€‚
    æ­¤æšä¸¾ä»…ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œå°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚
    """
    PENDING = 'å¾…å¤„ç†'
    UPLOADED = 'å·²ä¸Šä¼ '
    SPLITTING = 'æ‹†åˆ†ä¸­'
    TRANSLATING = 'ç¿»è¯‘ä¸­'
    TRANSLATED = 'ç¿»è¯‘å®Œæˆ'
    FAILED = 'ç¿»è¯‘å¤±è´¥'
    CONFIRMED = 'å·²ç¡®è®¤'

# ç™¾åº¦ç¿»è¯‘APIé…ç½®ä¼šåœ¨translate_filenameå‡½æ•°ä¸­åŠ¨æ€åŠ è½½

# å°è¯•å¯¼å…¥ç¿»è¯‘ç›¸å…³çš„åº“
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

try:
    from pyppeteer import launch
    from PIL import Image
    PYPPETEER_AVAILABLE = True
except ImportError:
    PYPPETEER_AVAILABLE = False
    print("WARNING: pyppeteer or PIL not installed, some PDF generation features may not be available")

try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False
    print("WARNING: PyMuPDF not installed, PDF split features may not be available")

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app, origins=[
    "https://zac-chen-2024.github.io"  # GitHub Pages (å¼€å‘ç«¯å’Œç”Ÿäº§ç«¯å…±ç”¨åŒä¸€ä¸ªåŸŸå)
], supports_credentials=True)

# âœ… åˆå§‹åŒ– SocketIOï¼ˆä½¿ç”¨é•¿è½®è¯¢ï¼Œä¸éœ€è¦WebSocketï¼‰
socketio = SocketIO(app,
                   cors_allowed_origins=["https://zac-chen-2024.github.io"],
                   async_mode='threading',  # ä½¿ç”¨ threadingï¼ˆæœ€ç®€å•æœ€å¯é ï¼‰
                   logger=True,
                   engineio_logger=False,
                   ping_timeout=60,
                   ping_interval=25)

# å¯¼å…¥å¹¶åˆå§‹åŒ– WebSocket äº‹ä»¶å¤„ç†
try:
    from websocket_events import (init_socketio_events, emit_translation_started, 
                                 emit_material_updated, emit_material_error, 
                                 emit_translation_completed, emit_llm_started, 
                                 emit_llm_completed, emit_llm_error)
    init_socketio_events(socketio)
    print('[WebSocket] SocketIO åˆå§‹åŒ–æˆåŠŸ')
    WEBSOCKET_ENABLED = True
except Exception as e:
    print(f'[WebSocket] SocketIO åˆå§‹åŒ–å¤±è´¥: {e}')
    WEBSOCKET_ENABLED = False
    # å®šä¹‰ç©ºå‡½æ•°ï¼Œé¿å…æŠ¥é”™
    emit_translation_started = lambda *args, **kwargs: None
    emit_material_updated = lambda *args, **kwargs: None
    emit_material_error = lambda *args, **kwargs: None
    emit_translation_completed = lambda *args, **kwargs: None
    emit_llm_started = lambda *args, **kwargs: None
    emit_llm_completed = lambda *args, **kwargs: None
    emit_llm_error = lambda *args, **kwargs: None

# é…ç½®
app.config['SECRET_KEY'] = 'your-secret-key-change-this-in-production'
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///translation_platform.db'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
app.config['JWT_SECRET_KEY'] = 'jwt-secret-key-change-this-in-production'
app.config['JWT_ACCESS_TOKEN_EXPIRES'] = timedelta(hours=24)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024

# åˆå§‹åŒ–æ‰©å±•
db = SQLAlchemy(app)
jwt = JWTManager(app)

# æ·»åŠ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.before_request
def log_request_info():
    """è®°å½•æ¯ä¸ªè¯·æ±‚çš„ä¿¡æ¯"""
    # åˆ¤æ–­æ˜¯å¦æ˜¯è½®è¯¢è¯·æ±‚ï¼ˆGETææ–™åˆ—è¡¨ï¼‰
    is_polling = request.method == 'GET' and '/materials' in request.path and 'client' in request.path
    log_message(f"è¯·æ±‚: {request.method} {request.path} - IP: {request.remote_addr}", "INFO", is_polling=is_polling)

# åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹
os.makedirs('downloads', exist_ok=True)
os.makedirs('original_snapshot', exist_ok=True)
os.makedirs('translated_snapshot', exist_ok=True)
os.makedirs('poster_output', exist_ok=True)
os.makedirs('web_translation_output', exist_ok=True)
os.makedirs('uploads', exist_ok=True)
os.makedirs('image_translation_output', exist_ok=True)
os.makedirs('formula_output', exist_ok=True)


# JWT Tokené»‘åå•å­˜å‚¨
blacklisted_tokens = set()

@jwt.token_in_blocklist_loader
def check_if_token_revoked(jwt_header, jwt_payload):
    return jwt_payload['jti'] in blacklisted_tokens

# ========== Google ç½‘é¡µç¿»è¯‘å·¥å…·å‡½æ•° ==========

def _sanitize_title(title: str) -> str:
    """æ¸…ç†ç½‘é¡µæ ‡é¢˜ï¼Œä½¿å…¶é€‚åˆä½œä¸ºæ–‡ä»¶å"""
    title = (title or "webpage").strip().replace('\n', ' ')
    title = re.sub(r'[\\/*?:"<>|]', '_', title)
    return title[:80] or "webpage"

def _hide_google_translate_toolbar(driver):
    """ç§»é™¤ Google Translate é¡¶éƒ¨å·¥å…·æ """
    try:
        driver.execute_script("var nv = document.getElementById('gt-nvframe'); if(nv){ nv.remove(); }")
        driver.execute_script("""
            var css = document.createElement("style");
            css.type = "text/css";
            css.innerHTML = `
                .goog-te-gadget, .goog-te-gadget-simple, #goog-gt-tt { display: none !important; }
            `;
            document.head.appendChild(css);
        """)
        log_message("å·²ç§»é™¤ Google Translate é¡¶éƒ¨å·¥å…·æ ", "SUCCESS")
    except Exception as e:
        log_message(f"ç§»é™¤é¡¶éƒ¨å·¥å…·æ æ—¶å‡ºé”™ï¼š{e}", "WARNING")

def _setup_chrome(disable_js: bool = False):
    """è®¾ç½®Chromeæµè§ˆå™¨é€‰é¡¹"""
    if not SELENIUM_AVAILABLE:
        raise RuntimeError("Selenium ä¸å¯ç”¨ï¼Œè¯·å®‰è£…ä¾èµ–æˆ–é…ç½® ChromeDriver")
    
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--window-size=1280,800")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-setuid-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--allow-insecure-localhost")
    options.add_argument("--ignore-certificate-errors")
    options.add_argument("--disable-web-security")
    options.add_argument("--allow-running-insecure-content")
    options.add_argument("--lang=en-US,en;q=0.9")

    # é¢å¤–çš„éš”ç¦»é€‰é¡¹
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-background-networking")
    options.add_argument("--disable-sync")
    options.add_argument("--disable-default-apps")
    options.add_argument("--no-first-run")
    options.add_argument("--disable-background-timer-throttling")
    options.add_argument("--disable-backgrounding-occluded-windows")
    options.add_argument("--disable-renderer-backgrounding")

    # ä½¿ç”¨éšæœºremote debugging portæ¥é¿å…å†²çª
    import random
    options.add_argument(f"--remote-debugging-port={random.randint(9222, 9999)}")

    # ä½¿ç”¨å†…å­˜ä¸­çš„profileï¼Œé¿å…ç£ç›˜å†²çª
    options.add_argument("--disable-features=UseChromeOSDirectVideoDecoder")

    # æŒ‡å®šä¸€ä¸ªsnapå¯ä»¥è®¿é—®çš„ç›®å½•ï¼ˆåœ¨é¡¹ç›®ç›®å½•å†…ï¼‰
    import tempfile
    import uuid
    import os
    import time
    chrome_data_dir = os.path.join(os.path.dirname(__file__), 'tmp', 'chrome_data')
    os.makedirs(chrome_data_dir, exist_ok=True)
    user_data_dir = os.path.join(chrome_data_dir, f"profile_{os.getpid()}_{int(time.time()*1000)}_{uuid.uuid4().hex[:8]}")
    options.add_argument(f"--user-data-dir={user_data_dir}")

    # Snapä¸“ç”¨ï¼šå…è®¸è®¿é—®æ›´å¤šç›®å½•
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-software-rasterizer")

    if disable_js:
        prefs = {"profile.managed_default_content_settings.javascript": 2}
        options.add_experimental_option("prefs", prefs)

    # æ‰“å°Chromeå¯åŠ¨å‚æ•°ç”¨äºè°ƒè¯•
    log_message(f"[Chromeå¯åŠ¨] è¿›ç¨‹ID: {os.getpid()}, ä¸´æ—¶ç›®å½•: {user_data_dir}", "DEBUG")
    log_message(f"[Chromeå¯åŠ¨] æ‰€æœ‰å‚æ•°: {options.arguments}", "DEBUG")

    driver = webdriver.Chrome(options=options)

    # å°†ä¸´æ—¶ç›®å½•è·¯å¾„é™„åŠ åˆ° driver å¯¹è±¡ï¼Œä¾¿äºåç»­æ¸…ç†
    driver._user_data_dir = user_data_dir

    log_message(f"[Chromeå¯åŠ¨] æˆåŠŸåˆ›å»ºdriverå®ä¾‹", "DEBUG")
    return driver

def _cleanup_chrome_driver(driver):
    """å…³é—­Chrome driverå¹¶æ¸…ç†ä¸´æ—¶ç›®å½•"""
    try:
        driver.quit()
    except Exception as e:
        log_message(f"å…³é—­Chrome driverå¤±è´¥: {str(e)}", "WARN")

    # æ¸…ç†ä¸´æ—¶ç”¨æˆ·æ•°æ®ç›®å½•
    if hasattr(driver, '_user_data_dir'):
        import shutil
        try:
            shutil.rmtree(driver._user_data_dir, ignore_errors=True)
        except Exception as e:
            log_message(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {str(e)}", "WARN")

def _print_to_pdf(driver, pdf_path: str, scale: float = 0.9):
    """ä½¿ç”¨Chromeå°†é¡µé¢æ‰“å°ä¸ºPDF"""
    margins = {"top": 0.4, "bottom": 0.4, "left": 0.4, "right": 0.4}
    print_options = {
        "paperWidth": 8.27,
        "paperHeight": 11.7,
        "marginTop": margins.get("top", 0.4),
        "marginBottom": margins.get("bottom", 0.4),
        "marginLeft": margins.get("left", 0.4),
        "marginRight": margins.get("right", 0.4),
        "printBackground": True,
        "scale": scale,
        "preferCSSPageSize": False,
    }
    result = driver.execute_cdp_cmd("Page.printToPDF", print_options)
    pdf_data = base64.b64decode(result['data'])
    os.makedirs(os.path.dirname(pdf_path), exist_ok=True)
    with open(pdf_path, "wb") as f:
        f.write(pdf_data)
    log_message(f"å·²ä¿å­˜ PDF: {pdf_path}", "SUCCESS")

def _capture_google_translated_pdf_pyppeteer(url: str) -> (str, str):
    """ä½¿ç”¨ Pyppeteer æ¸²æŸ“ç¿»è¯‘é¡µä¸º PDF"""
    if not PYPPETEER_AVAILABLE:
        raise RuntimeError("Pyppeteer ä¸å¯ç”¨")
    
    import asyncio
    from pyppeteer import launch
    
    async def _run():
        browser = await launch({
            'headless': True,
            'args': [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-gpu',
                '--allow-insecure-localhost',
                '--ignore-certificate-errors',
                '--lang=en-US,en;q=0.9',
            ]
        })
        page = await browser.newPage()
        await page.setViewport({'width': 1280, 'height': 800, 'deviceScaleFactor': 1})
        from urllib.parse import quote
        translate_url = f"https://translate.google.com/translate?hl=en&sl=auto&tl=en&u={quote(url)}&prev=search"
        log_message(f"[pyppeteer] æ‰“å¼€: {translate_url}", "DEBUG")
        await page.goto(translate_url, {'waitUntil': 'networkidle2', 'timeout': 60000})
        
        # å°è¯•ç­‰å¾…ä¸»ä½“å†…å®¹ç¨³å®š
        try:
            await page.waitForSelector('body', {'timeout': 20000})
        except Exception:
            pass
        
        # ä½¿ç”¨ print åª’ä½“
        try:
            await page.emulateMediaType('print')
        except Exception:
            pass
        
        safe_title = _sanitize_title(await page.title())
        out_dir = os.path.join('translated_snapshot')
        os.makedirs(out_dir, exist_ok=True)
        pdf_filename = f"{safe_title}.pdf"
        pdf_path = os.path.join(out_dir, pdf_filename)
        await page.pdf({
            'path': pdf_path,
            'format': 'A4',
            'printBackground': True,
            'margin': {'top': '0.4in', 'bottom': '0.4in', 'left': '0.4in', 'right': '0.4in'},
            'scale': 0.9
        })
        await browser.close()
        return pdf_path, pdf_filename
    
    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(_run())
    finally:
        loop.close()

def _capture_google_translated_pdf(url: str) -> (str, str):
    """æ‰“å¼€Googleç¿»è¯‘é¡µé¢å¹¶ç”ŸæˆPDFï¼Œè¿”å› (pdf_path, pdf_filename)"""
    # ä¼˜å…ˆä½¿ç”¨ Pyppeteer
    if PYPPETEER_AVAILABLE:
        try:
            return _capture_google_translated_pdf_pyppeteer(url)
        except Exception as e:
            log_message(f"Pyppeteer è½¬ PDF å¤±è´¥ï¼Œå›é€€åˆ° Selenium: {str(e)}", "ERROR")
    
    from urllib.parse import quote
    driver = None
    try:
        driver = _setup_chrome(disable_js=False)
        translate_url = f"https://translate.google.com/translate?hl=en&sl=auto&tl=en&u={quote(url)}&prev=search"
        log_message(f"æ‰“å¼€Googleç¿»è¯‘åœ°å€: {translate_url}", "DEBUG")
        driver.get(translate_url)
        
        # åŸºæœ¬ç­‰å¾…
        try:
            WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))
        except Exception:
            time.sleep(2)
        
        # è®¾ç½®æ‰“å°åª’ä½“
        try:
            driver.execute_cdp_cmd('Emulation.setEmulatedMedia', {'media': 'print'})
        except Exception:
            pass
        
        safe_title = _sanitize_title(driver.title)
        out_dir = os.path.join('translated_snapshot')
        os.makedirs(out_dir, exist_ok=True)
        pdf_filename = f"{safe_title}.pdf"
        pdf_path = os.path.join(out_dir, pdf_filename)
        _print_to_pdf(driver, pdf_path, scale=0.9)
        return pdf_path, pdf_filename
    finally:
        if driver:
            _cleanup_chrome_driver(driver)

# ========== ç¼“å­˜å®ç° ==========
class SimpleCache:
    """ç®€å•çš„å†…å­˜ç¼“å­˜å®ç°"""
    def __init__(self):
        self.cache = {}
        self.lock = Lock()
        self.ttl = {}  # å­˜å‚¨æ¯ä¸ªé”®çš„è¿‡æœŸæ—¶é—´
    
    def get(self, key):
        """è·å–ç¼“å­˜å€¼"""
        with self.lock:
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if key in self.ttl and datetime.now() > self.ttl[key]:
                del self.cache[key]
                del self.ttl[key]
                return None
            return self.cache.get(key)
    
    def set(self, key, value, timeout_seconds=300):
        """è®¾ç½®ç¼“å­˜å€¼ï¼Œé»˜è®¤5åˆ†é’Ÿè¿‡æœŸ"""
        with self.lock:
            self.cache[key] = value
            self.ttl[key] = datetime.now() + timedelta(seconds=timeout_seconds)
    
    def delete(self, key):
        """åˆ é™¤ç¼“å­˜å€¼"""
        with self.lock:
            if key in self.cache:
                del self.cache[key]
            if key in self.ttl:
                del self.ttl[key]
    
    def clear_expired(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜"""
        with self.lock:
            current_time = datetime.now()
            expired_keys = [k for k, v in self.ttl.items() if current_time > v]
            for key in expired_keys:
                del self.cache[key]
                del self.ttl[key]

# åˆ›å»ºç¼“å­˜å®ä¾‹
api_cache = SimpleCache()

def cache_key_for_user(user_id, prefix):
    """ç”Ÿæˆç”¨æˆ·ç›¸å…³çš„ç¼“å­˜é”®"""
    return f"{prefix}:user:{user_id}"

def cache_key_for_client_materials(client_id):
    """ç”Ÿæˆå®¢æˆ·ææ–™åˆ—è¡¨çš„ç¼“å­˜é”®"""
    return f"materials:client:{client_id}"

def invalidate_client_cache(user_id):
    """ä½¿å®¢æˆ·ç›¸å…³çš„ç¼“å­˜å¤±æ•ˆ"""
    cache_key = cache_key_for_user(user_id, 'clients_list')
    api_cache.delete(cache_key)

def invalidate_materials_cache(client_id):
    """ä½¿ææ–™åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ"""
    cache_key = cache_key_for_client_materials(client_id)
    api_cache.delete(cache_key)

def cache_api_response(cache_key_prefix, timeout_seconds=300):
    """APIå“åº”ç¼“å­˜è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            # è·å–ç”¨æˆ·ID
            try:
                user_id = get_jwt_identity()
            except:
                # å¦‚æœæ²¡æœ‰JWTï¼Œç›´æ¥æ‰§è¡ŒåŸå‡½æ•°
                return f(*args, **kwargs)
            
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = cache_key_for_user(user_id, cache_key_prefix)
            
            # æ£€æŸ¥ç¼“å­˜
            cached_response = api_cache.get(cache_key)
            if cached_response is not None:
                response, status_code = cached_response
                return response, status_code
            
            # æ‰§è¡ŒåŸå‡½æ•°
            result = f(*args, **kwargs)
            
            # ç¼“å­˜æˆåŠŸçš„å“åº”
            if isinstance(result, tuple):
                response, status_code = result
                if status_code == 200:
                    api_cache.set(cache_key, result, timeout_seconds)
            else:
                # å¦‚æœåªè¿”å›å“åº”å¯¹è±¡ï¼Œå‡è®¾çŠ¶æ€ç ä¸º200
                api_cache.set(cache_key, (result, 200), timeout_seconds)
            
            return result
        
        return decorated_function
    return decorator

# å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜
def cleanup_cache():
    """å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜çš„åå°ä»»åŠ¡"""
    while True:
        time.sleep(600)  # æ¯10åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
        api_cache.clear_expired()

# ========== å·¥å…·å‡½æ•° ========== 

def get_baidu_access_token(api_key, secret_key):
    """è·å–ç™¾åº¦ç¿»è¯‘APIçš„access_token"""
    try:
        # ç™¾åº¦è·å–access_tokençš„API
        url = "https://aip.baidubce.com/oauth/2.0/token"
        params = {
            'grant_type': 'client_credentials',
            'client_id': api_key,
            'client_secret': secret_key
        }
        
        response = requests.post(url, params=params, timeout=10)
        result = response.json()
        
        if 'access_token' in result:
            log_message(f"ç™¾åº¦access_tokenè·å–æˆåŠŸ")
            return result['access_token']
        else:
            error_msg = result.get('error_description', result.get('error', 'æœªçŸ¥é”™è¯¯'))
            log_message(f"è·å–access_tokenå¤±è´¥: {error_msg}", "ERROR")
            return None
            
    except Exception as e:
        log_message(f"è·å–access_tokenå¼‚å¸¸: {e}", "ERROR")
        return None

def translate_filename_with_token(filename, access_token, target_lang='en'):
    """ä½¿ç”¨å·²æœ‰çš„access_tokenç¿»è¯‘æ–‡ä»¶å"""
    try:
        # ä½¿ç”¨access_tokenè°ƒç”¨ç¿»è¯‘API
        url = f"https://aip.baidubce.com/rpc/2.0/mt/texttrans/v1?access_token={access_token}"
        
        headers = {
            'Content-Type': 'application/json;charset=utf-8'
        }
        
        data = {
            'from': 'auto',  # è‡ªåŠ¨æ£€æµ‹æºè¯­è¨€
            'to': target_lang if target_lang == 'en' else 'zh',
            'q': filename
        }
        
        # å‘é€POSTè¯·æ±‚
        response = requests.post(url, headers=headers, json=data, timeout=10)
        result = response.json()
        
        # æ£€æŸ¥å“åº”
        if 'result' in result and 'trans_result' in result['result']:
            trans_results = result['result']['trans_result']
            if trans_results:
                translated_text = trans_results[0]['dst']
                # æ¸…ç†ç¿»è¯‘ç»“æœï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
                import re
                translated_text = re.sub(r'[^\w\s-]', '', translated_text)
                translated_text = translated_text.replace(' ', '_')
                log_message(f"æ–‡ä»¶åç¿»è¯‘æˆåŠŸ: '{filename}' -> '{translated_text}'")
                return translated_text
        
        # å¦‚æœæ²¡æœ‰ç¿»è¯‘ç»“æœï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
        error_msg = result.get('error_msg', result.get('error_code', 'æœªçŸ¥é”™è¯¯'))
        log_message(f"ç™¾åº¦ç¿»è¯‘APIé”™è¯¯: {error_msg}", "WARN")
        return filename
            
    except Exception as e:
        log_message(f"æ–‡ä»¶åç¿»è¯‘å¤±è´¥: {e}", "WARN")
        return filename

def translate_filename(filename, target_lang='en'):
    """ä½¿ç”¨ç™¾åº¦æœºå™¨ç¿»è¯‘APIç¿»è¯‘æ–‡ä»¶åï¼ˆè·å–æ–°tokenï¼‰"""
    # åŠ è½½ç™¾åº¦APIå¯†é’¥
    api_keys = load_api_keys()
    baidu_api_key = api_keys.get('BAIDU_API_KEY')
    baidu_secret_key = api_keys.get('BAIDU_SECRET_KEY')
    
    if not baidu_api_key or not baidu_secret_key:
        log_message("ç™¾åº¦ç¿»è¯‘APIå¯†é’¥æœªé…ç½®ï¼Œè¿”å›åŸæ–‡ä»¶å", "WARN")
        return filename
    
    # è·å–access_token
    access_token = get_baidu_access_token(baidu_api_key, baidu_secret_key)
    if not access_token:
        log_message("æ— æ³•è·å–access_tokenï¼Œè¿”å›åŸæ–‡ä»¶å", "WARN")
        return filename
    
    return translate_filename_with_token(filename, access_token, target_lang)

import logging
from logging.handlers import RotatingFileHandler
import os

# è‡ªå®šä¹‰æ§åˆ¶å°è¿‡æ»¤å™¨ï¼šåªæ˜¾ç¤ºé‡è¦ä¿¡æ¯ï¼Œè¿‡æ»¤æ‰è½®è¯¢æ—¥å¿—
class ConsoleFilter(logging.Filter):
    def filter(self, record):
        # è¿‡æ»¤æ‰è½®è¯¢ç›¸å…³çš„æ—¥å¿—
        if 'polling' in record.getMessage().lower():
            return False
        if 'materials' in record.getMessage() and 'GET' in record.getMessage():
            return False
        # åªæ˜¾ç¤ºWARNINGä»¥ä¸Šï¼Œæˆ–è€…åŒ…å«SUCCESSçš„INFOæ—¥å¿—
        if record.levelno >= logging.WARNING:
            return True
        if 'SUCCESS' in record.levelname or 'âœ“' in record.getMessage():
            return True
        return False

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿï¼šä¸»æ—¥å¿—å’Œè½®è¯¢æ—¥å¿—åˆ†ç¦»"""
    # åˆ›å»ºlogsç›®å½•
    if not os.path.exists('logs'):
        os.makedirs('logs')

    # ä¸»æ—¥å¿— - è®°å½•ä¸šåŠ¡æ“ä½œ
    main_logger = logging.getLogger('main')
    main_logger.setLevel(logging.INFO)

    # ä¸»æ—¥å¿—æ–‡ä»¶ï¼šè‡ªåŠ¨è½®è½¬ï¼Œæœ€å¤šä¿ç•™5ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ª10MB
    main_handler = RotatingFileHandler(
        'logs/server.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    main_handler.setLevel(logging.INFO)
    main_formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s')
    main_handler.setFormatter(main_formatter)
    main_logger.addHandler(main_handler)

    # æ§åˆ¶å°è¾“å‡º - ä½¿ç”¨è‡ªå®šä¹‰è¿‡æ»¤å™¨ï¼Œåªæ˜¾ç¤ºé‡è¦ä¿¡æ¯
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)  # æ¥æ”¶INFOçº§åˆ«
    console_handler.setFormatter(main_formatter)
    console_handler.addFilter(ConsoleFilter())  # æ·»åŠ è¿‡æ»¤å™¨ï¼Œåªæ˜¾ç¤ºé‡è¦ä¿¡æ¯
    main_logger.addHandler(console_handler)

    # ç¦ç”¨Flaskçš„werkzeugæ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆé¿å…åˆ·å±ï¼‰
    werkzeug_logger = logging.getLogger('werkzeug')
    werkzeug_logger.setLevel(logging.ERROR)  # åªæ˜¾ç¤ºERRORåŠä»¥ä¸Š

    # è½®è¯¢æ—¥å¿— - å•ç‹¬è®°å½•ï¼Œé¿å…æ·¹æ²¡ä¸»æ—¥å¿—
    polling_logger = logging.getLogger('polling')
    polling_logger.setLevel(logging.DEBUG)

    # è½®è¯¢æ—¥å¿—æ–‡ä»¶ï¼šè‡ªåŠ¨è½®è½¬ï¼Œæœ€å¤šä¿ç•™3ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ª5MB
    polling_handler = RotatingFileHandler(
        'logs/polling.log',
        maxBytes=5*1024*1024,  # 5MB
        backupCount=3,
        encoding='utf-8'
    )
    polling_handler.setLevel(logging.DEBUG)
    polling_formatter = logging.Formatter('[%(asctime)s] [POLLING] %(message)s')
    polling_handler.setFormatter(polling_formatter)
    polling_logger.addHandler(polling_handler)

    return main_logger, polling_logger

# åˆå§‹åŒ–æ—¥å¿—
main_logger, polling_logger = setup_logging()

# ========== çŠ¶æ€æ›´æ–°è¾…åŠ©å‡½æ•° ==========

def update_material_status(material, status, **kwargs):
    """
    ç»Ÿä¸€çš„ææ–™çŠ¶æ€æ›´æ–°å‡½æ•°ï¼ŒåŒ…å«ç‰ˆæœ¬æ§åˆ¶å’ŒWebSocketæ¨é€

    Args:
        material: Materialå¯¹è±¡æˆ–material_id
        status: MaterialStatusæšä¸¾å€¼
        **kwargs: å…¶ä»–éœ€è¦æ›´æ–°çš„å­—æ®µ
            - processing_step: ProcessingStepæšä¸¾å€¼
            - processing_progress: 0-100çš„è¿›åº¦
            - translation_text_info: ç¿»è¯‘æ•°æ®ï¼ˆä¼šè‡ªåŠ¨JSONåºåˆ—åŒ–ï¼‰
            - translation_error: é”™è¯¯ä¿¡æ¯
            - translated_image_path: ç¿»è¯‘åå›¾ç‰‡è·¯å¾„
            - emit_websocket: æ˜¯å¦æ¨é€WebSocketï¼ˆé»˜è®¤Trueï¼‰

    Returns:
        bool: æ›´æ–°æ˜¯å¦æˆåŠŸï¼ˆå¤±è´¥è¡¨ç¤ºç‰ˆæœ¬å†²çªï¼‰
    """
    from flask import current_app

    # å¦‚æœä¼ å…¥çš„æ˜¯IDï¼Œå…ˆæŸ¥è¯¢
    if isinstance(material, str):
        material = db.session.get(Material, material)
        if not material:
            log_message(f"Material {material} ä¸å­˜åœ¨", "ERROR")
            return False

    # è®°å½•æ—§ç‰ˆæœ¬å·
    old_version = material.version

    try:
        # æ›´æ–°çŠ¶æ€ï¼ˆä½¿ç”¨æšä¸¾å€¼ï¼‰
        if isinstance(status, MaterialStatus):
            material.status = status.value
        else:
            material.status = status

        # æ›´æ–°å…¶ä»–å­—æ®µ
        for key, value in kwargs.items():
            if key == 'translation_text_info' and isinstance(value, dict):
                # è‡ªåŠ¨åºåˆ—åŒ–JSON
                setattr(material, key, json.dumps(value, ensure_ascii=False))
            elif key != 'emit_websocket':  # emit_websocketä¸æ˜¯æ•°æ®åº“å­—æ®µ
                setattr(material, key, value)

        # å¢åŠ ç‰ˆæœ¬å·ï¼ˆä¹è§‚é”ï¼‰
        material.version = old_version + 1
        material.updated_at = datetime.utcnow()

        # æäº¤åˆ°æ•°æ®åº“
        db.session.commit()

        # ğŸ”§ æ¸…é™¤APIç¼“å­˜ï¼Œç¡®ä¿å‰ç«¯è·å–æœ€æ–°æ•°æ®
        cache_key = f"client_materials_{material.client_id}"
        api_cache.delete(cache_key)

        # WebSocketæ¨é€ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        emit_websocket = kwargs.get('emit_websocket', True)
        if emit_websocket and WEBSOCKET_ENABLED:
            # å‡†å¤‡WebSocketæ•°æ®
            ws_data = {
                'material_id': material.id,
                'status': material.status,
                'progress': material.processing_progress,
                'material': material.to_dict()  # ğŸ”§ æ·»åŠ å®Œæ•´çš„materialå¯¹è±¡
            }

            # æ·»åŠ å¯é€‰å­—æ®µ
            if 'translated_image_path' in kwargs:
                ws_data['translated_path'] = kwargs['translated_image_path']
            if 'translation_text_info' in kwargs:
                ws_data['translation_info'] = kwargs['translation_text_info'] if isinstance(kwargs['translation_text_info'], dict) else json.loads(kwargs['translation_text_info'])

            # ğŸ”§ æ·»åŠ  processing_stepï¼ˆå¦‚æœåœ¨kwargsä¸­ä¼ é€’ï¼‰
            if 'processing_step' in kwargs:
                ws_data['processing_step'] = kwargs['processing_step']

            # å‘é€WebSocketäº‹ä»¶
            if material.status == MaterialStatus.TRANSLATED.value:
                emit_material_updated(material.client_id, **ws_data)
            elif material.status == MaterialStatus.FAILED.value:
                emit_material_error(material.client_id, material.id, material.translation_error or 'ç¿»è¯‘å¤±è´¥')
            else:
                emit_material_updated(material.client_id, **ws_data)

        log_message(f"âœ“ Material {material.id} çŠ¶æ€æ›´æ–°: {material.status} (v{material.version})", "SUCCESS")
        return True

    except Exception as e:
        db.session.rollback()
        log_message(f"âœ— Material {material.id if hasattr(material, 'id') else 'unknown'} çŠ¶æ€æ›´æ–°å¤±è´¥: {str(e)}", "ERROR")
        return False

def check_translation_lock(material_id):
    """
    æ£€æŸ¥ææ–™æ˜¯å¦æ­£åœ¨ç¿»è¯‘ä¸­ï¼ˆé˜²æ­¢é‡å¤ç¿»è¯‘ï¼‰

    Args:
        material_id: Material ID

    Returns:
        tuple: (is_locked, material) - (æ˜¯å¦è¢«é”å®š, Materialå¯¹è±¡)
    """
    material = db.session.get(Material, material_id)
    if not material:
        return False, None

    # æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç¿»è¯‘
    is_locked = material.status == MaterialStatus.TRANSLATING.value

    return is_locked, material

def log_message(message, level="INFO", is_polling=False):
    """ç»Ÿä¸€çš„æ—¥å¿—è¾“å‡ºå‡½æ•°

    Args:
        message: æ—¥å¿—æ¶ˆæ¯
        level: æ—¥å¿—çº§åˆ« (INFO, DEBUG, WARNING, ERROR, SUCCESS)
        is_polling: æ˜¯å¦æ˜¯è½®è¯¢æ—¥å¿—ï¼ˆè½®è¯¢æ—¥å¿—ä¼šå•ç‹¬è®°å½•åˆ°polling.logï¼‰
    """
    # è½®è¯¢æ—¥å¿—å•ç‹¬å¤„ç†
    if is_polling:
        polling_logger.debug(message)
        return

    # ä¸»æ—¥å¿—æ ¹æ®çº§åˆ«è¾“å‡º
    if level == "DEBUG":
        main_logger.debug(message)
    elif level == "INFO":
        main_logger.info(message)
    elif level == "WARNING" or level == "WARN":
        main_logger.warning(message)
    elif level == "ERROR":
        main_logger.error(message)
    elif level == "SUCCESS":
        main_logger.info(f"âœ“ {message}")
    else:
        main_logger.info(message)

def load_api_keys():
    """åŠ è½½APIå¯†é’¥"""
    keys = {}
    
    # é¦–å…ˆä»è€åç«¯æ–¹å¼çš„å•ç‹¬æ–‡ä»¶è¯»å–APIå¯†é’¥
    api_key_files = {
        'BAIDU_API_KEY': 'config/baidu_api_key.txt',
        'BAIDU_SECRET_KEY': 'config/baidu_secret_key.txt',
        'OPENAI_API_KEY': 'config/openai_api_key.txt'
    }

    for key_name, file_path in api_key_files.items():
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    value = f.read().strip()
                    if value:
                        keys[key_name] = value
                        log_message(f"ä» {file_path} åŠ è½½äº† {key_name}", "INFO")
            except Exception as e:
                log_message(f"è¯»å– {file_path} å¤±è´¥: {e}", "WARNING")
    
    # ç„¶åä»config.envæ–‡ä»¶åŠ è½½å…¶ä»–é…ç½®
    config_path = "config.env"
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if '=' in line and not line.startswith('#') and line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        # å¦‚æœç™¾åº¦å¯†é’¥è¿˜æ²¡æœ‰ä»å•ç‹¬æ–‡ä»¶è¯»å–åˆ°ï¼Œåˆ™ä»config.envè¯»å–
                        if key not in keys:
                            keys[key] = value
            log_message(f"ä»é…ç½®æ–‡ä»¶ config.env åŠ è½½äº†é¢å¤–é…ç½®", "INFO")
        except Exception as e:
            log_message(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}", "WARNING")
    
    # ä»ç¯å¢ƒå˜é‡åŠ è½½ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
    keys.update({
        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY', keys.get('OPENAI_API_KEY', '')),
        'BAIDU_API_KEY': os.getenv('BAIDU_API_KEY', keys.get('BAIDU_API_KEY', '')),
        'BAIDU_SECRET_KEY': os.getenv('BAIDU_SECRET_KEY', keys.get('BAIDU_SECRET_KEY', ''))
    })
    
    # æ‰“å°é…ç½®çŠ¶æ€ï¼ˆä¸æ˜¾ç¤ºå®é™…å¯†é’¥ï¼‰
    log_message(f"OpenAI API: {'å·²é…ç½®' if keys.get('OPENAI_API_KEY') else 'æœªé…ç½®'}", "INFO")
    log_message(f"ç™¾åº¦API: {'å·²é…ç½®' if keys.get('BAIDU_API_KEY') else 'æœªé…ç½®'}", "INFO")
    
    return keys

# ========== Referenceé¡¹ç›®çš„ç™¾åº¦APIè°ƒç”¨æ–¹å¼ï¼ˆå®Œå…¨ç…§æ¬ï¼‰ ==========

def get_access_token_reference():
    """è·å–access token - Referenceé¡¹ç›®æ–¹å¼ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    print(f"[TOKEN] å¼€å§‹è·å– Access Token", flush=True)
    # åŠ è½½APIå¯†é’¥
    api_keys = load_api_keys()
    API_KEY = api_keys.get('BAIDU_API_KEY')
    SECRET_KEY = api_keys.get('BAIDU_SECRET_KEY')

    if not API_KEY or not SECRET_KEY:
        raise Exception("ç™¾åº¦APIå¯†é’¥æœªé…ç½®")

    print(f"[TOKEN] APIå¯†é’¥å·²åŠ è½½", flush=True)
    log_message(f"è·å–Access Token...", "INFO")
    log_message(f"API_KEY: {API_KEY[:10]}...", "DEBUG")
    log_message(f"SECRET_KEY: {SECRET_KEY[:10]}...", "DEBUG")

    url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={API_KEY}&client_secret={SECRET_KEY}"

    payload = ""
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
    }

    # é‡è¯•æœºåˆ¶ï¼šæœ€å¤š3æ¬¡
    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"[TOKEN] å°è¯• {attempt + 1}/{max_retries}", flush=True)
            if attempt > 0:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’ã€8ç§’
                log_message(f"Tokenè¯·æ±‚é‡è¯• {attempt + 1}/{max_retries}ï¼Œç­‰å¾… {wait_time} ç§’...", "INFO")
                print(f"[TOKEN] ç­‰å¾… {wait_time} ç§’åé‡è¯•", flush=True)
                time.sleep(wait_time)
            
            log_message("å‘é€Tokenè¯·æ±‚...", "DEBUG")
            print(f"[TOKEN] å‡†å¤‡å‘é€POSTè¯·æ±‚åˆ°ç™¾åº¦API", flush=True)
            
            # ä½¿ç”¨ Session ä»¥æ”¯æŒè¿æ¥æ± å’Œé‡ç”¨
            session = requests.Session()
            # é…ç½® urllib3 é‡è¯•ç­–ç•¥
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            
            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=["POST"]
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session.mount("https://", adapter)
            session.mount("http://", adapter)
            
            print(f"[TOKEN] å¼€å§‹POSTè¯·æ±‚ï¼ˆè¶…æ—¶180ç§’ï¼‰", flush=True)
            response = session.post(url, headers=headers, data=payload, timeout=180)
            print(f"[TOKEN] POSTè¯·æ±‚å®Œæˆï¼ŒçŠ¶æ€ç : {response.status_code}", flush=True)
            log_message(f"Tokenå“åº”çŠ¶æ€: {response.status_code}", "DEBUG")

            data = response.json()
            log_message(f"Tokenå“åº”: {json.dumps(data, ensure_ascii=False)[:100]}...", "DEBUG")

            if 'access_token' in data:
                log_message("æˆåŠŸè·å–Access Token", "SUCCESS")
                return data['access_token']
            else:
                log_message(f"è·å–Tokenå¤±è´¥: {data}", "ERROR")
                if attempt < max_retries - 1:
                    continue
                raise Exception(f"è·å–tokenå¤±è´¥: {data}")
                
        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            log_message(f"Tokenè¯·æ±‚ç½‘ç»œé”™è¯¯ (attempt {attempt + 1}/{max_retries}): {str(e)}", "WARNING")
            if attempt == max_retries - 1:
                raise Exception(f"è·å–Tokenå¤±è´¥ï¼šç½‘ç»œè¶…æ—¶æˆ–è¿æ¥é”™è¯¯ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰")
        except Exception as e:
            log_message(f"è·å–Tokenå¼‚å¸¸ (attempt {attempt + 1}/{max_retries}): {str(e)}", "ERROR")
            if attempt == max_retries - 1:
                raise
    
    raise Exception(f"è·å–Tokenå¤±è´¥ï¼šå·²é‡è¯•{max_retries}æ¬¡")

def translate_image_reference(image_path, source_lang='zh', target_lang='en', max_retries=3):
    """è°ƒç”¨ç™¾åº¦å›¾ç‰‡ç¿»è¯‘API - Referenceé¡¹ç›®æ–¹å¼ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    log_message(f"è°ƒç”¨translate_image_referenceå‡½æ•°", "INFO")
    log_message(f"å›¾ç‰‡è·¯å¾„(åŸå§‹): {image_path}", "DEBUG")

    # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
    if not os.path.isabs(image_path):
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        abs_path = os.path.join(app.root_path, image_path)
        if os.path.exists(abs_path):
            image_path = abs_path
            log_message(f"è½¬æ¢ä¸ºç»å¯¹è·¯å¾„: {image_path}", "DEBUG")
        else:
            log_message(f"è­¦å‘Šï¼šæ–‡ä»¶ä¸å­˜åœ¨äºç»å¯¹è·¯å¾„: {abs_path}", "WARNING")
            # å°è¯•ç›´æ¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶: {image_path} (ä¹Ÿå°è¯•äº† {abs_path})")

    log_message(f"æœ€ç»ˆå›¾ç‰‡è·¯å¾„: {image_path}", "DEBUG")
    log_message(f"æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(image_path)}", "DEBUG")
    log_message(f"æºè¯­è¨€: {source_lang}, ç›®æ ‡è¯­è¨€: {target_lang}", "DEBUG")

    # ç¦ç”¨SSLè­¦å‘Š
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    for attempt in range(max_retries):
        try:
            if attempt > 0:
                log_message(f"é‡è¯•ç¬¬ {attempt + 1}/{max_retries} æ¬¡...", "INFO")
                import time
                time.sleep(2 * attempt)  # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’

            log_message("æ­£åœ¨è·å–access token...", "DEBUG")
            access_token = get_access_token_reference()
            log_message(f"Access Token: {access_token[:20]}...", "DEBUG")

            url = f"https://aip.baidubce.com/file/2.0/mt/pictrans/v1?access_token={access_token}"
            log_message(f"API URL: {url[:50]}...", "DEBUG")

            # æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œåˆ†è¾¨ç‡
            file_size = os.path.getsize(image_path)
            log_message(f"å›¾ç‰‡æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f}MB", "DEBUG")

            if file_size > 4 * 1024 * 1024:
                raise Exception(f"å›¾ç‰‡æ–‡ä»¶è¿‡å¤§: {file_size / 1024 / 1024:.2f}MBï¼Œè¶…è¿‡4MBé™åˆ¶")

            # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸
            try:
                from PIL import Image
                img = Image.open(image_path)
                log_message(f"å›¾ç‰‡å°ºå¯¸: {img.width}x{img.height}px", "DEBUG")
                if max(img.width, img.height) > 4096:
                    log_message(f"è­¦å‘Šï¼šå›¾ç‰‡å°ºå¯¸è¶…è¿‡4096pxï¼Œå¯èƒ½å¯¼è‡´ç¿»è¯‘å¤±è´¥", "WARNING")
            except:
                pass

            with open(image_path, 'rb') as f:
                files = {
                    'image': ('image.jpg', f, 'image/jpeg')
                }

                data = {
                    'from': source_lang,
                    'to': target_lang,
                    'paste': '1'
                }

                log_message(f"è¯·æ±‚å‚æ•°: {data}", "DEBUG")
                log_message("å‘é€POSTè¯·æ±‚åˆ°ç™¾åº¦API...", "DEBUG")
                print(f"[TRANSLATE] å‘é€ç¿»è¯‘APIè¯·æ±‚", flush=True)

                response = requests.post(
                    url,
                    files=files,
                    data=data,
                    verify=False,
                    timeout=180  # è¶…æ—¶æ—¶é—´ï¼š180ç§’ï¼ˆ3åˆ†é’Ÿï¼‰
                )
                print(f"[TRANSLATE] ç¿»è¯‘APIè¯·æ±‚å®Œæˆ", flush=True)
                log_message(f"å“åº”çŠ¶æ€ç : {response.status_code}", "DEBUG")

                result = response.json()
                log_message(f"å“åº”å†…å®¹é•¿åº¦: {len(str(result))} å­—ç¬¦", "DEBUG")

                # æ£€æŸ¥é”™è¯¯ç ï¼ˆ0è¡¨ç¤ºæˆåŠŸï¼‰
                error_code = result.get('error_code')
                if error_code and error_code not in [0, '0']:
                    error_msg = result.get('error_msg', 'æœªçŸ¥é”™è¯¯')
                    log_message(f"APIè¿”å›é”™è¯¯: {error_code} - {error_msg}", "ERROR")

                    # æŸäº›é”™è¯¯ä¸éœ€è¦é‡è¯•ï¼ˆå¦‚å›¾ç‰‡æ ¼å¼é”™è¯¯ï¼‰
                    no_retry_codes = [69006, 216015, 216201]  # å›¾ç‰‡é”™è¯¯ã€å‚æ•°é”™è¯¯ç­‰
                    if error_code in no_retry_codes:
                        return result  # ç›´æ¥è¿”å›ï¼Œä¸é‡è¯•

                    # å…¶ä»–é”™è¯¯ç»§ç»­é‡è¯•
                    if attempt < max_retries - 1:
                        continue
                elif error_code == 0 or error_code == '0':
                    log_message("ç™¾åº¦APIè°ƒç”¨æˆåŠŸ", "SUCCESS")

                return result

        except requests.exceptions.Timeout as e:
            log_message(f"APIè¯·æ±‚è¶…æ—¶ (attempt {attempt + 1}/{max_retries}): {str(e)}", "WARNING")
            if attempt == max_retries - 1:
                raise Exception(f"APIè¯·æ±‚è¶…æ—¶ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰")
        except requests.exceptions.SSLError as e:
            log_message(f"SSLè¿æ¥é”™è¯¯ (attempt {attempt + 1}/{max_retries}): {str(e)}", "WARNING")
            if attempt == max_retries - 1:
                raise Exception(f"SSLè¿æ¥å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        except Exception as e:
            log_message(f"translate_image_referenceå¼‚å¸¸ (attempt {attempt + 1}/{max_retries}): {str(e)}", "ERROR")
            if attempt == max_retries - 1:
                raise

    raise Exception(f"ç¿»è¯‘å¤±è´¥ï¼šå·²é‡è¯•{max_retries}æ¬¡")

# ========== å›¾ç‰‡ç”Ÿæˆå·¥å…·å‡½æ•° ==========

def generate_image_from_regions(original_image_path, regions_data):
    """
    ä»åŸå›¾å’Œregionsæ•°æ®ç”Ÿæˆæœ€ç»ˆçš„å¸¦æ–‡å­—å›¾ç‰‡

    Args:
        original_image_path: åŸå§‹å›¾ç‰‡è·¯å¾„
        regions_data: regions JSONæ•°æ®ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰

    Returns:
        PIL Imageå¯¹è±¡
    """
    from PIL import Image, ImageDraw, ImageFont

    try:
        # æ‰“å¼€åŸå›¾
        img = Image.open(original_image_path)
        if img.mode == 'RGBA':
            img = img.convert('RGB')

        # åˆ›å»ºç»˜å›¾å¯¹è±¡
        draw = ImageDraw.Draw(img)

        # è§£æregionsæ•°æ®
        if isinstance(regions_data, str):
            regions = json.loads(regions_data)
        else:
            regions = regions_data

        if not regions:
            log_message("æ²¡æœ‰regionsæ•°æ®ï¼Œè¿”å›åŸå›¾", "WARN")
            return img

        log_message(f"å¼€å§‹æ¸²æŸ“ {len(regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ", "INFO")

        # éå†æ¯ä¸ªregionï¼Œå…ˆç»˜åˆ¶é®ç½©ï¼Œå†ç»˜åˆ¶æ–‡å­—
        for idx, region in enumerate(regions):
            try:
                # è·å–ä½ç½®å’Œå¤§å°
                x = region.get('x', 0)
                y = region.get('y', 0)
                width = region.get('width', 100)
                height = region.get('height', 30)

                # ç»˜åˆ¶ç™½è‰²é®ç½©èƒŒæ™¯
                mask_bbox = [x, y, x + width, y + height]
                draw.rectangle(mask_bbox, fill=(255, 255, 255, 255))

                # è·å–æ–‡æœ¬å†…å®¹
                text = region.get('dst', region.get('src', ''))
                if not text:
                    continue

                # è·å–å­—ä½“å‚æ•°
                font_size = int(region.get('fontSize', 16))
                font_family = region.get('fontFamily', 'Arial')
                text_color = region.get('fill', '#000000')

                # è½¬æ¢é¢œè‰²æ ¼å¼
                if text_color.startswith('#'):
                    text_color = text_color.lstrip('#')
                    if len(text_color) == 6:
                        r = int(text_color[0:2], 16)
                        g = int(text_color[2:4], 16)
                        b = int(text_color[4:6], 16)
                        text_color_rgb = (r, g, b)
                    else:
                        text_color_rgb = (0, 0, 0)
                else:
                    text_color_rgb = (0, 0, 0)

                # åŠ è½½å­—ä½“
                try:
                    # å°è¯•åŠ è½½ç³»ç»Ÿå­—ä½“
                    if os.name == 'nt':  # Windows
                        font_paths = [
                            'C:/Windows/Fonts/msyh.ttc',  # å¾®è½¯é›…é»‘
                            'C:/Windows/Fonts/simhei.ttf',  # é»‘ä½“
                            'C:/Windows/Fonts/simsun.ttc',  # å®‹ä½“
                        ]
                    else:  # Linux/Mac
                        font_paths = [
                            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
                            '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',
                            '/System/Library/Fonts/PingFang.ttc',
                        ]

                    font = None
                    for font_path in font_paths:
                        if os.path.exists(font_path):
                            font = ImageFont.truetype(font_path, font_size)
                            break

                    if not font:
                        font = ImageFont.load_default()
                        log_message(f"æœªæ‰¾åˆ°ç³»ç»Ÿå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“", "WARN")

                except Exception as font_error:
                    log_message(f"åŠ è½½å­—ä½“å¤±è´¥: {font_error}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“", "WARN")
                    font = ImageFont.load_default()

                # ç»˜åˆ¶æ–‡æœ¬
                text_align = region.get('textAlign', 'center')

                # ç®€å•çš„æ–‡æœ¬æ¢è¡Œå¤„ç†
                lines = []
                words = text
                current_line = ""

                for char in words:
                    test_line = current_line + char
                    bbox = draw.textbbox((0, 0), test_line, font=font)
                    text_width = bbox[2] - bbox[0]

                    if text_width <= width - 10:  # ç•™10pxè¾¹è·
                        current_line = test_line
                    else:
                        if current_line:
                            lines.append(current_line)
                        current_line = char

                if current_line:
                    lines.append(current_line)

                # ç»˜åˆ¶æ¯ä¸€è¡Œ
                line_height = region.get('lineHeight', 1.2)
                actual_line_height = font_size * line_height

                for line_idx, line in enumerate(lines):
                    bbox = draw.textbbox((0, 0), line, font=font)
                    text_width = bbox[2] - bbox[0]

                    # æ ¹æ®å¯¹é½æ–¹å¼è®¡ç®—xåæ ‡
                    if text_align == 'center':
                        text_x = x + (width - text_width) / 2
                    elif text_align == 'right':
                        text_x = x + width - text_width - 5
                    else:  # left
                        text_x = x + 5

                    text_y = y + line_idx * actual_line_height + 5

                    draw.text((text_x, text_y), line, fill=text_color_rgb, font=font)

                log_message(f"âœ“ åŒºåŸŸ {idx} æ¸²æŸ“å®Œæˆ: {text[:20]}...", "DEBUG")

            except Exception as region_error:
                log_message(f"æ¸²æŸ“åŒºåŸŸ {idx} å¤±è´¥: {region_error}", "ERROR")
                continue

        log_message("å›¾ç‰‡ç”Ÿæˆå®Œæˆ", "SUCCESS")
        return img

    except Exception as e:
        log_message(f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        log_message(traceback.format_exc(), "ERROR")
        raise

# ========== æ•°æ®åº“æ¨¡å‹ ========== 

class User(db.Model):
    __tablename__ = 'users'
    __table_args__ = {'extend_existing': True}
    
    id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    name = db.Column(db.String(100), nullable=False)
    email = db.Column(db.String(120), unique=True, nullable=False)
    password_hash = db.Column(db.String(255), nullable=False)
    phone = db.Column(db.String(50))
    law_firm_id = db.Column(db.String(36))
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    clients = db.relationship('Client', backref='user', lazy=True, cascade='all, delete-orphan')
    
    def set_password(self, password):
        self.password_hash = generate_password_hash(password)
    
    def check_password(self, password):
        return check_password_hash(self.password_hash, password)
    
    def to_dict(self):
        return {
            'uid': self.id,
            'name': self.name,
            'email': self.email,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat()
        }

class Client(db.Model):
    __tablename__ = 'clients'
    __table_args__ = {'extend_existing': True}
    
    id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    name = db.Column(db.String(100), nullable=False)
    case_type = db.Column(db.String(100))
    case_date = db.Column(db.String(20))
    user_id = db.Column(db.String(36), db.ForeignKey('users.id'), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # è”ç³»ä¿¡æ¯å­—æ®µ
    phone = db.Column(db.String(50))
    email = db.Column(db.String(100))
    address = db.Column(db.Text)
    notes = db.Column(db.Text)
    
    # å½’æ¡£å­—æ®µ
    is_archived = db.Column(db.Boolean, default=False)
    archived_at = db.Column(db.DateTime)
    archived_reason = db.Column(db.String(500))
    
    materials = db.relationship('Material', backref='client', lazy=True, cascade='all, delete-orphan')
    
    def to_dict(self):
        return {
            'cid': self.id,
            'name': self.name,
            'caseType': self.case_type,
            'caseDate': self.case_date,
            'phone': self.phone,
            'email': self.email,
            'address': self.address,
            'notes': self.notes,
            'isArchived': bool(self.is_archived) if self.is_archived is not None else False,
            'archivedAt': self.archived_at.isoformat() if self.archived_at else None,
            'archivedReason': self.archived_reason,
            'createdAt': self.created_at.isoformat() if hasattr(self.created_at, 'isoformat') else str(self.created_at),
            'updatedAt': self.updated_at.isoformat() if hasattr(self.updated_at, 'isoformat') else str(self.updated_at)
        }

class Material(db.Model):
    __tablename__ = 'materials'
    __table_args__ = {'extend_existing': True}
    
    id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    name = db.Column(db.String(255), nullable=False)
    type = db.Column(db.String(50), nullable=False)
    status = db.Column(db.String(50), default='å¾…å¤„ç†')
    confirmed = db.Column(db.Boolean, default=False)
    selected_result = db.Column(db.String(20), default='api')  # é»˜è®¤ä½¿ç”¨ç™¾åº¦APIç¿»è¯‘ç»“æœ
    original_filename = db.Column(db.String(255))
    file_path = db.Column(db.String(500))
    url = db.Column(db.String(1000))
    # ç¿»è¯‘ç»“æœå­—æ®µ
    translated_image_path = db.Column(db.String(500))  # ç¿»è¯‘åçš„å›¾ç‰‡è·¯å¾„
    original_pdf_path = db.Column(db.String(500))  # åŸå§‹ç½‘é¡µPDFè·¯å¾„ï¼ˆç½‘é¡µææ–™ä¸“ç”¨ï¼‰
    translation_text_info = db.Column(db.Text)  # JSONæ ¼å¼çš„æ–‡æœ¬ä¿¡æ¯
    translation_error = db.Column(db.Text)  # APIç¿»è¯‘é”™è¯¯ä¿¡æ¯
    latex_translation_result = db.Column(db.Text)  # LaTeXç¿»è¯‘ç»“æœ
    latex_translation_error = db.Column(db.Text)  # LaTeXç¿»è¯‘é”™è¯¯ä¿¡æ¯
    llm_translation_result = db.Column(db.Text)  # LLMç¿»è¯‘ç»“æœï¼ˆJSONæ ¼å¼ï¼‰
    edited_image_path = db.Column(db.String(500))  # ç¼–è¾‘åçš„å›¾ç‰‡è·¯å¾„ï¼ˆä¸å¸¦æ–‡å­—ç‰ˆæœ¬ï¼Œç”¨äºé¢„è§ˆï¼‰
    final_image_path = db.Column(db.String(500))  # æœ€ç»ˆå›¾ç‰‡è·¯å¾„ï¼ˆå¸¦æ–‡å­—å®Œæ•´ç‰ˆæœ¬ï¼Œç”¨äºå¯¼å‡ºï¼‰
    has_edited_version = db.Column(db.Boolean, default=False)  # æ˜¯å¦æœ‰ç¼–è¾‘ç‰ˆæœ¬
    edited_regions = db.Column(db.Text)  # ç¼–è¾‘çš„regionsçŠ¶æ€ï¼ˆJSONæ ¼å¼ï¼‰
    # PDFå¤šé¡µç›¸å…³å­—æ®µ
    pdf_session_id = db.Column(db.String(100))  # PDFä¼šè¯IDï¼ˆå¤šé¡µPDFå…±äº«ï¼‰
    pdf_page_number = db.Column(db.Integer)  # PDFé¡µç 
    pdf_total_pages = db.Column(db.Integer)  # PDFæ€»é¡µæ•°
    pdf_original_file = db.Column(db.String(500))  # PDFåŸå§‹æ–‡ä»¶è·¯å¾„
    # å®ä½“è¯†åˆ«ç›¸å…³å­—æ®µ
    entity_recognition_enabled = db.Column(db.Boolean, default=False)  # æ˜¯å¦å¯ç”¨å®ä½“è¯†åˆ«
    entity_recognition_mode = db.Column(db.String(20))  # å®ä½“è¯†åˆ«æ¨¡å¼ï¼š'standard' æˆ– 'deep'
    entity_recognition_result = db.Column(db.Text)  # å®ä½“è¯†åˆ«ç»“æœï¼ˆJSONæ ¼å¼ï¼‰
    entity_recognition_confirmed = db.Column(db.Boolean, default=False)  # å®ä½“è¯†åˆ«æ˜¯å¦å·²ç¡®è®¤
    entity_recognition_triggered = db.Column(db.Boolean, default=False)  # æ˜¯å¦å·²è§¦å‘å®ä½“è¯†åˆ«ï¼ˆé˜²é‡å¤ï¼‰
    entity_user_edits = db.Column(db.Text)  # ç”¨æˆ·ç¼–è¾‘åçš„å®ä½“ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼Œç”¨äºæŒ‡å¯¼LLMç¿»è¯‘ï¼‰
    entity_recognition_error = db.Column(db.Text)  # å®ä½“è¯†åˆ«é”™è¯¯ä¿¡æ¯
    # å¤„ç†æ­¥éª¤è¿›åº¦: uploaded, translating, llm_optimizing, completed, failed
    processing_step = db.Column(db.String(50), default='uploaded')
    processing_progress = db.Column(db.Integer, default=0)  # 0-100çš„è¿›åº¦ç™¾åˆ†æ¯”
    # ä¹è§‚é”ç‰ˆæœ¬å·
    version = db.Column(db.Integer, default=0, nullable=False)
    client_id = db.Column(db.String(36), db.ForeignKey('clients.id'), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def to_dict(self):
        # è§£æç¿»è¯‘æ–‡æœ¬ä¿¡æ¯
        text_info = None
        if self.translation_text_info:
            try:
                text_info = json.loads(self.translation_text_info)
            except:
                text_info = None

        # è§£æLLMç¿»è¯‘ç»“æœ
        llm_translation = None
        if self.llm_translation_result:
            try:
                llm_translation = json.loads(self.llm_translation_result)
            except:
                llm_translation = None

        # è§£æå®ä½“è¯†åˆ«ç»“æœ
        entity_recognition = None
        if self.entity_recognition_result:
            try:
                entity_recognition = json.loads(self.entity_recognition_result)
            except:
                entity_recognition = None

        # è§£æç”¨æˆ·ç¼–è¾‘çš„å®ä½“ä¿¡æ¯
        entity_edits = None
        if self.entity_user_edits:
            try:
                entity_edits = json.loads(self.entity_user_edits)
            except:
                entity_edits = None

        return {
            'id': self.id,
            'name': self.name,
            'type': self.type,
            'status': self.status,
            'confirmed': self.confirmed,
            'selectedResult': self.selected_result,
            'originalFilename': self.original_filename,
            'filePath': self.file_path,  # åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæ˜¾ç¤ºåŸå›¾ï¼‰
            'url': self.url,
            'clientId': self.client_id,
            'createdAt': self.created_at.isoformat(),
            'updatedAt': self.updated_at.isoformat(),
            # ç¿»è¯‘ç»“æœ
            'translatedImagePath': self.translated_image_path,
            'originalPdfPath': self.original_pdf_path,  # åŸå§‹ç½‘é¡µPDFè·¯å¾„
            'translationTextInfo': text_info,
            'translationError': self.translation_error,
            'latexTranslationResult': self.latex_translation_result,
            'latexTranslationError': self.latex_translation_error,
            'llmTranslationResult': llm_translation,  # LLMç¿»è¯‘ç»“æœ
            'editedImagePath': self.edited_image_path,  # ç¼–è¾‘åçš„å›¾ç‰‡è·¯å¾„
            'finalImagePath': self.final_image_path,  # æœ€ç»ˆå›¾ç‰‡è·¯å¾„ï¼ˆå¸¦æ–‡å­—å®Œæ•´ç‰ˆï¼‰
            'hasEditedVersion': self.has_edited_version,  # æ˜¯å¦æœ‰ç¼–è¾‘ç‰ˆæœ¬
            'editedRegions': json.loads(self.edited_regions) if self.edited_regions else None,  # ç¼–è¾‘çš„regions
            # PDFå¤šé¡µç›¸å…³
            'pdfSessionId': self.pdf_session_id,
            'pdfPageNumber': self.pdf_page_number,
            'pdfTotalPages': self.pdf_total_pages,
            'pdfOriginalFile': self.pdf_original_file,
            # å®ä½“è¯†åˆ«ç›¸å…³
            'entityRecognitionEnabled': self.entity_recognition_enabled,
            'entityRecognitionMode': self.entity_recognition_mode,  # âœ… æ·»åŠ modeå­—æ®µ
            'entityRecognitionResult': entity_recognition,
            'entityRecognitionConfirmed': self.entity_recognition_confirmed,
            'entityRecognitionTriggered': self.entity_recognition_triggered,  # âœ… æ·»åŠ triggeredå­—æ®µ
            'entityUserEdits': entity_edits,
            'entityRecognitionError': self.entity_recognition_error,
            # å¤„ç†è¿›åº¦
            'processingStep': self.processing_step,
            'processingProgress': self.processing_progress
        }

class PosterTranslator:
    """æµ·æŠ¥ç¿»è¯‘ç±»ï¼Œå¤„ç†ä»å›¾åƒåˆ°PDFçš„å®Œæ•´æµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self, api_key=None, pdflatex_path=None):
        """
        åˆå§‹åŒ–æµ·æŠ¥ç¿»è¯‘å™¨
        
        Args:
            api_key (str): OpenAI APIå¯†é’¥
            pdflatex_path (str): pdflatex.exeçš„è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        # é…ç½®APIå¯†é’¥
        self.api_key = api_key or self._load_api_key()
        if self.api_key and OPENAI_AVAILABLE:
            self.client = OpenAI(api_key=self.api_key)
            self.log("OpenAI APIå¯†é’¥å·²é…ç½®", "SUCCESS")
        else:
            self.client = None
            if not OPENAI_AVAILABLE:
                self.log("[WARNING] OpenAIåº“æœªå®‰è£…", "WARNING")
            else:
                self.log("[WARNING] OpenAI APIå¯†é’¥æœªè®¾ç½®", "WARNING")
        
        # æ™ºèƒ½æ£€æµ‹pdflatexè·¯å¾„
        self.pdflatex_path = self._detect_pdflatex_path(pdflatex_path)
        
        # å®šä¹‰æµ·æŠ¥è½¬LaTeXçš„è¯¦ç»†æç¤ºè¯ï¼ˆå¢å¼ºç‰ˆï¼‰
        self.custom_prompt = r"""
IMPORTANT: Generate ONLY pure LaTeX code. Do not include any explanatory text, markdown formatting, or instructions. The output must start with \documentclass and end with \end{document}.

Upload a source image (e.g., a poster, flyer, single-page document, etc.) and generate "directly compilable LaTeX code" that faithfully reproduces the layout of the source. The requirements are as follows:

1. Mandatory LaTeX Preamble (Crucial for Compatibility)
The generated code MUST use the following preamble exactly as provided. Do not add, remove, or alter packages in this section. The entire document structure must be built upon this foundation.

Code snippet

\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=2cm]{geometry}
\usepackage{tabularx}
\usepackage{array}
\usepackage{graphicx}
2. Primary Goal: Faithful and Complete Reproduction

Layout Fidelity: Your highest priority is to meticulously replicate the geometric layout, alignment, and relative spacing of the original source image. The output must be a structural mirror of the original.

Content Completeness (No Omissions): It is mandatory to transcribe all textual information from the source image without any omissions. This includes titles, body text, tables, speaker information, footnotes, and any fine print. Pay special attention to names of people and organizations (especially Chinese names), which must be accurately transcribed first and then appropriately translated or transliterated. No content should be summarized or left out, regardless of its perceived importance.
3. Page Boundary and Margin Control (Critical)
It is absolutely essential that all content remains strictly within the page boundaries defined by the preamble's geometry package. No text, tables, or placeholders should overflow the page. Use width-aware environments like tabularx, \parbox, or minipage to control element widths.

4. Text and Typography

Translation: The source document is written in Chinese. All textual content must be translated from Chinese to English.

Text Normalization and Sanitization (Critical): Before outputting any text, ensure all characters are normalized for maximum pdflatex compatibility.

Punctuation: All punctuation marks MUST be converted from full-width forms to their standard half-width ASCII equivalents (e.g., ï¼ˆ to (, ï¼š to :, ï¼Œ to ,).

Currency Symbols: Non-ASCII currency symbols must be translated to their English text equivalents. For example, a price like ï¿¥100 should be translated to 100 Yuan or RMB 100. The symbol ï¿¥ itself should not appear in the final code.

Hierarchy: Use \large or \Large for titles.

Emphasis: Bold key information as needed.

5. Conditional Placeholder Generation

Strict Condition: Only generate placeholders for photos or QR codes if they are explicitly present in the source image.

Representation: Use \fbox or \framebox to draw placeholders. For example: \fbox{\parbox[c][1.5cm][c]{2.5cm}{\centering Photo}}.

6. Strict Technical Constraints

100% Self-Contained Code: The \includegraphics command is strictly forbidden.

Special Character Escaping: Properly escape all special LaTeX characters (& must be \&, etc.).

Style Restrictions: No color commands. No font sizes larger than \Large.

Package Restrictions: DO NOT use any of the following packages which are incompatible with pdflatex: fontspec, xeCJK, ctex, polyglossia, luatex85. DO NOT use system fonts or \setmainfont commands.

Engine Compatibility: The code MUST be compilable with pdflatex ONLY. Do not use features that require xelatex or lualatex.

7. Final Output Format

Raw Code Only: The output must be raw LaTeX code, starting with \documentclass and ending with \end{document}. Do not enclose it in any markdown formatting. Do not include any text before \documentclass or after \end{document}.

8. Error Prevention

Ensure all environments are properly closed (every \begin{X} has a matching \end{X}).

Avoid empty commands like \text{} or \textbf{}.

Ensure the document has proper structure: \documentclass, necessary packages, \begin{document}, content, \end{document}.

9. Final Verification Step (Mandatory)
Before providing the final output, perform one last check. Verify that the generated code begins exactly with the mandatory preamble provided in step 1, from \documentclass{article} down to \usepackage{graphicx}. There must be no extra characters, words, or commands inserted within or immediately after the \documentclass or \usepackage lines. If any deviation is found, you must correct it before outputting the final code.

"""

    def _detect_pdflatex_path(self, custom_path=None):
        """æ™ºèƒ½æ£€æµ‹pdflatexè·¯å¾„"""
        self.log("æ­£åœ¨æ£€æµ‹pdflatexè·¯å¾„...", "DEBUG")
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰è·¯å¾„ï¼Œå…ˆå°è¯•
        if custom_path and os.path.exists(custom_path):
            self.log(f"ä½¿ç”¨è‡ªå®šä¹‰pdflatexè·¯å¾„: {custom_path}", "SUCCESS")
            return custom_path
        
        # å¸¸è§çš„MiKTeXå®‰è£…è·¯å¾„ï¼ˆWindowsï¼‰
        common_paths = [
            r"F:\\tex\\miktex\\bin\\x64\\pdflatex.exe",  # åŸå§‹è·¯å¾„
            r"C:\\Program Files\\MiKTeX\\miktex\\bin\\x64\\pdflatex.exe",
            r"C:\\Users\\{}\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\pdflatex.exe".format(os.getenv('USERNAME', '')),
            r"C:\\Program Files (x86)\\MiKTeX\\miktex\\bin\\pdflatex.exe",
            r"D:\\MiKTeX\\miktex\\bin\\x64\\pdflatex.exe",
            r"E:\\MiKTeX\\miktex\\bin\\x64\\pdflatex.exe"
        ]
        
        # æ£€æŸ¥å¸¸è§è·¯å¾„
        for path in common_paths:
            if os.path.exists(path):
                self.log(f"æ‰¾åˆ°pdflatex: {path}", "SUCCESS")
                return path
        
        # æ£€æŸ¥ç³»ç»ŸPATH
        try:
            result = subprocess.run(["pdflatex", "--version"], 
                                 check=True, capture_output=True, text=True, timeout=10)
            self.log("åœ¨ç³»ç»ŸPATHä¸­æ‰¾åˆ°pdflatex", "SUCCESS")
            return "pdflatex"
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›é»˜è®¤è·¯å¾„å¹¶è®°å½•è­¦å‘Š
        default_path = r"F:\\tex\\miktex\\bin\\x64\\pdflatex.exe"
        self.log(f"æœªæ‰¾åˆ°pdflatexï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {default_path}", "WARNING")
        return default_path

    def log(self, message, level="INFO"):
        """è¯¦ç»†çŠ¶æ€æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        prefix = {
            "INFO": "[INFO]",
            "SUCCESS": "[SUCCESS]", 
            "WARNING": "[WARNING]",
            "ERROR": "[ERROR]",
            "DEBUG": "[DEBUG]"
        }
        print(f"[{timestamp}] {prefix.get(level, '[INFO]')} {message}")

    def _remove_chinese_content(self, latex_code):
        """
        ä»LaTeXä»£ç ä¸­å‰”é™¤æ‰€æœ‰ä¸­æ–‡å†…å®¹
        
        Args:
            latex_code (str): åŸå§‹LaTeXä»£ç 
            
        Returns:
            str: å‰”é™¤ä¸­æ–‡åçš„LaTeXä»£ç 
        """
        import re
        
        # å®šä¹‰ä¸­æ–‡å­—ç¬¦çš„æ­£åˆ™è¡¨è¾¾å¼
        chinese_pattern = r'[\u4e00-\u9fff]+'
        
        # è®°å½•å‰”é™¤çš„ä¸­æ–‡å†…å®¹
        chinese_matches = re.findall(chinese_pattern, latex_code)
        if chinese_matches:
            self.log(f"å‘ç°ä¸­æ–‡å†…å®¹: {chinese_matches}", "DEBUG")
        
        # å‰”é™¤ä¸­æ–‡å†…å®¹ï¼Œä½†ä¿ç•™LaTeXå‘½ä»¤ç»“æ„
        def replace_chinese(match):
            chinese_text = match.group(0)
            # å¦‚æœä¸­æ–‡åœ¨LaTeXå‘½ä»¤ä¸­ï¼ˆå¦‚\text{ä¸­æ–‡}ï¼‰ï¼Œæ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
            return ""
        
        # æ›¿æ¢æ‰€æœ‰ä¸­æ–‡å†…å®¹
        cleaned_code = re.sub(chinese_pattern, replace_chinese, latex_code)
        
        # æ¸…ç†å¯èƒ½äº§ç”Ÿçš„å¤šä½™ç©ºæ ¼å’Œç©ºè¡Œ
        # ç§»é™¤è¿ç»­çš„ç©ºè¡Œ
        cleaned_code = re.sub(r'\n\s*\n\s*\n', '\n\n', cleaned_code)
        
        # ç§»é™¤è¡Œé¦–è¡Œå°¾çš„å¤šä½™ç©ºæ ¼
        lines = cleaned_code.split('\n')
        cleaned_lines = [line.rstrip() for line in lines]
        cleaned_code = '\n'.join(cleaned_lines)
        
        # ç§»é™¤å¯èƒ½äº§ç”Ÿçš„ç©ºå‘½ä»¤ï¼ˆå¦‚\text{}ï¼‰
        cleaned_code = re.sub(r'\\\\text\{\s*\}', '', cleaned_code)
        cleaned_code = re.sub(r'\\\\textbf\{\s*\}', '', cleaned_code)
        cleaned_code = re.sub(r'\\\\textit\{\s*\}', '', cleaned_code)
        cleaned_code = re.sub(r'\\\\emph\{\s*\}', '', cleaned_code)
        
        # ç§»é™¤å¯èƒ½äº§ç”Ÿçš„ç©ºè¡¨æ ¼å•å…ƒæ ¼
        cleaned_code = re.sub(r'&\s*&', '& &', cleaned_code)  # ä¿®å¤ç©ºå•å…ƒæ ¼
        cleaned_code = re.sub(r'&\s*\\\\\\\\', '& \\\\\\\\', cleaned_code)  # ä¿®å¤è¡Œå°¾ç©ºå•å…ƒæ ¼
        
        # ç§»é™¤å¯èƒ½äº§ç”Ÿçš„ç©ºæ®µè½
        cleaned_code = re.sub(r'\\\\par\s*\\\\par', '\\\\par', cleaned_code)
        
        if chinese_matches:
            self.log(f"å·²å‰”é™¤ {len(chinese_matches)} å¤„ä¸­æ–‡å†…å®¹", "SUCCESS")
        
        return cleaned_code

    def _enhance_latex_code(self, latex_code):
        """
        åº”ç”¨å¢å¼ºçš„LaTeXä»£ç ä¿®å¤å’Œè¿‡æ»¤
        
        Args:
            latex_code (str): åŸå§‹LaTeXä»£ç 
            
        Returns:
            str: ä¿®å¤åçš„LaTeXä»£ç 
        """
        # 1. ä¿®å¤å¸¸è§çš„æ–‡æ¡£ç±»å£°æ˜é—®é¢˜
        latex_code = self._fix_documentclass_issues(latex_code)
        
        # 2. ç§»é™¤ä¸pdflatexä¸å…¼å®¹çš„åŒ…
        latex_code = self._remove_incompatible_packages(latex_code)
        
        # 3. ä¿®å¤å¸¸è§çš„LaTeXè¯­æ³•é”™è¯¯
        latex_code = self._fix_common_latex_errors(latex_code)
        
        # 4. éªŒè¯LaTeXæ–‡æ¡£ç»“æ„
        latex_code = self._validate_and_fix_structure(latex_code)
        
        return latex_code
    
    def _fix_documentclass_issues(self, latex_code):
        """ä¿®å¤æ–‡æ¡£ç±»å£°æ˜é—®é¢˜"""
        # ä¿®å¤é”™è¯¯çš„documentclasså£°æ˜
        latex_code = re.sub(r'\\documentclass`\s*with.*?$', r'\\documentclass[12pt]{article}', latex_code, flags=re.MULTILINE)
        latex_code = re.sub(r'\\documentclass\\{', r'\\documentclass{', latex_code)
        
        # å¦‚æœæ²¡æœ‰documentclassï¼Œæ·»åŠ é»˜è®¤çš„
        if not re.search(r'\\documentclass', latex_code):
            self.log("æœªæ‰¾åˆ°documentclassï¼Œæ·»åŠ é»˜è®¤æ–‡æ¡£ç±»", "WARNING")
            latex_code = r"\documentclass[12pt]{article}\n" + latex_code
        
        return latex_code
    
    def _remove_incompatible_packages(self, latex_code):
        """ç§»é™¤ä¸pdflatexä¸å…¼å®¹çš„åŒ…"""
        # ä¸pdflatexä¸å…¼å®¹çš„åŒ…åˆ—è¡¨
        incompatible_packages = ['fontspec', 'xeCJK', 'ctex', 'luatex85', 'polyglossia']
        
        for pkg in incompatible_packages:
            # ç§»é™¤usepackageå‘½ä»¤
            latex_code = re.sub(rf'\\usepackage(?:\[.*?\])?{{\s*{pkg}\s*}}.*?\n', '', latex_code)
            # ç§»é™¤ç›¸å…³è®¾ç½®å‘½ä»¤
            if pkg == 'fontspec':
                latex_code = re.sub(r'\\setmainfont\{.*?\}.*?\n', '', latex_code)
                latex_code = re.sub(r'\\setsansfont\{.*?\}.*?\n', '', latex_code)
                latex_code = re.sub(r'\\setmonofont\{.*?\}.*?\n', '', latex_code)
        
        # ç¡®ä¿æœ‰åŸºæœ¬çš„utf8ç¼–ç æ”¯æŒ
        if 'inputenc' not in latex_code:
            # åœ¨\documentclassåæ·»åŠ 
            latex_code = re.sub(r'(\\documentclass.*?\n)', r'\1\\usepackage[utf8]{inputenc}\n', latex_code)
        
        return latex_code
    
    def _fix_common_latex_errors(self, latex_code):
        """ä¿®å¤å¸¸è§çš„LaTeXè¯­æ³•é”™è¯¯"""
        # ä¿®å¤æœªé—­åˆçš„ç¯å¢ƒ
        environments = re.findall(r'\\begin\{(\w+)\}', latex_code)
        for env in environments:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„\end
            if not re.search(rf'\\end\{{{env}\}}', latex_code):
                self.log(f"å‘ç°æœªé—­åˆçš„ç¯å¢ƒ: {env}", "WARNING")
                # åœ¨æ–‡æ¡£æœ«å°¾ä¹‹å‰æ·»åŠ \end
                latex_code = re.sub(r'(\\end\{document\})', rf'\\end{{{env}}}\n\1', latex_code)
        
        # ä¿®å¤æ•°å­¦æ¨¡å¼ä¸­çš„éæ³•å­—ç¬¦
        # åœ¨$...$ä¸­çš„_å’Œ^éœ€è¦è½¬ä¹‰
        def fix_math_mode(match):
            content = match.group(1)
            # å¦‚æœæ˜¯åœ¨æ•°å­¦å‘½ä»¤ä¸­ï¼Œä¸éœ€è¦è½¬ä¹‰
            if '_' in content or '^' in content:
                # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨æ•°å­¦å‘½ä»¤ä¸­
                if not re.search(r'\\[a-zA-Z]+', content):
                    content = content.replace('_', '\\_').replace('^', '\\^')
            return f'${content}$'
        
        # ä¸ä¿®æ”¹æ•°å­¦æ¨¡å¼ä¸­çš„å†…å®¹ï¼Œå› ä¸º_å’Œ^åœ¨æ•°å­¦æ¨¡å¼ä¸­æ˜¯åˆæ³•çš„
        # latex_code = re.sub(r'\$([^$]+)\$', fix_math_mode, latex_code)
        
        # ä¿®å¤è¿ç»­çš„\\å‘½ä»¤
        latex_code = re.sub(r'\\\\\s*\\\\', r'\\\\', latex_code)
        
        # ç§»é™¤ç©ºçš„æ®µè½
        latex_code = re.sub(r'\n\s*\n\s*\n', '\n\n', latex_code)
        
        return latex_code
    
    def _validate_and_fix_structure(self, latex_code):
        """éªŒè¯å¹¶ä¿®å¤LaTeXæ–‡æ¡£ç»“æ„"""
        # æ£€æŸ¥\begin{document}
        if not re.search(r'\\begin\{document\}', latex_code):
            self.log("ç¼ºå°‘\\begin{document}ï¼Œæ­£åœ¨æ·»åŠ ...", "WARNING")
            # åœ¨\documentclasså’Œ\usepackageä¹‹åæ·»åŠ 
            lines = latex_code.split('\n')
            insert_pos = 0
            for i, line in enumerate(lines):
                if re.search(r'\\documentclass|\\usepackage', line):
                    insert_pos = i + 1
            lines.insert(insert_pos, '\n\\begin{document}')
            latex_code = '\n'.join(lines)
        
        # æ£€æŸ¥\end{document}
        if not re.search(r'\\end\{document\}', latex_code):
            self.log("ç¼ºå°‘\\end{document}ï¼Œæ­£åœ¨æ·»åŠ ...", "WARNING")
            latex_code += '\n\\end{document}'
        
        # ç¡®ä¿\end{document}æ˜¯æœ€åä¸€ä¸ªå‘½ä»¤
        end_doc_match = re.search(r'\\end\{document\}', latex_code)
        if end_doc_match:
            end_pos = end_doc_match.end()
            # ç§»é™¤\end{document}åçš„æ‰€æœ‰å†…å®¹ï¼ˆé™¤äº†ç©ºç™½ï¼‰
            after_content = latex_code[end_pos:].strip()
            if after_content:
                self.log(f"å‘ç°\\end{{document}}åæœ‰é¢å¤–å†…å®¹: {after_content[:50]}...", "WARNING")
                latex_code = latex_code[:end_pos]
        
        return latex_code
    
    def _get_fallback_latex_template(self):
        """è·å–å¤‡ç”¨LaTeXæ¨¡æ¿"""
        return r"""
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}

\begin{document}

\section*{Translation Notice}

The automatic LaTeX generation failed for this document. 

This is a placeholder document. Please try the following:

\begin{itemize}
\item Ensure the input image is clear and readable
\item Try with a simpler layout
\item Check the LaTeX compilation logs for specific errors
\end{itemize}

\end{document}
"""

    def _load_api_key(self):
        """ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶åŠ è½½APIå¯†é’¥"""
        self.log("æ­£åœ¨æŸ¥æ‰¾OpenAI APIå¯†é’¥...", "DEBUG")
        
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            self.log("ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥", "DEBUG")
            return api_key
        
        # å°è¯•ä»é…ç½®æ–‡ä»¶è·å–
        # config_files = ['api_key.txt', 'openai_key.txt', 'config.json']
        config_files = ['config/openai_api_key.txt', 'api_key.txt', 'openai_key.txt', 'config.json']
        for config_file in config_files:
            if os.path.exists(config_file):
                try:
                    self.log(f"å°è¯•ä» {config_file} è¯»å–APIå¯†é’¥", "DEBUG")
                    with open(config_file, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if config_file.endswith('.json'):
                            data = json.loads(content)
                            return data.get('openai_api_key') or data.get('api_key')
                        else:
                            return content
                except Exception as e:
                    self.log(f"è¯»å–é…ç½®æ–‡ä»¶ {config_file} å¤±è´¥: {e}", "WARNING")
        
        self.log("æœªæ‰¾åˆ°APIå¯†é’¥é…ç½®", "WARNING")
        return None

    def check_requirements(self):
        """è¯¦ç»†æ£€æŸ¥è¿è¡Œç¯å¢ƒå’Œè¦æ±‚"""
        self.log("ğŸ” å¼€å§‹è¯¦ç»†ç¯å¢ƒæ£€æŸ¥...", "INFO")
        
        check_results = {
            "api_key": {"status": False, "details": [], "solutions": []},
            "pdflatex": {"status": False, "details": [], "solutions": []},
            "python_modules": {"status": False, "details": [], "solutions": []},
            "file_permissions": {"status": False, "details": [], "solutions": []}
        }
        
        # 1. è¯¦ç»†æ£€æŸ¥APIå¯†é’¥
        self.log("æ­¥éª¤1: æ£€æŸ¥OpenAI APIå¯†é’¥é…ç½®", "DEBUG")
        api_check = self._check_api_key_detailed()
        check_results["api_key"] = api_check
        
        # 2. è¯¦ç»†æ£€æŸ¥pdflatex
        self.log("æ­¥éª¤2: æ£€æŸ¥LaTeXç¯å¢ƒ", "DEBUG")
        latex_check = self._check_pdflatex_detailed()
        check_results["pdflatex"] = latex_check
        
        # 3. æ£€æŸ¥Pythonæ¨¡å—
        self.log("æ­¥éª¤3: æ£€æŸ¥Pythonæ¨¡å—ä¾èµ–", "DEBUG")
        modules_check = self._check_python_modules()
        check_results["python_modules"] = modules_check
        
        # 4. æ£€æŸ¥æ–‡ä»¶æƒé™
        self.log("æ­¥éª¤4: æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿæƒé™", "DEBUG")
        permissions_check = self._check_file_permissions()
        check_results["file_permissions"] = permissions_check
        
        # æ±‡æ€»æ£€æŸ¥ç»“æœ
        all_passed = all(result["status"] for result in check_results.values())
        
        if all_passed:
            self.log("ğŸ‰ æ‰€æœ‰ç¯å¢ƒæ£€æŸ¥é€šè¿‡!", "SUCCESS")
            return True
        else:
            self._generate_detailed_error_report(check_results)
            return False

    def _check_api_key_detailed(self):
        """è¯¦ç»†æ£€æŸ¥APIå¯†é’¥é…ç½®"""
        result = {"status": False, "details": [], "solutions": []}
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_key = os.getenv('OPENAI_API_KEY')
        if env_key:
            result["details"].append("âœ… ç¯å¢ƒå˜é‡ OPENAI_API_KEY å­˜åœ¨")
            if len(env_key.strip()) > 0:
                result["details"].append(f"âœ… å¯†é’¥é•¿åº¦: {len(env_key)} å­—ç¬¦")
                if env_key.startswith('sk-'):
                    result["details"].append("âœ… å¯†é’¥æ ¼å¼æ­£ç¡® (ä»¥sk-å¼€å¤´)")
                    result["status"] = True
                else:
                    result["details"].append("âš ï¸ å¯†é’¥æ ¼å¼å¯èƒ½æœ‰è¯¯ (ä¸ä»¥sk-å¼€å¤´)")
                    result["solutions"].append("æ£€æŸ¥å¯†é’¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
            else:
                result["details"].append("âŒ ç¯å¢ƒå˜é‡ä¸ºç©º")
                result["solutions"].append("è®¾ç½®æœ‰æ•ˆçš„OPENAI_API_KEYç¯å¢ƒå˜é‡")
        else:
            result["details"].append("âŒ ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_files = [
            'config/openai_api_key.txt',
            'api_key.txt', 
            'openai_key.txt', 
            'config.json'
        ]
        
        found_config = False
        for config_file in config_files:
            if os.path.exists(config_file):
                found_config = True
                result["details"].append(f"âœ… æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file}")
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if config_file.endswith('.json'):
                            data = json.loads(content)
                            key = data.get('openai_api_key') or data.get('api_key')
                            if key:
                                result["details"].append("âœ… JSONé…ç½®æ–‡ä»¶åŒ…å«APIå¯†é’¥")
                                if not result["status"] and key.startswith('sk-'):
                                    result["status"] = True
                            else:
                                result["details"].append("âŒ JSONé…ç½®æ–‡ä»¶ç¼ºå°‘APIå¯†é’¥å­—æ®µ")
                        else:
                            if content and content.startswith('sk-'):
                                result["details"].append("âœ… é…ç½®æ–‡ä»¶åŒ…å«æœ‰æ•ˆæ ¼å¼çš„APIå¯†é’¥")
                                if not result["status"]:
                                    result["status"] = True
                            else:
                                result["details"].append("âŒ é…ç½®æ–‡ä»¶å¯†é’¥æ ¼å¼æ— æ•ˆ")
                except Exception as e:
                    result["details"].append(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
                    result["solutions"].append(f"æ£€æŸ¥æ–‡ä»¶ {config_file} çš„æƒé™å’Œæ ¼å¼")
                break
        
        if not found_config and not env_key:
            result["details"].append("âŒ æœªæ‰¾åˆ°ä»»ä½•APIå¯†é’¥é…ç½®")
            result["solutions"].extend([
                "æ–¹æ¡ˆ1: è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY",
                "æ–¹æ¡ˆ2: åˆ›å»º config/openai_api_key.txt æ–‡ä»¶å¹¶å†™å…¥å¯†é’¥",
                "æ–¹æ¡ˆ3: åˆ›å»º api_key.txt æ–‡ä»¶å¹¶å†™å…¥å¯†é’¥",
                "è¯·è®¿é—® https://platform.openai.com/account/api-keys è·å–APIå¯†é’¥"
            ])
        
        return result

    def _check_pdflatex_detailed(self):
        """è¯¦ç»†æ£€æŸ¥pdflatexç¯å¢ƒ"""
        result = {"status": False, "details": [], "solutions": []}
        
        # æ£€æŸ¥é…ç½®çš„è·¯å¾„
        if self.pdflatex_path != "pdflatex":
            result["details"].append(f"ğŸ” æ£€æŸ¥é…ç½®è·¯å¾„: {self.pdflatex_path}")
            if os.path.exists(self.pdflatex_path):
                result["details"].append("âœ… é…ç½®è·¯å¾„å­˜åœ¨")
                # æ£€æŸ¥æ–‡ä»¶æƒé™
                if os.access(self.pdflatex_path, os.X_OK):
                    result["details"].append("âœ… æ–‡ä»¶å…·æœ‰æ‰§è¡Œæƒé™")
                    try:
                        # æµ‹è¯•æ‰§è¡Œ
                        proc = subprocess.run([self.pdflatex_path, "--version"], 
                                            capture_output=True, text=True, timeout=10)
                        if proc.returncode == 0:
                            version_info = proc.stdout.split('\n')[0] if proc.stdout else "æœªçŸ¥ç‰ˆæœ¬"
                            result["details"].append(f"âœ… pdflatexç‰ˆæœ¬: {version_info}")
                            result["status"] = True
                        else:
                            result["details"].append(f"âŒ pdflatexæ‰§è¡Œå¤±è´¥: {proc.stderr}")
                            result["solutions"].append("æ£€æŸ¥pdflatexå®‰è£…æ˜¯å¦å®Œæ•´")
                    except subprocess.TimeoutExpired:
                        result["details"].append("âŒ pdflatexæ‰§è¡Œè¶…æ—¶")
                        result["solutions"].append("æ£€æŸ¥pdflatexæ˜¯å¦å“åº”")
                    except Exception as e:
                        result["details"].append(f"âŒ pdflatexæ‰§è¡Œå¼‚å¸¸: {e}")
                else:
                    result["details"].append("âŒ æ–‡ä»¶æ²¡æœ‰æ‰§è¡Œæƒé™")
                    result["solutions"].append(f"æˆäºˆæ‰§è¡Œæƒé™: chmod +x {self.pdflatex_path}")
            else:
                result["details"].append("âŒ é…ç½®è·¯å¾„ä¸å­˜åœ¨")
                result["solutions"].append("æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®æˆ–é‡æ–°å®‰è£…LaTeX")
        
        # æ£€æŸ¥ç³»ç»ŸPATH
        result["details"].append("ğŸ” æ£€æŸ¥ç³»ç»ŸPATHä¸­çš„pdflatex")
        try:
            proc = subprocess.run(["pdflatex", "--version"], 
                                capture_output=True, text=True, timeout=10)
            if proc.returncode == 0:
                result["details"].append("âœ… ç³»ç»ŸPATHä¸­æ‰¾åˆ°pdflatex")
                version_info = proc.stdout.split('\n')[0] if proc.stdout else "æœªçŸ¥ç‰ˆæœ¬"
                result["details"].append(f"âœ… ç³»ç»Ÿpdflatexç‰ˆæœ¬: {version_info}")
                if not result["status"]:
                    result["status"] = True
            else:
                result["details"].append("âŒ ç³»ç»ŸPATHä¸­pdflatexæ‰§è¡Œå¤±è´¥")
        except subprocess.TimeoutExpired:
            result["details"].append("âŒ ç³»ç»Ÿpdflatexæ‰§è¡Œè¶…æ—¶")
        except FileNotFoundError:
            result["details"].append("âŒ ç³»ç»ŸPATHä¸­æœªæ‰¾åˆ°pdflatex")
        except Exception as e:
            result["details"].append(f"âŒ ç³»ç»Ÿpdflatexæ£€æŸ¥å¼‚å¸¸: {e}")
        
        # æ£€æŸ¥å¸¸è§çš„LaTeXå‘è¡Œç‰ˆ
        common_latex_paths = [
            "C:\\Program Files\\MiKTeX\\miktex\\bin\\x64\\pdflatex.exe",
            "C:\\Users\\{username}\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\pdflatex.exe",
            "/usr/bin/pdflatex",
            "/usr/local/bin/pdflatex",
            "/Library/TeX/texbin/pdflatex"
        ]
        
        username = os.getenv('USERNAME', os.getenv('USER', ''))
        result["details"].append("ğŸ” æ£€æŸ¥å¸¸è§LaTeXå®‰è£…ä½ç½®")
        found_latex = False
        
        for path_template in common_latex_paths:
            path = path_template.replace('{username}', username)
            if os.path.exists(path):
                result["details"].append(f"âœ… æ‰¾åˆ°LaTeXå®‰è£…: {path}")
                found_latex = True
                if not result["status"]:
                    # æ›´æ–°é…ç½®å»ºè®®
                    result["solutions"].append(f"å¯ä»¥æ‰‹åŠ¨è®¾ç½®è·¯å¾„: {path}")
                break
        
        if not found_latex:
            result["details"].append("âŒ æœªæ‰¾åˆ°å¸¸è§çš„LaTeXå®‰è£…")
        
        # æ·»åŠ å®‰è£…å»ºè®®
        if not result["status"]:
            result["solutions"].extend([
                "å®‰è£…å»ºè®®:",
                "Windows: ä¸‹è½½å¹¶å®‰è£… MiKTeX (https://miktex.org/download)",
                "macOS: å®‰è£… MacTeX (https://www.tug.org/mactex/)",
                "Linux: sudo apt-get install texlive-latex-base",
                "å®‰è£…åé‡å¯å‘½ä»¤è¡Œæˆ–IDE",
                "ç¡®ä¿LaTeXç¨‹åºæ·»åŠ åˆ°ç³»ç»ŸPATH"
            ])
        
        return result

    def _check_python_modules(self):
        """æ£€æŸ¥Pythonæ¨¡å—ä¾èµ–"""
        result = {"status": True, "details": [], "solutions": []}
        
        required_modules = [
            ('openai', 'OpenAI APIå®¢æˆ·ç«¯'),
            ('PIL', 'Pythonå›¾åƒå¤„ç†åº“'),
            ('pathlib', 'Pythonè·¯å¾„å¤„ç†'),
            ('base64', 'Base64ç¼–ç '),
            ('json', 'JSONå¤„ç†'),
            ('subprocess', 'å­è¿›ç¨‹ç®¡ç†'),
            ('os', 'æ“ä½œç³»ç»Ÿæ¥å£')
        ]
        
        missing_modules = []
        for module_name, description in required_modules:
            try:
                __import__(module_name)
                result["details"].append(f"âœ… {module_name}: {description}")
            except ImportError:
                result["details"].append(f"âŒ {module_name}: {description} - ç¼ºå¤±")
                missing_modules.append(module_name)
        
        if missing_modules:
            result["status"] = False
            result["solutions"].append(f"å®‰è£…ç¼ºå¤±çš„æ¨¡å—: pip install {' '.join(missing_modules)}")
        
        return result

    def _check_file_permissions(self):
        """æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿæƒé™"""
        result = {"status": True, "details": [], "solutions": []}
        
        # æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™
        output_dirs = ['poster_output', 'uploads', 'downloads']
        
        for dir_name in output_dirs:
            try:
                os.makedirs(dir_name, exist_ok=True)
                # æµ‹è¯•å†™å…¥æƒé™
                test_file = os.path.join(dir_name, 'test_permission.tmp')
                with open(test_file, 'w') as f:
                    f.write('test')
                os.remove(test_file)
                result["details"].append(f"âœ… {dir_name}: è¯»å†™æƒé™æ­£å¸¸")
            except PermissionError:
                result["details"].append(f"âŒ {dir_name}: æƒé™ä¸è¶³")
                result["status"] = False
                result["solutions"].append(f"æˆäºˆç›®å½•å†™å…¥æƒé™: {dir_name}")
            except Exception as e:
                result["details"].append(f"âŒ {dir_name}: æ£€æŸ¥å¤±è´¥ - {e}")
                result["status"] = False
        
        return result

    def _generate_detailed_error_report(self, check_results):
        """ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š"""
        self.log("=" * 60, "ERROR")
        self.log("ğŸš¨ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ - è¯¦ç»†æŠ¥å‘Š", "ERROR")
        self.log("=" * 60, "ERROR")
        
        for category, result in check_results.items():
            status_icon = "âœ…" if result["status"] else "âŒ"
            category_name = {
                "api_key": "OpenAI APIå¯†é’¥",
                "pdflatex": "LaTeXç¯å¢ƒ",
                "python_modules": "Pythonæ¨¡å—",
                "file_permissions": "æ–‡ä»¶æƒé™"
            }.get(category, category)
            
            self.log(f"\n{status_icon} {category_name}:", "ERROR" if not result["status"] else "SUCCESS")
            
            for detail in result["details"]:
                print(f"   {detail}")
            
            if result["solutions"] and not result["status"]:
                self.log("   ğŸ’¡ è§£å†³æ–¹æ¡ˆ:", "WARNING")
                for i, solution in enumerate(result["solutions"], 1):
                    print(f"      {i}. {solution}")
        
        self.log("\n" + "=" * 60, "ERROR")
        self.log("è¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•", "ERROR")
        self.log("=" * 60, "ERROR")

    def check_requirements_with_details(self):
        """æ£€æŸ¥ç¯å¢ƒå¹¶è¿”å›è¯¦ç»†ç»“æœï¼ˆç”¨äºAPIå“åº”ï¼‰"""
        self.log("ğŸ” å¼€å§‹è¯¦ç»†ç¯å¢ƒæ£€æŸ¥...", "INFO")
        
        check_results = {
            "api_key": {"status": False, "details": [], "solutions": []},
            "pdflatex": {"status": False, "details": [], "solutions": []},
            "python_modules": {"status": False, "details": [], "solutions": []},
            "file_permissions": {"status": False, "details": [], "solutions": []}
        }
        
        # æ‰§è¡Œå„é¡¹æ£€æŸ¥
        check_results["api_key"] = self._check_api_key_detailed()
        check_results["pdflatex"] = self._check_pdflatex_detailed()
        check_results["python_modules"] = self._check_python_modules()
        check_results["file_permissions"] = self._check_file_permissions()
        
        # æ±‡æ€»ç»“æœ
        all_passed = all(result["status"] for result in check_results.values())
        
        if all_passed:
            self.log("ğŸ‰ æ‰€æœ‰ç¯å¢ƒæ£€æŸ¥é€šè¿‡!", "SUCCESS")
            return {
                'success': True,
                'message': 'ç¯å¢ƒæ£€æŸ¥é€šè¿‡'
            }
        else:
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            self._generate_detailed_error_report(check_results)
            
            # å‡†å¤‡APIå“åº”æ•°æ®
            error_summary = []
            all_details = {}
            all_solutions = []
            
            for category, result in check_results.items():
                category_name = {
                    "api_key": "OpenAI APIå¯†é’¥",
                    "pdflatex": "LaTeXç¯å¢ƒ", 
                    "python_modules": "Pythonæ¨¡å—",
                    "file_permissions": "æ–‡ä»¶æƒé™"
                }.get(category, category)
                
                if not result["status"]:
                    error_summary.append(f"âŒ {category_name}: æ£€æŸ¥å¤±è´¥")
                    all_details[category_name] = {
                        'details': result["details"],
                        'solutions': result["solutions"]
                    }
                    all_solutions.extend(result["solutions"])
                else:
                    error_summary.append(f"âœ… {category_name}: æ­£å¸¸")
            
            return {
                'success': False,
                'error_summary': '; '.join(error_summary),
                'details': all_details,
                'solutions': all_solutions
            }

    def validate_image_file(self, image_path):
        """éªŒè¯å›¾åƒæ–‡ä»¶"""
        self.log(f"éªŒè¯å›¾åƒæ–‡ä»¶: {image_path}", "DEBUG")
        
        if not os.path.exists(image_path):
            self.log(f"æ–‡ä»¶ä¸å­˜åœ¨: {image_path}", "ERROR")
            return False
        
        if not os.path.isfile(image_path):
            self.log(f"ä¸æ˜¯æ–‡ä»¶: {image_path}", "ERROR")
            return False
        
        file_size = os.path.getsize(image_path)
        if file_size == 0:
            self.log(f"æ–‡ä»¶å¤§å°ä¸º0: {image_path}", "ERROR")
            return False
        
        self.log(f"æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œå¤§å°: {file_size} bytes", "SUCCESS")
        return True

    def encode_image_to_base64(self, image_path):
        """
        å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼
        
        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: base64ç¼–ç çš„å›¾åƒæ•°æ®
        """
        try:
            self.log(f"ç¼–ç å›¾åƒæ–‡ä»¶: {image_path}", "DEBUG")
            
            if not self.validate_image_file(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶éªŒè¯å¤±è´¥: {image_path}")
            
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                image_base64 = base64.b64encode(image_data).decode("utf-8")
            
            self.log(f"å›¾åƒç¼–ç æˆåŠŸï¼Œæ•°æ®é•¿åº¦: {len(image_base64)} å­—ç¬¦", "SUCCESS")
            return image_base64
            
        except FileNotFoundError as e:
            self.log(f"æ–‡ä»¶æœªæ‰¾åˆ°: {str(e)}", "ERROR")
            raise
        except Exception as e:
            self.log(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}", "ERROR")
            raise Exception(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}")

    def poster_to_latex(self, image_path, output_tex_file="output.tex"):
        """
        å°†æµ·æŠ¥å›¾åƒè½¬æ¢ä¸ºLaTeXä»£ç 
        
        Args:
            image_path (str): æµ·æŠ¥å›¾åƒè·¯å¾„
            output_tex_file (str): è¾“å‡ºçš„LaTeXæ–‡ä»¶å
            
        Returns:
            str: ç”Ÿæˆçš„LaTeXä»£ç 
        """
        self.log(f"å¼€å§‹åˆ†ææµ·æŠ¥å›¾åƒ: {image_path}", "INFO")
        
        if not self.client:
            raise Exception("OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œæ— æ³•ç”ŸæˆLaTeXä»£ç ")
        
        # ç¼–ç å›¾åƒ
        image_base64 = self.encode_image_to_base64(image_path)
        
        # ç¡®å®šå›¾åƒMIMEç±»å‹
        image_ext = Path(image_path).suffix.lower()
        if image_ext in ['.png']:
            mime_type = "image/png"
        elif image_ext in ['.jpg', '.jpeg']:
            mime_type = "image/jpeg"
        else:
            mime_type = "image/png"  # é»˜è®¤ä¸ºPNG
        
        self.log(f"å›¾åƒç±»å‹: {mime_type}", "DEBUG")
        
        # æ„å»ºå›¾åƒpayload
        image_payload = {
            "type": "image_url",
            "image_url": {
                "url": f"data:{mime_type};base64,{image_base64}"
            }
        }
        
        # è°ƒç”¨OpenAI API
        self.log("è°ƒç”¨OpenAI APIç”ŸæˆLaTeXä»£ç ...", "INFO")
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "You are a helpful assistant that outputs complete LaTeX code for poster layout recreation."
                    },
                    {"role": "user", "content": self.custom_prompt},
                    {"role": "user", "content": [image_payload]}
                ]
            )
            
            # latex_code = response.choices[0].message.content
            raw_response = response.choices[0].message.content

            # --- START: è¿™æ˜¯æˆ‘ä»¬æ–°å¢çš„æ¸…ç†ä»£ç  ---
            self.log("æ­£åœ¨æ¸…ç†AIè¿”å›çš„LaTeXä»£ç ...", "DEBUG")
            
            # é¦–å…ˆå°è¯•ç§»é™¤Markdownä»£ç å—æ ‡è®°
            cleaned_code = re.sub(r'^```(latex)?\s*', '', raw_response, flags=re.MULTILINE)
            cleaned_code = re.sub(r'```\s*$', '', cleaned_code, flags=re.MULTILINE)
            
            # å¦‚æœAIè¿”å›çš„å†…å®¹åŒ…å«è¯´æ˜æ–‡å­—ï¼Œå°è¯•æå–LaTeXä»£ç éƒ¨åˆ†
            # æŸ¥æ‰¾ \documentclass å¼€å§‹çš„ä½ç½®
            documentclass_match = re.search(r'\\documentclass', cleaned_code)
            if documentclass_match:
                # ä» \documentclass å¼€å§‹æå–
                latex_start = documentclass_match.start()
                cleaned_code = cleaned_code[latex_start:]
                self.log("æ£€æµ‹åˆ°è¯´æ˜æ–‡å­—ï¼Œå·²æå–LaTeXä»£ç éƒ¨åˆ†", "DEBUG")
            
            # æŸ¥æ‰¾ \end{document} ç»“æŸçš„ä½ç½®
            end_document_match = re.search(r'\\end\{document\}', cleaned_code)
            if end_document_match:
                # æå–åˆ° \end{document} ç»“æŸ
                latex_end = end_document_match.end()
                cleaned_code = cleaned_code[:latex_end]
                self.log("å·²æˆªå–åˆ°LaTeXä»£ç ç»“æŸä½ç½®", "DEBUG")
            
            # ç§»é™¤å¼€å¤´å’Œç»“å°¾å¯èƒ½å­˜åœ¨çš„ä»»ä½•ç©ºç™½å­—ç¬¦
            latex_code = cleaned_code.strip()
            
            # å‰”é™¤æ‰€æœ‰ä¸­æ–‡å†…å®¹
            self.log("æ­£åœ¨å‰”é™¤LaTeXä»£ç ä¸­çš„ä¸­æ–‡å†…å®¹...", "DEBUG")
            latex_code = self._remove_chinese_content(latex_code)
            
            # åº”ç”¨å¢å¼ºçš„LaTeXä»£ç ä¿®å¤
            self.log("æ­£åœ¨åº”ç”¨å¢å¼ºçš„LaTeXä»£ç ä¿®å¤...", "DEBUG")
            latex_code = self._enhance_latex_code(latex_code)
            # --- END: æ¸…ç†ä»£ç ç»“æŸ ---
            self.log("LaTeXä»£ç ç”ŸæˆæˆåŠŸ!", "SUCCESS")
            
            # ä¿å­˜LaTeXä»£ç åˆ°æ–‡ä»¶
            try:
                with open(output_tex_file, "w", encoding="utf-8") as f:
                    f.write(latex_code)
                self.log(f"LaTeXä»£ç å·²ä¿å­˜åˆ°: {output_tex_file}", "SUCCESS")
            except Exception as e:
                self.log(f"ä¿å­˜LaTeXæ–‡ä»¶å¤±è´¥: {e}", "ERROR")
                raise
            
            return latex_code
            
        except Exception as e:
            self.log(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}", "ERROR")
            raise Exception(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}")

    def compile_tex_to_pdf(self, tex_filename):
        """
        ç¼–è¯‘LaTeXæ–‡ä»¶ä¸ºPDFï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            tex_filename (str): LaTeXæ–‡ä»¶å
            
        Returns:
            str: ç”Ÿæˆçš„PDFæ–‡ä»¶è·¯å¾„
        """
        try:
            self.log(f"å¼€å§‹ç¼–è¯‘LaTeXæ–‡ä»¶: {tex_filename}", "INFO")
            
            if not os.path.exists(tex_filename):
                raise FileNotFoundError(f"LaTeXæ–‡ä»¶ä¸å­˜åœ¨: {tex_filename}")
            
            # æ£€æŸ¥LaTeXæ–‡ä»¶å†…å®¹
            file_size = os.path.getsize(tex_filename)
            self.log(f"LaTeXæ–‡ä»¶å¤§å°: {file_size} bytes", "DEBUG")
            
            if file_size == 0:
                raise Exception("LaTeXæ–‡ä»¶ä¸ºç©º")
            
            # ç¡®å®špdflatexå‘½ä»¤
            pdflatex_cmd = self._get_pdflatex_command()
            
            # ç¼–è¯‘LaTeXæ–‡ä»¶ - è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•
            tex_dir = os.path.dirname(os.path.abspath(tex_filename))
            tex_basename = os.path.basename(tex_filename)
            
            self.log("æ‰§è¡Œpdflatexç¼–è¯‘...", "DEBUG")
            self.log(f"å·¥ä½œç›®å½•: {tex_dir}", "DEBUG")
            self.log(f"ç¼–è¯‘æ–‡ä»¶: {tex_basename}", "DEBUG")
            self.log(f"ä½¿ç”¨å‘½ä»¤: {pdflatex_cmd}", "DEBUG")
            
            # æ¸…ç†ä¹‹å‰çš„è¾…åŠ©æ–‡ä»¶
            self._cleanup_before_compile(tex_filename)
            
            # å°è¯•ç¼–è¯‘ï¼ˆå¯èƒ½éœ€è¦å¤šæ¬¡ï¼‰
            max_attempts = 2
            for attempt in range(max_attempts):
                self.log(f"ç¼–è¯‘å°è¯• {attempt + 1}/{max_attempts}", "INFO")
                
                try:
                    result = subprocess.run(
                        [pdflatex_cmd, "-interaction=nonstopmode", "-halt-on-error", tex_basename], 
                        capture_output=True, text=True, cwd=tex_dir, timeout=60
                    )
                except UnicodeDecodeError:
                    # å¦‚æœå‡ºç°ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨é”™è¯¯å¿½ç•¥æ¨¡å¼
                    result = subprocess.run(
                        [pdflatex_cmd, "-interaction=nonstopmode", "-halt-on-error", tex_basename], 
                        capture_output=True, text=True, cwd=tex_dir, errors='ignore', timeout=60
                    )
                except subprocess.TimeoutExpired:
                    raise Exception("pdflatexç¼–è¯‘è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
                
                # è¯¦ç»†çš„é”™è¯¯åˆ†æ
                if result.returncode != 0:
                    self.log(f"ç¼–è¯‘å°è¯• {attempt + 1} å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}", "ERROR")
                    
                    # åˆ†æé”™è¯¯ç±»å‹
                    error_analysis = self._analyze_compilation_error(result.stdout, result.stderr)
                    
                    if error_analysis["is_miktex_update_issue"]:
                        raise Exception(
                            "MiKTeXéœ€è¦æ›´æ–°ã€‚è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š\n" 
                            "1. æ‰“å¼€ MiKTeX Console (ç®¡ç†å‘˜æ¨¡å¼)\n" 
                            "2. ç‚¹å‡» 'Check for updates'\n" 
                            "3. å®‰è£…æ‰€æœ‰å¯ç”¨æ›´æ–°\n" 
                            "4. é‡å¯åº”ç”¨ç¨‹åº\n" 
                            f"è¯¦ç»†é”™è¯¯: {error_analysis['error_message']}"
                        )
                    
                    if error_analysis["is_missing_package"]:
                        self.log(f"æ£€æµ‹åˆ°ç¼ºå¤±åŒ…: {error_analysis['missing_packages']}", "WARNING")
                        if attempt < max_attempts - 1:
                            self.log("å°è¯•è‡ªåŠ¨å®‰è£…ç¼ºå¤±åŒ…...", "INFO")
                            self._install_missing_packages(error_analysis['missing_packages'])
                            continue
                    
                    if attempt == max_attempts - 1:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¾“å‡ºè¯¦ç»†é”™è¯¯
                        self._output_detailed_error(result.stdout, result.stderr, tex_filename)
                        raise Exception(f"pdflatexç¼–è¯‘å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                else:
                    self.log("pdflatexç¼–è¯‘æˆåŠŸ!", "SUCCESS")
                    if result.stdout:
                        self.log(f"ç¼–è¯‘è¾“å‡ºæ‘˜è¦: {result.stdout[:200]}...", "DEBUG")
                    break
            
            # æ£€æŸ¥PDFæ˜¯å¦ç”Ÿæˆ
            pdf_filename = tex_filename.replace(".tex", ".pdf")
            if os.path.exists(pdf_filename):
                pdf_size = os.path.getsize(pdf_filename)
                self.log(f"PDFç¼–è¯‘æˆåŠŸ: {pdf_filename} ({pdf_size} bytes)", "SUCCESS")
                return pdf_filename
            else:
                raise Exception("PDFæ–‡ä»¶æœªç”Ÿæˆï¼Œå³ä½¿ç¼–è¯‘è¿”å›æˆåŠŸ")
            
        except subprocess.CalledProcessError as e:
            self.log(f"ç¼–è¯‘è¿‡ç¨‹å‡ºé”™: {e}", "ERROR")
            raise Exception(f"ç¼–è¯‘ {tex_filename} æ—¶å‡ºé”™: {e}")

    def _get_pdflatex_command(self):
        """è·å–å¯ç”¨çš„pdflatexå‘½ä»¤"""
        if self.pdflatex_path == "pdflatex":
            return "pdflatex"
        elif os.path.exists(self.pdflatex_path):
            return self.pdflatex_path
        else:
            # æœ€åå°è¯•ç³»ç»ŸPATH
            try:
                subprocess.run(["pdflatex", "--version"], 
                             check=True, capture_output=True, text=True, timeout=5)
                return "pdflatex"
            except:
                raise FileNotFoundError(
                    f"pdflatexæœªæ‰¾åˆ°ã€‚è¯·æ£€æŸ¥MiKTeXå®‰è£…æˆ–è·¯å¾„é…ç½®ã€‚\n" 
                    f"å½“å‰é…ç½®è·¯å¾„: {self.pdflatex_path}\n" 
                    "å»ºè®®ï¼š\n" 
                    "1. é‡æ–°å®‰è£…MiKTeX\n" 
                    "2. ç¡®ä¿MiKTeXæ·»åŠ åˆ°ç³»ç»ŸPATH\n" 
                    "3. æˆ–è€…æ‰‹åŠ¨æŒ‡å®špdflatex.exeçš„å®Œæ•´è·¯å¾„"
                )

    def _cleanup_before_compile(self, tex_filename):
        """ç¼–è¯‘å‰æ¸…ç†è¾…åŠ©æ–‡ä»¶"""
        base_name = tex_filename.replace(".tex", "")
        cleanup_extensions = ["aux", "log", "out", "toc", "nav", "snm", "fdb_latexmk", "fls"]
        
        for ext in cleanup_extensions:
            aux_file = f"{base_name}.{ext}"
            try:
                if os.path.exists(aux_file):
                    os.remove(aux_file)
                    self.log(f"æ¸…ç†æ—§æ–‡ä»¶: {aux_file}", "DEBUG")
            except Exception as e:
                self.log(f"æ¸…ç†æ–‡ä»¶ {aux_file} æ—¶å‡ºé”™: {e}", "WARNING")

    def _analyze_compilation_error(self, stdout, stderr):
        """åˆ†æç¼–è¯‘é”™è¯¯"""
        analysis = {
            "is_miktex_update_issue": False,
            "is_missing_package": False,
            "missing_packages": [],
            "error_message": "",
            "suggestions": []
        }
        
        error_text = (stdout or "") + (stderr or "")
        error_text_lower = error_text.lower()
        
        # æ£€æŸ¥MiKTeXæ›´æ–°é—®é¢˜
        miktex_update_keywords = [
            "you have not checked for miktex updates",
            "miktex update required",
            "miktex console",
            "check for updates"
        ]
        
        for keyword in miktex_update_keywords:
            if keyword in error_text_lower:
                analysis["is_miktex_update_issue"] = True
                analysis["error_message"] = error_text[:500]
                break
        
        # æ£€æŸ¥ç¼ºå¤±åŒ…
        import re
        package_patterns = [
            r"File `([^']+\.sty)' not found",
            r"LaTeX Error: File `([^']+)' not found",
            r"! Package (\\w+) Error"
        ]
        
        for pattern in package_patterns:
            matches = re.findall(pattern, error_text)
            for match in matches:
                package_name = match.replace('.sty', '')
                if package_name not in analysis["missing_packages"]:
                    analysis["missing_packages"].append(package_name)
                    analysis["is_missing_package"] = True
        
        return analysis

    def _install_missing_packages(self, packages):
        """å°è¯•å®‰è£…ç¼ºå¤±çš„åŒ…"""
        for package in packages:
            try:
                self.log(f"å°è¯•å®‰è£…åŒ…: {package}", "INFO")
                # ä½¿ç”¨MiKTeXåŒ…ç®¡ç†å™¨å®‰è£…
                subprocess.run(["mpm", "--install", package], 
                             check=True, capture_output=True, text=True, timeout=30)
                self.log(f"åŒ…å®‰è£…æˆåŠŸ: {package}", "SUCCESS")
            except Exception as e:
                self.log(f"åŒ…å®‰è£…å¤±è´¥: {package} - {e}", "WARNING")

    def _output_detailed_error(self, stdout, stderr, tex_filename):
        """è¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯"""
        self.log("=== è¯¦ç»†ç¼–è¯‘é”™è¯¯ä¿¡æ¯ ===", "ERROR")
        
        if stdout:
            self.log("ç¼–è¯‘è¾“å‡º (stdout):", "DEBUG")
            # è¾“å‡ºæœ€å1000ä¸ªå­—ç¬¦ï¼Œè¿™é€šå¸¸åŒ…å«å…³é”®é”™è¯¯ä¿¡æ¯
            print(stdout[-1000:] if len(stdout) > 1000 else stdout)
        
        if stderr:
            self.log("ç¼–è¯‘é”™è¯¯ (stderr):", "DEBUG")
            print(stderr[-1000:] if len(stderr) > 1000 else stderr)
        
        # å°è¯•æŸ¥æ‰¾.logæ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯
        log_file = tex_filename.replace(".tex", ".log")
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                    log_content = f.read()
                    # æŸ¥æ‰¾é”™è¯¯è¡Œ
                    lines = log_content.split('\n')
                    error_lines = [line for line in lines if 'error' in line.lower() or '!' in line]
                    if error_lines:
                        self.log("LaTeXæ—¥å¿—ä¸­çš„é”™è¯¯è¡Œ:", "DEBUG")
                        for line in error_lines[-10:]:
                            print(f"  {line}")
            except Exception as e:
                self.log(f"æ— æ³•è¯»å–LaTeXæ—¥å¿—æ–‡ä»¶: {e}", "WARNING")

    def clean_auxiliary_files(self, tex_filename):
        """
        æ¸…ç†ç¼–è¯‘è¿‡ç¨‹ä¸­äº§ç”Ÿçš„è¾…åŠ©æ–‡ä»¶
        
        Args:
            tex_filename (str): LaTeXæ–‡ä»¶å
        """
        base_name = tex_filename.replace(".tex", "")
        auxiliary_extensions = ["aux", "log", "out", "toc", "nav", "snm"]
        
        cleaned_files = []
        for ext in auxiliary_extensions:
            aux_file = f"{base_name}.{ext}"
            try:
                if os.path.exists(aux_file):
                    os.remove(aux_file)
                    cleaned_files.append(aux_file)
            except Exception as e:
                self.log(f"æ¸…ç†æ–‡ä»¶ {aux_file} æ—¶å‡ºé”™: {e}", "WARNING")
        
        if cleaned_files:
            self.log(f"å·²æ¸…ç†è¾…åŠ©æ–‡ä»¶: {', '.join(cleaned_files)}", "SUCCESS")

    def translate_poster_complete(self, image_path, output_base_name="output", clean_aux=True):
        """
        å®Œæ•´çš„æµ·æŠ¥ç¿»è¯‘æµç¨‹ï¼šå›¾åƒ -> LaTeX -> PDF
        
        Args:
            image_path (str): æµ·æŠ¥å›¾åƒè·¯å¾„
            output_base_name (str): è¾“å‡ºæ–‡ä»¶åŸºç¡€åç§°
            clean_aux (bool): æ˜¯å¦æ¸…ç†è¾…åŠ©æ–‡ä»¶
            
        Returns:
            dict: åŒ…å«ç”Ÿæˆæ–‡ä»¶ä¿¡æ¯çš„å­—å…¸
        """
        self.log("ğŸš€ å¼€å§‹æµ·æŠ¥ç¿»è¯‘æµç¨‹...", "INFO")
        
        try:
            # éªŒè¯å›¾åƒæ–‡ä»¶
            if not self.validate_image_file(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶æ— æ•ˆ: {image_path}")
            
            # ç¬¬ä¸€æ­¥ï¼šç”ŸæˆLaTeXä»£ç 
            tex_filename = f"{output_base_name}.tex"
            self.log("ç¬¬1æ­¥: ç”ŸæˆLaTeXä»£ç ", "INFO")
            latex_code = self.poster_to_latex(image_path, tex_filename)
            
            # ç¬¬äºŒæ­¥ï¼šç¼–è¯‘PDF
            self.log("ç¬¬2æ­¥: ç¼–è¯‘PDF", "INFO")
            pdf_filename = self.compile_tex_to_pdf(tex_filename)
            
            # ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†è¾…åŠ©æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            if clean_aux:
                self.log("ç¬¬3æ­¥: æ¸…ç†è¾…åŠ©æ–‡ä»¶", "INFO")
                self.clean_auxiliary_files(tex_filename)
            
            result = {
                "success": True,
                "tex_file": tex_filename,
                "pdf_file": pdf_filename,
                "image_file": image_path,
                "latex_code_length": len(latex_code)
            }
            
            self.log("ğŸ‰ æµ·æŠ¥ç¿»è¯‘å®Œæˆ!", "SUCCESS")
            self.log(f"   è¾“å…¥å›¾åƒ: {image_path}", "INFO")
            self.log(f"   LaTeXæ–‡ä»¶: {tex_filename}", "INFO")
            self.log(f"   PDFæ–‡ä»¶: {pdf_filename}", "INFO")
            
            return result
            
        except Exception as e:
            self.log(f"æµ·æŠ¥ç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
            return {
                "success": False,
                "error": str(e),
                "image_file": image_path
            }

# ========== ç¿»è¯‘åŠŸèƒ½ç±» ========== 

class SimpleTranslator:
    """ç®€åŒ–çš„ç¿»è¯‘å™¨ç±»ï¼ŒåŒ…å«æ ¸å¿ƒç¿»è¯‘åŠŸèƒ½"""
    
    def __init__(self, api_keys=None):
        self.api_keys = api_keys or load_api_keys()
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if OPENAI_AVAILABLE and self.api_keys.get('OPENAI_API_KEY'):
            try:
                self.openai_client = OpenAI(api_key=self.api_keys['OPENAI_API_KEY'])
                log_message("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ", "SUCCESS")
            except Exception as e:
                log_message(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}", "ERROR")
                self.openai_client = None
        else:
            self.openai_client = None
            log_message("OpenAIä¸å¯ç”¨æˆ–APIå¯†é’¥æœªè®¾ç½®", "WARNING")
    
    def translate_poster(self, image_path, output_dir='poster_output'):
        """æµ·æŠ¥ç¿»è¯‘åŠŸèƒ½ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            if not self.openai_client:
                return {
                    'success': False,
                    'error': 'OpenAI APIæœªé…ç½®'
                }
            
            # è¯»å–å›¾ç‰‡å¹¶ç¼–ç ä¸ºbase64
            with open(image_path, 'rb') as image_file:
                image_base64 = base64.b64encode(image_file.read()).decode('utf-8')
            
            # æ„å»ºè¯·æ±‚
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "è¯·å°†è¿™å¼ æµ·æŠ¥ç¿»è¯‘æˆLaTeXä»£ç ï¼Œè¦æ±‚ï¼š1. ç¿»è¯‘æ‰€æœ‰æ–‡å­—å†…å®¹ 2. ä¿æŒåŸæœ‰å¸ƒå±€ç»“æ„ 3. ç”Ÿæˆå¯ç›´æ¥ç¼–è¯‘çš„LaTeXä»£ç  4. ä¸ä½¿ç”¨å¤–éƒ¨å›¾ç‰‡æ–‡ä»¶"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ]
            
            # è°ƒç”¨OpenAI API
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=4000
            )
            
            latex_content = response.choices[0].message.content
            
            # ä¿å­˜LaTeXæ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            tex_filename = f"poster_{timestamp}.tex"
            tex_path = os.path.join(output_dir, tex_filename)
            
            os.makedirs(output_dir, exist_ok=True)
            with open(tex_path, 'w', encoding='utf-8') as f:
                f.write(latex_content)
            
            log_message(f"æµ·æŠ¥ç¿»è¯‘å®Œæˆ: {tex_filename}", "SUCCESS")
            
            return {
                'success': True,
                'message': 'æµ·æŠ¥ç¿»è¯‘å®Œæˆ',
                'tex_filename': tex_filename,
                'tex_path': tex_path,
                'latex_content': latex_content[:500] + '...' if len(latex_content) > 500 else latex_content
            }
            
        except Exception as e:
            log_message(f"æµ·æŠ¥ç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
            return {
                'success': False,
                'error': f'æµ·æŠ¥ç¿»è¯‘å¤±è´¥: {str(e)}'
            }
    
    def translate_webpage_google(self, url):
        """Googleç½‘é¡µç¿»è¯‘ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            if not SELENIUM_AVAILABLE:
                return {
                    'success': False,
                    'error': 'Seleniumæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œç½‘é¡µç¿»è¯‘'
                }
            
            # è®¾ç½®Chromeé€‰é¡¹
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')

            # é¢å¤–çš„éš”ç¦»é€‰é¡¹
            chrome_options.add_argument("--disable-extensions")
            chrome_options.add_argument("--disable-background-networking")
            chrome_options.add_argument("--disable-sync")
            chrome_options.add_argument("--disable-default-apps")
            chrome_options.add_argument("--no-first-run")
            chrome_options.add_argument("--disable-background-timer-throttling")
            chrome_options.add_argument("--disable-backgrounding-occluded-windows")
            chrome_options.add_argument("--disable-renderer-backgrounding")

            # ä½¿ç”¨éšæœºremote debugging portæ¥é¿å…å†²çª
            import random
            chrome_options.add_argument(f"--remote-debugging-port={random.randint(9222, 9999)}")

            # æŒ‡å®šä¸€ä¸ªsnapå¯ä»¥è®¿é—®çš„ç›®å½•ï¼ˆåœ¨é¡¹ç›®ç›®å½•å†…ï¼‰
            import tempfile
            import uuid
            import os
            import time
            chrome_data_dir = os.path.join(os.path.dirname(__file__), 'tmp', 'chrome_data')
            os.makedirs(chrome_data_dir, exist_ok=True)
            user_data_dir = os.path.join(chrome_data_dir, f"profile_{os.getpid()}_{int(time.time()*1000)}_{uuid.uuid4().hex[:8]}")
            chrome_options.add_argument(f"--user-data-dir={user_data_dir}")

            # Snapä¸“ç”¨ï¼šå…è®¸è®¿é—®æ›´å¤šç›®å½•
            chrome_options.add_argument("--disable-software-rasterizer")

            driver = None
            try:
                driver = webdriver.Chrome(options=chrome_options)
                
                # è®¿é—®Googleç¿»è¯‘
                translate_url = f"https://translate.google.com/translate?sl=auto&tl=zh&u={url}"
                driver.get(translate_url)
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                time.sleep(5)
                
                # è·å–ç¿»è¯‘åçš„å†…å®¹
                page_source = driver.page_source
                
                # è§£æå†…å®¹
                soup = BeautifulSoup(page_source, 'html.parser')
                
                # ä¿å­˜ç»“æœ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"google_translate_{timestamp}.html"
                output_path = os.path.join('web_translation_output', output_filename)
                
                os.makedirs('web_translation_output', exist_ok=True)
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(page_source)
                
                log_message(f"Googleç½‘é¡µç¿»è¯‘å®Œæˆ: {output_filename}", "SUCCESS")
                
                return {
                    'success': True,
                    'message': 'Googleç½‘é¡µç¿»è¯‘å®Œæˆ',
                    'output_filename': output_filename,
                    'output_path': output_path,
                    'url': url
                }
                
            finally:
                if driver:
                    _cleanup_chrome_driver(driver)
                # æ¸…ç†ä¸´æ—¶ç”¨æˆ·æ•°æ®ç›®å½•
                try:
                    import shutil
                    shutil.rmtree(user_data_dir, ignore_errors=True)
                except Exception:
                    pass
            
        except Exception as e:
            log_message(f"Googleç½‘é¡µç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
            return {
                'success': False,
                'error': f'Googleç½‘é¡µç¿»è¯‘å¤±è´¥: {str(e)}'
            }
    
    def translate_webpage_gpt(self, url):
        """GPTç½‘é¡µç¿»è¯‘ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            if not self.openai_client:
                return {
                    'success': False,
                    'error': 'OpenAI APIæœªé…ç½®'
                }
            
            # è·å–ç½‘é¡µå†…å®¹
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # è§£æHTMLå†…å®¹
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æå–ä¸»è¦æ–‡æœ¬å†…å®¹
            for script in soup(["script", "style"]):
                script.decompose()
            
            text_content = soup.get_text()
            text_content = '\n'.join(line.strip() for line in text_content.splitlines() if line.strip())
            
            # é™åˆ¶æ–‡æœ¬é•¿åº¦
            if len(text_content) > 8000:
                text_content = text_content[:8000] + "..."
            
            # ä½¿ç”¨GPTç¿»è¯‘
            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘é¡µç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†æä¾›çš„ç½‘é¡µå†…å®¹ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒåŸæœ‰çš„ç»“æ„å’Œæ ¼å¼ã€‚"
                },
                {
                    "role": "user",
                    "content": f"è¯·å°†ä»¥ä¸‹ç½‘é¡µå†…å®¹ç¿»è¯‘æˆä¸­æ–‡ï¼š\n\n{text_content}"
                }
            ]
            
            gpt_response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                max_tokens=4000
            )
            
            translated_content = gpt_response.choices[0].message.content
            
            # ä¿å­˜ç¿»è¯‘ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"gpt_translate_{timestamp}.txt"
            output_path = os.path.join('web_translation_output', output_filename)
            
            os.makedirs('web_translation_output', exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"åŸå§‹URL: {url}\n")
                f.write("="*50 + "\n")
                f.write(translated_content)
            
            log_message(f"GPTç½‘é¡µç¿»è¯‘å®Œæˆ: {output_filename}", "SUCCESS")
            
            return {
                'success': True,
                'message': 'GPTç½‘é¡µç¿»è¯‘å®Œæˆ',
                'output_filename': output_filename,
                'output_path': output_path,
                'url': url,
                'translated_content': translated_content[:500] + '...' if len(translated_content) > 500 else translated_content
            }
            
        except Exception as e:
            log_message(f"GPTç½‘é¡µç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
            return {
                'success': False,
                'error': f'GPTç½‘é¡µç¿»è¯‘å¤±è´¥: {str(e)}'
            }
    
# å»¶è¿Ÿåˆå§‹åŒ–ç¿»è¯‘å™¨å®ä¾‹
translator = None

def get_translator():
    """è·å–ç¿»è¯‘å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global translator
    if translator is None:
        translator = SimpleTranslator()
    return translator

# ========== ç½‘é¡µç¿»è¯‘APIæ¥å£ ==========

@app.route('/api/webpage-google-translate', methods=['POST'])
@jwt_required()
def webpage_google_translate():
    """Googleç½‘é¡µç¿»è¯‘APIï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    try:
        log_message("å¼€å§‹Googleç½‘é¡µç¿»è¯‘APIè¯·æ±‚å¤„ç†", "INFO")
        
        data = request.get_json()
        if not data or not data.get('url'):
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›ç½‘é¡µURL'
            }), 400
        
        url = data['url'].strip()
        
        # éªŒè¯URLæ ¼å¼
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                raise ValueError("æ— æ•ˆçš„URLæ ¼å¼")
        except Exception:
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„URLæ ¼å¼'
            }), 400
        
        # ä½¿ç”¨ç¼“å­˜ï¼šæ ¹æ®URLç”Ÿæˆç¨³å®šæ–‡ä»¶åï¼ˆMD5ï¼‰
        import hashlib
        url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()[:16]
        cache_dir = os.path.join('translated_snapshot')
        os.makedirs(cache_dir, exist_ok=True)
        cached_pdf = os.path.join(cache_dir, f"web_{url_hash}.pdf")
        
        if os.path.exists(cached_pdf) and os.path.getsize(cached_pdf) > 0:
            pdf_filename = os.path.basename(cached_pdf)
            log_message(f"å‘½ä¸­ç½‘é¡µç¿»è¯‘ç¼“å­˜: {pdf_filename}", "INFO")
            return jsonify({
                'success': True,
                'message': 'ç¼“å­˜å‘½ä¸­',
                'pdf_filename': pdf_filename,
                'preview_url': f'/preview/translated/{pdf_filename}',
                'original_url': url,
                'file_size': os.path.getsize(cached_pdf)
            })

        # æœªå‘½ä¸­åˆ™æ‰§è¡ŒæŠ“å–å¹¶ç”ŸæˆPDF
        try:
            pdf_path, pdf_filename_real = _capture_google_translated_pdf(url)
            # å¤åˆ¶ä¸ºç¨³å®šhashå‘½åï¼Œä¾¿äºå¤ç”¨
            try:
                import shutil
                shutil.copy2(pdf_path, cached_pdf)
                pdf_filename = os.path.basename(cached_pdf)
            except Exception:
                pdf_filename = pdf_filename_real
                cached_pdf = pdf_path

            result = {
                'success': True,
                'pdf_filename': pdf_filename,
                'output_filename': pdf_filename
            }
        except Exception as e:
            result = {
                'success': False,
                'error': str(e)
            }
        
        if result['success']:
            return jsonify({
                'success': True,
                'message': 'Googleç½‘é¡µç¿»è¯‘å®Œæˆ',
                'pdf_filename': result['pdf_filename'],
                'output_filename': result['output_filename'],
                'preview_url': f'/preview/translated/{result["pdf_filename"]}',
                'url': url,
                'file_size': os.path.getsize(cached_pdf) if 'cached_pdf' in locals() else 0
            })
        else:
            return jsonify(result), 500
        
    except Exception as e:
        log_message(f"Googleç½‘é¡µç¿»è¯‘APIå¤±è´¥: {str(e)}", "ERROR")
        return jsonify({
            'success': False,
            'error': f'Googleç½‘é¡µç¿»è¯‘å¤±è´¥: {str(e)}'
        }), 500

# GPTç½‘é¡µç¿»è¯‘åŠŸèƒ½æš‚æ—¶ç§»é™¤ï¼Œå¾…ç¨³å®šåå†æ·»åŠ 
# æœªæ¥å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ GPTç½‘é¡µç¿»è¯‘çš„å®ç°

# ========== ç½‘é¡µç¿»è¯‘è¾…åŠ©å‡½æ•° ==========

def _sanitize_title(title: str) -> str:
    """
    æ¸…ç†ç½‘é¡µæ ‡é¢˜ï¼Œä½¿å…¶é€‚åˆä½œä¸ºæ–‡ä»¶å
    
    å‚æ•°:
        title: åŸå§‹ç½‘é¡µæ ‡é¢˜
        
    è¿”å›:
        æ¸…ç†åçš„å®‰å…¨æ–‡ä»¶å
    """
    # å¦‚æœæ ‡é¢˜ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼
    title = (title or "webpage").strip().replace('\n', ' ')
    # ç§»é™¤Windowsæ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
    title = re.sub(r'[\\/*?:"<>|]', '_', title)
    # é™åˆ¶é•¿åº¦ä¸º80ä¸ªå­—ç¬¦
    return title[:80] or "webpage"

async def _capture_google_translated_pdf_pyppeteer_async(url: str):
    """
    ä½¿ç”¨Pyppeteerï¼ˆå¼‚æ­¥ï¼‰æ¸²æŸ“Googleç¿»è¯‘é¡µé¢å¹¶ç”ŸæˆPDF
    
    å‚æ•°:
        url: è¦ç¿»è¯‘çš„åŸå§‹ç½‘é¡µURL
        
    è¿”å›:
        (pdf_path, pdf_filename): PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„å’Œæ–‡ä»¶å
    """
    browser = await launch({
        'headless': True,
        'args': [
            '--no-sandbox',
            '--disable-setuid-sandbox',
            '--disable-gpu',
            '--allow-insecure-localhost',
            '--ignore-certificate-errors',
            '--lang=en-US,en;q=0.9',
        ]
    })
    
    page = await browser.newPage()
    
    # è®¾ç½®è§†å£å¤§å°
    await page.setViewport({
        'width': 1280,
        'height': 800,
        'deviceScaleFactor': 1
    })
    
    # æ„å»ºGoogleç¿»è¯‘URL
    translate_url = f"https://translate.google.com/translate?hl=en&sl=auto&tl=en&u={quote(url)}&prev=search"
    log_message(f"[pyppeteer] æ‰“å¼€: {translate_url}", "DEBUG")
    
    # è®¿é—®é¡µé¢å¹¶ç­‰å¾…åŠ è½½å®Œæˆ
    await page.goto(translate_url, {
        'waitUntil': 'networkidle2',  # ç­‰å¾…ç½‘ç»œç©ºé—²
        'timeout': 60000              # 60ç§’è¶…æ—¶
    })
    
    # å°è¯•ç­‰å¾…ä¸»ä½“å†…å®¹ç¨³å®š
    try:
        await page.waitForSelector('body', {'timeout': 20000})
    except Exception:
        pass
    
    # ç§»é™¤Googleç¿»è¯‘å·¥å…·æ 
    try:
        await page.evaluate("var nv = document.getElementById('gt-nvframe'); if(nv){ nv.remove(); }")
        await page.evaluate("""
            var css = document.createElement("style");
            css.type = "text/css";
            css.innerHTML = `
                .goog-te-gadget, .goog-te-gadget-simple, #goog-gt-tt { display: none !important; }
            `;
            document.head.appendChild(css);
        """)
        log_message("[pyppeteer] å·²ç§»é™¤ Google Translate é¡¶éƒ¨å·¥å…·æ ", "SUCCESS")
    except Exception as e:
        log_message(f"[pyppeteer] ç§»é™¤é¡¶éƒ¨å·¥å…·æ æ—¶å‡ºé”™ï¼š{e}", "WARNING")
    
    # ä½¿ç”¨printåª’ä½“ç±»å‹ï¼ˆæ›´é€‚åˆPDFè¾“å‡ºï¼‰
    try:
        await page.emulateMediaType('print')
    except Exception:
        pass
    
    # è·å–å¹¶æ¸…ç†é¡µé¢æ ‡é¢˜
    safe_title = _sanitize_title(await page.title())
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    out_dir = 'translated_snapshot'
    os.makedirs(out_dir, exist_ok=True)
    
    # ç”ŸæˆPDF
    pdf_filename = f"{safe_title}.pdf"
    pdf_path = os.path.join(out_dir, pdf_filename)
    
    await page.pdf({
        'path': pdf_path,
        'format': 'A4',
        'printBackground': True,
        'margin': {
            'top': '0.4in',
            'bottom': '0.4in',
            'left': '0.4in',
            'right': '0.4in'
        },
        'scale': 0.9
    })
    
    await browser.close()
    
    return pdf_path, pdf_filename

def _capture_google_translated_pdf_pyppeteer(url: str):
    """
    Pyppeteerçš„åŒæ­¥åŒ…è£…å™¨
    """
    if not PYPPETEER_AVAILABLE:
        raise RuntimeError("Pyppeteer ä¸å¯ç”¨")
    
    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(
            _capture_google_translated_pdf_pyppeteer_async(url)
        )
    finally:
        loop.close()

def _capture_original_webpage_pdf(url: str) -> tuple:
    """
    ç”ŸæˆåŸå§‹ç½‘é¡µçš„PDF
    
    å‚æ•°:
        url: åŸå§‹ç½‘é¡µURL
        
    è¿”å›:
        (pdf_path, pdf_filename): PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„å’Œæ–‡ä»¶å
    """
    # ä¼˜å…ˆå°è¯•ä½¿ç”¨Pyppeteer
    if PYPPETEER_AVAILABLE:
        try:
            return _capture_original_webpage_pdf_pyppeteer(url)
        except Exception as e:
            log_message(f"Pyppeteer ç”ŸæˆåŸå§‹PDFå¤±è´¥ï¼Œå›é€€åˆ° Selenium: {str(e)}", "ERROR")
    
    # ä½¿ç”¨Seleniumä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
    driver = None
    try:
        # å¯åŠ¨Chromeæµè§ˆå™¨
        driver = _setup_chrome(disable_js=False)
        
        log_message(f"æ‰“å¼€åŸå§‹ç½‘é¡µ: {url}", "DEBUG")
        
        # è®¿é—®é¡µé¢
        driver.get(url)
        
        # ç­‰å¾…é¡µé¢åŸºæœ¬åŠ è½½å®Œæˆ
        try:
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.TAG_NAME, 'body'))
            )
        except Exception:
            time.sleep(2)  # å…œåº•ç­‰å¾…
        
        # è®¾ç½®æ‰“å°åª’ä½“ç±»å‹
        try:
            driver.execute_cdp_cmd('Emulation.setEmulatedMedia', {'media': 'print'})
        except Exception:
            pass
        
        # è·å–å¹¶æ¸…ç†é¡µé¢æ ‡é¢˜
        safe_title = _sanitize_title(driver.title)
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        out_dir = 'original_snapshot'
        os.makedirs(out_dir, exist_ok=True)
        
        # ç”ŸæˆPDF
        pdf_filename = f"{safe_title}_original.pdf"
        pdf_path = os.path.join(out_dir, pdf_filename)
        _print_to_pdf(driver, pdf_path, scale=0.9)
        
        return pdf_path, pdf_filename
        
    finally:
        # ç¡®ä¿å…³é—­æµè§ˆå™¨
        if driver:
            try:
                driver.quit()
            except Exception:
                pass

async def _capture_original_webpage_pdf_pyppeteer_async(url: str):
    """
    ä½¿ç”¨Pyppeteerï¼ˆå¼‚æ­¥ï¼‰ç”ŸæˆåŸå§‹ç½‘é¡µPDF
    """
    browser = await launch({
        'headless': True,
        'args': [
            '--no-sandbox',
            '--disable-setuid-sandbox',
            '--disable-gpu',
            '--allow-insecure-localhost',
            '--ignore-certificate-errors',
            '--lang=zh-CN,zh;q=0.9',  # ä½¿ç”¨ä¸­æ–‡è¯­è¨€è®¾ç½®
        ]
    })
    
    page = await browser.newPage()
    
    # è®¾ç½®è§†å£å¤§å°
    await page.setViewport({
        'width': 1280,
        'height': 800,
        'deviceScaleFactor': 1
    })
    
    log_message(f"[pyppeteer] æ‰“å¼€åŸå§‹ç½‘é¡µ: {url}", "DEBUG")
    
    # è®¿é—®é¡µé¢å¹¶ç­‰å¾…åŠ è½½å®Œæˆ
    await page.goto(url, {
        'waitUntil': 'networkidle2',  # ç­‰å¾…ç½‘ç»œç©ºé—²
        'timeout': 60000              # 60ç§’è¶…æ—¶
    })
    
    # å°è¯•ç­‰å¾…ä¸»ä½“å†…å®¹ç¨³å®š
    try:
        await page.waitForSelector('body', {'timeout': 20000})
    except Exception:
        pass
    
    # ä½¿ç”¨printåª’ä½“ç±»å‹ï¼ˆæ›´é€‚åˆPDFè¾“å‡ºï¼‰
    try:
        await page.emulateMediaType('print')
    except Exception:
        pass
    
    # è·å–å¹¶æ¸…ç†é¡µé¢æ ‡é¢˜
    safe_title = _sanitize_title(await page.title())
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    out_dir = 'original_snapshot'
    os.makedirs(out_dir, exist_ok=True)
    
    # ç”ŸæˆPDF
    pdf_filename = f"{safe_title}_original.pdf"
    pdf_path = os.path.join(out_dir, pdf_filename)
    
    await page.pdf({
        'path': pdf_path,
        'format': 'A4',
        'printBackground': True,
        'margin': {
            'top': '0.4in',
            'bottom': '0.4in',
            'left': '0.4in',
            'right': '0.4in'
        },
        'scale': 0.9
    })
    
    await browser.close()
    
    return pdf_path, pdf_filename

def _capture_original_webpage_pdf_pyppeteer(url: str):
    """
    Pyppeteerçš„åŒæ­¥åŒ…è£…å™¨
    """
    if not PYPPETEER_AVAILABLE:
        raise RuntimeError("Pyppeteer ä¸å¯ç”¨")
    
    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(
            _capture_original_webpage_pdf_pyppeteer_async(url)
        )
    finally:
        loop.close()

def _capture_google_translated_pdf(url: str) -> tuple:
    """
    æ‰“å¼€Googleç¿»è¯‘é¡µé¢å¹¶ç”ŸæˆPDF
    ä¼˜å…ˆä½¿ç”¨Pyppeteerï¼Œå¤±è´¥æ—¶å›é€€åˆ°Selenium
    
    å‚æ•°:
        url: è¦ç¿»è¯‘çš„åŸå§‹ç½‘é¡µURL
        
    è¿”å›:
        (pdf_path, pdf_filename): PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„å’Œæ–‡ä»¶å
        
    å¼‚å¸¸:
        å¯èƒ½æŠ›å‡ºå„ç§æµè§ˆå™¨ç›¸å…³çš„å¼‚å¸¸
    """
    # ä¼˜å…ˆå°è¯•ä½¿ç”¨Pyppeteerï¼ˆé€šå¸¸æ›´ç¨³å®šï¼‰
    if PYPPETEER_AVAILABLE:
        try:
            return _capture_google_translated_pdf_pyppeteer(url)
        except Exception as e:
            log_message(f"Pyppeteer è½¬ PDF å¤±è´¥ï¼Œå›é€€åˆ° Selenium: {str(e)}", "ERROR")
    
    # ä½¿ç”¨Seleniumä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
    driver = None
    try:
        # å¯åŠ¨Chromeæµè§ˆå™¨
        driver = _setup_chrome(disable_js=False)
        
        # æ„å»ºGoogleç¿»è¯‘URL
        translate_url = f"https://translate.google.com/translate?hl=en&sl=auto&tl=en&u={quote(url)}&prev=search"
        log_message(f"æ‰“å¼€Googleç¿»è¯‘åœ°å€: {translate_url}", "DEBUG")
        
        # è®¿é—®é¡µé¢
        driver.get(translate_url)
        
        # ç­‰å¾…é¡µé¢åŸºæœ¬åŠ è½½å®Œæˆ
        try:
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.TAG_NAME, 'body'))
            )
        except Exception:
            time.sleep(2)  # å…œåº•ç­‰å¾…
        
        # ç§»é™¤Googleç¿»è¯‘å·¥å…·æ 
        _hide_google_translate_toolbar(driver)
        
        # è®¾ç½®æ‰“å°åª’ä½“ç±»å‹
        try:
            driver.execute_cdp_cmd('Emulation.setEmulatedMedia', {'media': 'print'})
        except Exception:
            pass
        
        # è·å–å¹¶æ¸…ç†é¡µé¢æ ‡é¢˜
        safe_title = _sanitize_title(driver.title)
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        out_dir = 'translated_snapshot'
        os.makedirs(out_dir, exist_ok=True)
        
        # ç”ŸæˆPDF
        pdf_filename = f"{safe_title}.pdf"
        pdf_path = os.path.join(out_dir, pdf_filename)
        _print_to_pdf(driver, pdf_path, scale=0.9)
        
        return pdf_path, pdf_filename
        
    finally:
        # ç¡®ä¿å…³é—­æµè§ˆå™¨
        if driver:
            try:
                driver.quit()
            except Exception:
                pass

# ========== ç½‘å€ä¸Šä¼ æ¥å£ ==========


# ========== è®¤è¯ç›¸å…³APIï¼ˆå¤åˆ¶ä¹‹å‰çš„å®ç°ï¼‰========== 

@app.route('/api/auth/signup', methods=['POST'])
def signup():
    try:
        data = request.get_json()
        if not data or not all(k in data for k in ('name', 'email', 'password')):
            return jsonify({'success': False, 'error': 'è¯·æä¾›å§“åã€é‚®ç®±å’Œå¯†ç '}), 400
        
        name = data['name'].strip()
        email = data['email'].strip().lower()
        password = data['password']
        
        if len(name) < 2:
            return jsonify({'success': False, 'error': 'å§“åè‡³å°‘éœ€è¦2ä¸ªå­—ç¬¦'}), 400
        
        if len(password) < 6:
            return jsonify({'success': False, 'error': 'å¯†ç è‡³å°‘éœ€è¦6ä¸ªå­—ç¬¦'}), 400
        
        if User.query.filter_by(email=email).first():
            return jsonify({'success': False, 'error': 'è¯¥é‚®ç®±å·²è¢«æ³¨å†Œ'}), 400
        
        user = User(name=name, email=email)
        user.set_password(password)
        db.session.add(user)
        db.session.commit()
        
        access_token = create_access_token(identity=user.id)
        log_message(f"æ–°ç”¨æˆ·æ³¨å†ŒæˆåŠŸ: {user.email}", "SUCCESS")
        
        return jsonify({
            'success': True,
            'message': 'æ³¨å†ŒæˆåŠŸ',
            'user': user.to_dict(),
            'token': access_token
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({'success': False, 'error': 'æ³¨å†Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'}), 500

@app.route('/api/auth/signin', methods=['POST'])
def signin():
    try:
        data = request.get_json()
        if not data or not all(k in data for k in ('email', 'password')):
            return jsonify({'success': False, 'error': 'è¯·æä¾›é‚®ç®±å’Œå¯†ç '}), 400
        
        email = data['email'].strip().lower()
        password = data['password']
        
        user = User.query.filter_by(email=email).first()
        if not user or not user.check_password(password):
            return jsonify({'success': False, 'error': 'é‚®ç®±æˆ–å¯†ç é”™è¯¯'}), 401
        
        access_token = create_access_token(identity=user.id)
        log_message(f"ç”¨æˆ·ç™»å½•æˆåŠŸ: {user.email}", "SUCCESS")
        
        return jsonify({
            'success': True,
            'message': 'ç™»å½•æˆåŠŸ',
            'user': user.to_dict(),
            'token': access_token
        })
    except Exception as e:
        return jsonify({'success': False, 'error': 'ç™»å½•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'}), 500

@app.route('/api/auth/logout', methods=['POST'])
@jwt_required()
def logout():
    try:
        jti = get_jwt()['jti']
        blacklisted_tokens.add(jti)
        return jsonify({'success': True, 'message': 'ç™»å‡ºæˆåŠŸ'})
    except Exception as e:
        return jsonify({'success': False, 'error': 'ç™»å‡ºå¤±è´¥'}), 500

@app.route('/api/auth/user', methods=['GET'])
@jwt_required()
def get_current_user():
    try:
        user_id = get_jwt_identity()
        user = User.query.get(user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
        return jsonify({'success': True, 'user': user.to_dict()})
    except Exception as e:
        return jsonify({'success': False, 'error': 'è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥'}), 500

# ========== å®¢æˆ·ç®¡ç†ï¼ˆå¤åˆ¶ä¹‹å‰çš„å®ç°ï¼‰========== 

@app.route('/api/clients', methods=['GET'])
@jwt_required()
@cache_api_response('clients_list', timeout_seconds=300)  # ç¼“å­˜5åˆ†é’Ÿ
def get_clients():
    try:
        user_id = get_jwt_identity()
        # è·å–æŸ¥è¯¢å‚æ•°ï¼Œé»˜è®¤åªæ˜¾ç¤ºæœªå½’æ¡£çš„å®¢æˆ·
        include_archived = request.args.get('include_archived', 'false').lower() == 'true'
        
        # ä½¿ç”¨SQLAlchemy ORMï¼ˆå…ƒæ•°æ®å·²åˆ·æ–°ï¼‰
        if include_archived:
            clients = Client.query.filter_by(user_id=user_id).order_by(Client.created_at.desc()).all()
        else:
            clients = Client.query.filter(
                Client.user_id == user_id,
                (Client.is_archived == False) | (Client.is_archived.is_(None))
            ).order_by(Client.created_at.desc()).all()
        
        clients_data = [client.to_dict() for client in clients]
        
        return jsonify({'success': True, 'clients': clients_data})
        
    except Exception as e:
        print(f"è·å–å®¢æˆ·åˆ—è¡¨é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': 'è·å–å®¢æˆ·åˆ—è¡¨å¤±è´¥', 'details': str(e)}), 500

@app.route('/api/clients', methods=['POST'])
@jwt_required()
def add_client():
    try:
        user_id = get_jwt_identity()
        data = request.get_json()
        if not data or not data.get('name', '').strip():
            return jsonify({'success': False, 'error': 'è¯·æä¾›å®¢æˆ·å§“å'}), 400
        
        # ä½¿ç”¨SQLAlchemy ORMï¼ˆå…ƒæ•°æ®å·²åˆ·æ–°ï¼‰
        client = Client(
            name=data['name'].strip(),
            case_type=data.get('caseType', '').strip(),
            case_date=data.get('caseDate', '').strip(),
            phone=data.get('phone', '').strip() if data.get('phone') else None,
            email=data.get('email', '').strip() if data.get('email') else None,
            address=data.get('address', '').strip() if data.get('address') else None,
            notes=data.get('notes', '').strip() if data.get('notes') else None,
            user_id=user_id
        )
        db.session.add(client)
        db.session.commit()
        
        # ä½¿å®¢æˆ·åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_client_cache(user_id)
        
        return jsonify({'success': True, 'message': 'å®¢æˆ·æ·»åŠ æˆåŠŸ', 'client': client.to_dict()})
    except Exception as e:
        db.session.rollback()
        print(f"æ·»åŠ å®¢æˆ·é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': 'æ·»åŠ å®¢æˆ·å¤±è´¥', 'details': str(e)}), 500

@app.route('/api/clients/<client_id>', methods=['DELETE'])
@jwt_required()
def delete_client(client_id):
    """åˆ é™¤å®¢æˆ·"""
    try:
        user_id = get_jwt_identity()
        client = Client.query.filter_by(id=client_id, user_id=user_id).first()
        if not client:
            return jsonify({'success': False, 'error': 'å®¢æˆ·ä¸å­˜åœ¨'}), 404
        
        client_name = client.name
        
        # åˆ é™¤å®¢æˆ·ï¼ˆææ–™ä¼šå› ä¸ºå¤–é”®çº¦æŸè‡ªåŠ¨åˆ é™¤ï¼‰
        db.session.delete(client)
        db.session.commit()
        
        # ä½¿å®¢æˆ·åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_client_cache(user_id)
        # ä½¿ææ–™åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_materials_cache(client_id)
        
        log_message(f"å®¢æˆ·åˆ é™¤æˆåŠŸ: {client_name}", "SUCCESS")
        
        return jsonify({'success': True, 'message': f'å®¢æˆ· {client_name} åˆ é™¤æˆåŠŸ'})
    except Exception as e:
        db.session.rollback()
        log_message(f"åˆ é™¤å®¢æˆ·å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': 'åˆ é™¤å®¢æˆ·å¤±è´¥'}), 500

# ========== ææ–™ç®¡ç†ï¼ˆå¤åˆ¶ä¹‹å‰çš„å®ç°ï¼‰========== 

@app.route('/api/clients/<client_id>/materials', methods=['GET'])
@jwt_required()
def get_materials(client_id):
    try:
        user_id = get_jwt_identity()
        client = Client.query.filter_by(id=client_id, user_id=user_id).first()
        if not client:
            return jsonify({'success': False, 'error': 'å®¢æˆ·ä¸å­˜åœ¨'}), 404
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = cache_key_for_client_materials(client_id)
        cached_materials = api_cache.get(cache_key)
        if cached_materials is not None:
            log_message(f"ä»ç¼“å­˜è·å–ææ–™åˆ—è¡¨: å®¢æˆ·ID={client_id}", "INFO", is_polling=True)
            return jsonify({'success': True, 'materials': cached_materials})

        # å¼ºåˆ¶åˆ·æ–°ä¼šè¯ä»¥è·å–æœ€æ–°æ•°æ®
        db.session.expire_all()
        materials = Material.query.filter_by(client_id=client_id).order_by(Material.created_at.desc()).all()

        log_message(f"è·å–ææ–™åˆ—è¡¨: å®¢æˆ·ID={client_id}, æ‰¾åˆ°{len(materials)}ä¸ªææ–™", "INFO", is_polling=True)
        
        # åºåˆ—åŒ–ææ–™åˆ—è¡¨
        materials_data = []
        for material in materials:
            try:
                materials_data.append(material.to_dict())
            except Exception as dict_error:
                log_message(f"åºåˆ—åŒ–ææ–™å¤±è´¥: {material.id}, é”™è¯¯: {str(dict_error)}", "ERROR")
                import traceback
                traceback.print_exc()
                # è·³è¿‡è¿™ä¸ªææ–™ï¼Œç»§ç»­å¤„ç†å…¶ä»–çš„
                continue

        # ç¼“å­˜ç»“æœï¼Œææ–™åˆ—è¡¨ç¼“å­˜1åˆ†é’Ÿï¼ˆå®æ—¶æ€§è¦æ±‚é«˜ï¼‰
        api_cache.set(cache_key, materials_data, timeout_seconds=60)

        return jsonify({'success': True, 'materials': materials_data})
    except Exception as e:
        log_message(f"è·å–ææ–™åˆ—è¡¨å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'è·å–ææ–™åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/clients/<client_id>/materials/upload', methods=['POST'])
@jwt_required()
def upload_files(client_id):
    """æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    try:
        user_id = get_jwt_identity()
        client = Client.query.filter_by(id=client_id, user_id=user_id).first()
        if not client:
            return jsonify({'success': False, 'error': 'å®¢æˆ·ä¸å­˜åœ¨'}), 404
        
        if 'files' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}), 400
        
        files = request.files.getlist('files')
        if not files or all(file.filename == '' for file in files):
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        uploaded_materials = []

        for file in files:
            if file.filename:
                # ä¿å­˜æ–‡ä»¶
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_ext = Path(file.filename).suffix.lower()
                safe_filename = secure_filename(file.filename)
                filename = f"{timestamp}_{safe_filename}"
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)

                file.save(file_path)

                file_type = get_file_type(file.filename)

                # æ£€æµ‹PDFæ–‡ä»¶ï¼Œåˆ›å»ºå ä½è®°å½•åå°æ‹†åˆ†
                if file_ext == '.pdf' and PYMUPDF_AVAILABLE:
                    log_message(f"æ£€æµ‹åˆ°PDFæ–‡ä»¶: {file.filename}", "INFO")

                    try:
                        # å¿«é€Ÿè·å–é¡µæ•°
                        doc = fitz.open(file_path)
                        total_pages = len(doc)
                        doc.close()

                        # åˆ›å»ºPDFä¼šè¯ID
                        pdf_session_id = f"pdf_{timestamp}_{uuid.uuid4().hex[:8]}"

                        # ç«‹å³åˆ›å»ºå ä½Materialè®°å½•ï¼ˆæ˜¾ç¤º"æ‹†åˆ†ä¸­"ï¼‰
                        log_message(f"PDFå…±æœ‰ {total_pages} é¡µï¼Œåˆ›å»ºå ä½è®°å½•", "INFO")
                        for page_num in range(total_pages):
                            page_material = Material(
                                name=f"{file.filename} - ç¬¬{page_num + 1}é¡µ",
                                type='image',
                                original_filename=f"{file.filename}_page_{page_num + 1}",
                                file_path=file_path,  # æš‚æ—¶æŒ‡å‘åŸPDF
                                status=get_legacy_status(ProcessingStep.SPLITTING.value),
                                client_id=client_id,
                                pdf_session_id=pdf_session_id,
                                pdf_page_number=page_num + 1,
                                pdf_total_pages=total_pages,
                                pdf_original_file=file_path,
                                processing_step=ProcessingStep.SPLITTING.value,
                                processing_progress=0  # 0%å¼€å§‹
                            )
                            db.session.add(page_material)
                            uploaded_materials.append(page_material)

                        # ç«‹å³æäº¤ï¼Œè®©å‰ç«¯çœ‹åˆ°
                        db.session.commit()
                        log_message(f"âœ“ å·²åˆ›å»º {total_pages} ä¸ªå ä½è®°å½•", "SUCCESS")

                        # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†PDFæ‹†åˆ†+ç¿»è¯‘
                        import threading
                        from concurrent.futures import ThreadPoolExecutor, as_completed

                        def process_pdf_async(pdf_file_path, session_id, client_id):
                            """åå°æ‹†åˆ†PDFå¹¶ç¿»è¯‘"""
                            try:
                                with app.app_context():
                                    # åˆ›å»ºä¼šè¯ç›®å½•
                                    session_dir = os.path.join(app.root_path, 'uploads', 'pdf_sessions', session_id)
                                    os.makedirs(session_dir, exist_ok=True)

                                    # æ‰“å¼€PDF
                                    doc = fitz.open(pdf_file_path)
                                    total_pages = len(doc)

                                    # æ‹†åˆ†æ¯ä¸€é¡µ
                                    for page_num in range(total_pages):
                                        page = doc[page_num]

                                        # è½¬æ¢ä¸ºå›¾ç‰‡ï¼Œé™åˆ¶åˆ†è¾¨ç‡ï¼ˆé™ä½åˆ°3000pxä»¥æé«˜ç¨³å®šæ€§ï¼‰
                                        page_rect = page.rect
                                        page_width = page_rect.width
                                        page_height = page_rect.height

                                        # è®¡ç®—zoomï¼Œç¡®ä¿æœ€é•¿è¾¹ä¸è¶…è¿‡3000pxï¼ˆé™ä½åˆ†è¾¨ç‡æé«˜ç¨³å®šæ€§ï¼‰
                                        max_dimension = max(page_width, page_height)
                                        max_allowed = 3000  # ä»4096é™ä½åˆ°3000

                                        if max_dimension * 2.0 > max_allowed:
                                            # å¦‚æœ2å€ä¼šè¶…æ ‡ï¼ŒæŒ‰æ¯”ä¾‹ç¼©å°
                                            zoom = max_allowed / max_dimension * 0.9  # ç•™10%ä½™é‡
                                        else:
                                            zoom = 2.0  # é»˜è®¤2å€é«˜æ¸…

                                        mat = fitz.Matrix(zoom, zoom)
                                        pix = page.get_pixmap(matrix=mat)

                                        log_message(f"ç¬¬ {page_num + 1} é¡µå°ºå¯¸: {int(pix.width)}x{int(pix.height)}px (zoom={zoom:.2f})", "DEBUG")

                                        # ä¿å­˜å›¾ç‰‡
                                        img_filename = f"page_{page_num + 1}.png"
                                        img_path = os.path.join(session_dir, img_filename)
                                        pix.save(img_path)

                                        # åŠ å¼ºå‹ç¼©ï¼šç›®æ ‡2MBï¼Œåˆ†è¾¨ç‡3000px
                                        try:
                                            from PIL import Image
                                            file_size = os.path.getsize(img_path)
                                            max_size = 2 * 1024 * 1024  # é™ä½åˆ°2MBï¼Œæé«˜ä¸Šä¼ ç¨³å®šæ€§

                                            img = Image.open(img_path)

                                            # å†æ¬¡æ£€æŸ¥å°ºå¯¸ï¼ˆé™ä½åˆ°3000pxï¼‰
                                            if max(img.width, img.height) > 3000:
                                                # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                                                scale = 2800 / max(img.width, img.height)  # ç›®æ ‡2800px
                                                new_width = int(img.width * scale)
                                                new_height = int(img.height * scale)
                                                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                                                log_message(f"ç¬¬ {page_num + 1} é¡µç¼©æ”¾åˆ°: {new_width}x{new_height}px", "INFO")

                                            if img.mode == 'RGBA':
                                                img = img.convert('RGB')

                                            jpg_path = img_path.replace('.png', '.jpg')

                                            # æ— è®ºæ–‡ä»¶å¤§å°ï¼Œéƒ½è¿›è¡Œå‹ç¼©ä»¥æé«˜ç¨³å®šæ€§
                                            if file_size > max_size:
                                                # äºŒåˆ†æŸ¥æ‰¾æœ€ä½³è´¨é‡ï¼ˆé™ä½èŒƒå›´ï¼‰
                                                low, high = 10, 85  # ä»95é™åˆ°85
                                                best_quality = low

                                                while low <= high:
                                                    mid = (low + high) // 2
                                                    img.save(jpg_path, 'JPEG', quality=mid, optimize=True)
                                                    current_size = os.path.getsize(jpg_path)

                                                    if current_size <= max_size:
                                                        best_quality = mid
                                                        low = mid + 1
                                                    else:
                                                        high = mid - 1

                                                img.save(jpg_path, 'JPEG', quality=best_quality, optimize=True)
                                                final_size = os.path.getsize(jpg_path)

                                                if final_size <= max_size:
                                                    # â­ å®‰å…¨åˆ é™¤ï¼šç¡®ä¿ä¸æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                                                    if img_path != jpg_path and os.path.exists(img_path):
                                                        os.remove(img_path)
                                                    img_path = jpg_path
                                                    log_message(f"âœ“ ç¬¬ {page_num + 1} é¡µå‹ç¼©å®Œæˆ: {final_size / 1024 / 1024:.2f}MB (è´¨é‡: {best_quality})", "SUCCESS")
                                                else:
                                                    try:
                                                        if os.path.exists(jpg_path) and jpg_path != img_path:
                                                            os.remove(jpg_path)
                                                    except:
                                                        pass
                                                    raise Exception(f"ç¬¬ {page_num + 1} é¡µå›¾ç‰‡è¿‡å¤§")
                                            else:
                                                # æ–‡ä»¶è¾ƒå°ï¼Œä½†ä»å‹ç¼©åˆ°åˆç†è´¨é‡ï¼ˆæé«˜ç¨³å®šæ€§ï¼‰
                                                img.save(jpg_path, 'JPEG', quality=75, optimize=True)  # ä»95é™åˆ°75
                                                # â­ å®‰å…¨åˆ é™¤ï¼šç¡®ä¿ä¸æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                                                if img_path != jpg_path and os.path.exists(img_path):
                                                    os.remove(img_path)
                                                img_path = jpg_path
                                                final_size = os.path.getsize(jpg_path)
                                                log_message(f"âœ“ ç¬¬ {page_num + 1} é¡µè½¬æ¢å®Œæˆ: {final_size / 1024 / 1024:.2f}MB", "SUCCESS")

                                        except Exception as compress_error:
                                            log_message(f"ç¬¬ {page_num + 1} é¡µå‹ç¼©å¤±è´¥: {str(compress_error)}", "WARNING")

                                        # æ›´æ–°Materialè®°å½•çš„æ–‡ä»¶è·¯å¾„å’ŒçŠ¶æ€
                                        page_material = Material.query.filter_by(
                                            pdf_session_id=session_id,
                                            pdf_page_number=page_num + 1
                                        ).first()

                                        if page_material:
                                            # å­˜å‚¨ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
                                            relative_path = os.path.relpath(img_path, app.root_path)
                                            page_material.file_path = relative_path
                                            page_material.status = get_legacy_status(ProcessingStep.SPLIT_COMPLETED.value)
                                            page_material.processing_step = ProcessingStep.SPLIT_COMPLETED.value
                                            page_material.processing_progress = 100  # æ‹†åˆ†å®Œæˆ
                                            db.session.commit()

                                            # æ¨é€WebSocketæ›´æ–°ï¼Œé€šçŸ¥å‰ç«¯æ‹†åˆ†å®Œæˆ
                                            if WEBSOCKET_ENABLED:
                                                emit_material_updated(
                                                    client_id,
                                                    material_id=page_material.id,
                                                    status=page_material.status,
                                                    processing_step=page_material.processing_step,
                                                    processing_progress=page_material.processing_progress,
                                                    file_path=page_material.file_path
                                                )

                                        log_message(f"âœ“ ç¬¬ {page_num + 1} é¡µå·²æ‹†åˆ†", "SUCCESS")

                                    doc.close()
                                    log_message(f"âœ“ PDFæ‹†åˆ†å®Œæˆ: {total_pages} é¡µï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨å¼€å§‹ç¿»è¯‘", "SUCCESS")

                            except Exception as e:
                                log_message(f"PDFå¤„ç†å¼‚å¸¸: {str(e)}", "ERROR")

                        # å¯åŠ¨åå°ä»»åŠ¡
                        bg_thread = threading.Thread(
                            target=process_pdf_async,
                            args=(file_path, pdf_session_id, client_id),
                            daemon=True
                        )
                        bg_thread.start()
                        log_message(f"âœ“ åå°ä»»åŠ¡å·²å¯åŠ¨", "SUCCESS")

                    except Exception as e:
                        log_message(f"PDFå¤„ç†å¤±è´¥: {str(e)}", "ERROR")
                        db.session.rollback()
                        # å¤±è´¥æ—¶åˆ›å»ºæ™®é€šè®°å½•
                        material = Material(
                            name=file.filename,
                            type=file_type,
                            original_filename=file.filename,
                            file_path=file_path,
                            status=get_legacy_status(ProcessingStep.UPLOADED.value),
                            processing_step=ProcessingStep.UPLOADED.value,
                            client_id=client_id
                        )
                        db.session.add(material)
                        uploaded_materials.append(material)
                else:
                    # éPDFæ–‡ä»¶æˆ–PDFåº“ä¸å¯ç”¨ï¼Œæ­£å¸¸å¤„ç†
                    # å¦‚æœæ˜¯å›¾ç‰‡ï¼ŒåŠ å¼ºå‹ç¼©
                    if file_type == 'image':
                        try:
                            from PIL import Image
                            img = Image.open(file_path)

                            log_message(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: {img.width}x{img.height}px", "DEBUG")

                            # é™åˆ¶åˆ†è¾¨ç‡åˆ°3000pxï¼ˆé™ä½ä»¥æé«˜ç¨³å®šæ€§ï¼‰
                            if max(img.width, img.height) > 3000:
                                scale = 2800 / max(img.width, img.height)  # ç›®æ ‡2800px
                                new_width = int(img.width * scale)
                                new_height = int(img.height * scale)
                                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                                log_message(f"å›¾ç‰‡å·²ç¼©æ”¾åˆ°: {new_width}x{new_height}px", "INFO")

                            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯RGBAï¼‰
                            if img.mode == 'RGBA':
                                img = img.convert('RGB')

                            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™ä½åˆ°2MBï¼‰
                            file_size = os.path.getsize(file_path)
                            max_size = 2 * 1024 * 1024  # é™ä½åˆ°2MB

                            # æ— è®ºä»€ä¹ˆæƒ…å†µéƒ½è½¬æ¢å¹¶å‹ç¼©
                            # â­ ä¿®å¤ï¼šé¿å…jpg_pathå’Œfile_pathç›¸åŒå¯¼è‡´æ–‡ä»¶è¢«åˆ é™¤
                            base_path = file_path.rsplit('.', 1)[0]
                            original_ext = file_path.rsplit('.', 1)[1] if '.' in file_path else ''

                            # å¦‚æœåŸæ–‡ä»¶å·²ç»æ˜¯jpgï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åé¿å…è¦†ç›–
                            if original_ext.lower() in ['jpg', 'jpeg']:
                                jpg_path = base_path + '_compressed.jpg'
                            else:
                                jpg_path = base_path + '.jpg'

                            if file_size > max_size:
                                # éœ€è¦å‹ç¼©ï¼šäºŒåˆ†æŸ¥æ‰¾æœ€ä½³è´¨é‡
                                log_message(f"å›¾ç‰‡è¿‡å¤§ ({file_size / 1024 / 1024:.2f}MB)ï¼Œå¼€å§‹å‹ç¼©", "INFO")
                                low, high = 10, 85  # é™ä½è´¨é‡ä¸Šé™
                                best_quality = low

                                while low <= high:
                                    mid = (low + high) // 2
                                    img.save(jpg_path, 'JPEG', quality=mid, optimize=True)
                                    current_size = os.path.getsize(jpg_path)

                                    if current_size <= max_size:
                                        best_quality = mid
                                        low = mid + 1
                                    else:
                                        high = mid - 1

                                img.save(jpg_path, 'JPEG', quality=best_quality, optimize=True)
                                final_size = os.path.getsize(jpg_path)

                                if final_size <= max_size:
                                    # â­ å®‰å…¨åˆ é™¤ï¼šç¡®ä¿ä¸æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                                    if file_path != jpg_path and os.path.exists(file_path):
                                        os.remove(file_path)
                                    file_path = jpg_path
                                    log_message(f"âœ“ å‹ç¼©å®Œæˆ: {final_size / 1024 / 1024:.2f}MB (è´¨é‡: {best_quality})", "SUCCESS")
                                else:
                                    if os.path.exists(jpg_path) and jpg_path != file_path:
                                        os.remove(jpg_path)
                                    raise Exception(f"å›¾ç‰‡å‹ç¼©å¤±è´¥ï¼Œä»è¶…è¿‡2MBé™åˆ¶")
                            else:
                                # æ–‡ä»¶è¾ƒå°ï¼Œä½†ä»å‹ç¼©åˆ°åˆç†è´¨é‡
                                img.save(jpg_path, 'JPEG', quality=75, optimize=True)
                                # â­ å®‰å…¨åˆ é™¤ï¼šç¡®ä¿ä¸æ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                                if file_path != jpg_path and os.path.exists(file_path):
                                    os.remove(file_path)
                                file_path = jpg_path
                                final_size = os.path.getsize(jpg_path)
                                log_message(f"âœ“ å‹ç¼©å®Œæˆ: {final_size / 1024 / 1024:.2f}MB", "SUCCESS")

                        except Exception as img_error:
                            log_message(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(img_error)}", "WARNING")

                    material = Material(
                        name=file.filename,
                        type=file_type,
                        original_filename=file.filename,
                        file_path=file_path,
                        status=get_legacy_status(ProcessingStep.UPLOADED.value),
                        client_id=client_id,
                        processing_step=ProcessingStep.UPLOADED.value,
                        processing_progress=0
                    )
                    db.session.add(material)
                    uploaded_materials.append(material)

        db.session.commit()

        # ä½¿ææ–™åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_materials_cache(client_id)

        # âŒ ä¸åœ¨ä¸Šä¼ æ—¶è‡ªåŠ¨ç¿»è¯‘ï¼Œç­‰å¾…å‰ç«¯è°ƒç”¨ start_translation
        # ä¸Šä¼ æ—¶åªè®¾ç½®çŠ¶æ€ä¸º 'å¤„ç†ä¸­'ï¼Œç¿»è¯‘åœ¨ start_translation API ä¸­è¿›è¡Œ

        log_message(f"æˆåŠŸä¸Šä¼  {len(uploaded_materials)} ä¸ªæ–‡ä»¶", "SUCCESS")
        
        return jsonify({
            'success': True,
            'message': f'æˆåŠŸä¸Šä¼  {len(uploaded_materials)} ä¸ªæ–‡ä»¶',
            'materials': [material.to_dict() for material in uploaded_materials]
        })
        
    except Exception as e:
        db.session.rollback()
        log_message(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸Šä¼ å¤±è´¥'}), 500

@app.route('/api/clients/<client_id>/materials/urls', methods=['POST'])
@jwt_required()
def upload_urls(client_id):
    try:
        user_id = get_jwt_identity()
        client = Client.query.filter_by(id=client_id, user_id=user_id).first()
        if not client:
            return jsonify({'success': False, 'error': 'å®¢æˆ·ä¸å­˜åœ¨'}), 404
        
        data = request.get_json()
        if not data or not data.get('urls'):
            return jsonify({'success': False, 'error': 'è¯·æä¾›ç½‘é¡µURL'}), 400
        
        urls = data['urls']
        uploaded_materials = []
        
        for url in urls:
            if url.strip():
                # è·å–ç½‘é¡µæ ‡é¢˜
                title = url.strip()  # é»˜è®¤ä½¿ç”¨URL
                try:
                    response = requests.get(url.strip(), timeout=10, headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'html.parser')
                        if soup.title and soup.title.string:
                            title = soup.title.string.strip().replace('\n', ' ')[:100]
                except Exception as e:
                    log_message(f"è·å–ç½‘é¡µæ ‡é¢˜å¤±è´¥: {url} - {str(e)}", "WARNING")
                
                material = Material(
                    name=title,  # ä½¿ç”¨ç½‘é¡µæ ‡é¢˜
                    type='webpage',
                    url=url.strip(),
                    status=get_legacy_status(ProcessingStep.UPLOADED.value),
                    processing_step=ProcessingStep.UPLOADED.value,
                    client_id=client_id
                )
                db.session.add(material)
                uploaded_materials.append(material)
        
        db.session.commit()

        # ä½¿ææ–™åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_materials_cache(client_id)

        # âœ… ç½‘é¡µè‡ªåŠ¨ç¿»è¯‘ - å¼‚æ­¥å¤„ç†
        material_ids = [m.id for m in uploaded_materials]
        log_message(f"ç½‘é¡µæ·»åŠ æˆåŠŸï¼Œå¯åŠ¨è‡ªåŠ¨ç¿»è¯‘ä»»åŠ¡: {len(material_ids)} ä¸ªç½‘é¡µ", "INFO")

        import threading

        def auto_translate_webpages():
            """åå°è‡ªåŠ¨ç¿»è¯‘ç½‘é¡µ"""
            with app.app_context():
                for mat_id in material_ids:
                    try:
                        material = db.session.get(Material, mat_id)
                        if not material:
                            continue

                        log_message(f"å¼€å§‹è‡ªåŠ¨ç¿»è¯‘ç½‘é¡µ: {material.name}", "INFO")

                        # æ›´æ–°çŠ¶æ€ä¸ºç¿»è¯‘ä¸­
                        material.status = MaterialStatus.TRANSLATING
                        db.session.commit()

                        # WebSocketæ¨é€
                        if WEBSOCKET_ENABLED:
                            emit_translation_started(client_id, material.id, f"å¼€å§‹ç¿»è¯‘ç½‘é¡µ {material.name}")

                        try:
                            # 1. ç”ŸæˆåŸå§‹ç½‘é¡µPDF
                            log_message(f"ç”ŸæˆåŸå§‹ç½‘é¡µPDF: {material.name}", "INFO")
                            original_pdf_path, original_pdf_filename = _capture_original_webpage_pdf(material.url)
                            material.original_pdf_path = original_pdf_filename

                            # 2. ç”ŸæˆGoogleç¿»è¯‘PDF
                            log_message(f"ç”Ÿæˆç¿»è¯‘ç½‘é¡µPDF: {material.name}", "INFO")
                            pdf_path, pdf_filename = _capture_google_translated_pdf(material.url)

                            # æ›´æ–°çŠ¶æ€ä¸ºç¿»è¯‘å®Œæˆ
                            update_material_status(
                                material,
                                MaterialStatus.TRANSLATED,
                                translated_image_path=pdf_filename,
                                translation_error=None,
                                processing_progress=100
                            )

                            log_message(f"ç½‘é¡µè‡ªåŠ¨ç¿»è¯‘å®Œæˆ: {material.name}", "SUCCESS")

                        except Exception as e:
                            update_material_status(
                                material,
                                MaterialStatus.FAILED,
                                translation_error=str(e)
                            )
                            log_message(f"ç½‘é¡µè‡ªåŠ¨ç¿»è¯‘å¤±è´¥: {material.name} - {str(e)}", "ERROR")
                            import traceback
                            traceback.print_exc()

                    except Exception as e:
                        log_message(f"ç½‘é¡µç¿»è¯‘å¼‚å¸¸: {str(e)}", "ERROR")
                        import traceback
                        traceback.print_exc()

        # å¯åŠ¨åå°ç¿»è¯‘çº¿ç¨‹
        thread = threading.Thread(target=auto_translate_webpages)
        thread.daemon = True
        thread.start()

        return jsonify({
            'success': True,
            'message': f'æˆåŠŸæ·»åŠ  {len(uploaded_materials)} ä¸ªç½‘é¡µï¼Œæ­£åœ¨è‡ªåŠ¨ç¿»è¯‘...',
            'materials': [material.to_dict() for material in uploaded_materials]
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({'success': False, 'error': 'ç½‘é¡µæ·»åŠ å¤±è´¥'}), 500

@app.route('/api/materials/<material_id>', methods=['GET'])
@jwt_required()
def get_material(material_id):
    """è·å–å•ä¸ªææ–™çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        user_id = get_jwt_identity()

        # é€šè¿‡materialæ‰¾åˆ°clientï¼ŒéªŒè¯ç”¨æˆ·æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨æˆ–æ— æƒé™'}), 404

        # è¿”å›ææ–™çš„å®Œæ•´ä¿¡æ¯
        return jsonify({
            'success': True,
            'material': material.to_dict()
        })
    except Exception as e:
        log_message(f"è·å–ææ–™è¯¦æƒ…å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': 'è·å–ææ–™è¯¦æƒ…å¤±è´¥'}), 500

@app.route('/api/materials/<material_id>', methods=['DELETE'])
@jwt_required()
def delete_material(material_id):
    """åˆ é™¤ææ–™"""
    try:
        user_id = get_jwt_identity()

        # é€šè¿‡materialæ‰¾åˆ°clientï¼ŒéªŒè¯ç”¨æˆ·æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨æˆ–æ— æƒé™'}), 404
        
        # ä¿å­˜client_idä»¥ä¾¿åç»­ä½¿ç”¨
        client_id = material.client_id
        material_name = material.name
        
        # åˆ é™¤å…³è”çš„æ–‡ä»¶
        if material.file_path and os.path.exists(material.file_path):
            try:
                os.remove(material.file_path)
                log_message(f"åˆ é™¤æ–‡ä»¶: {material.file_path}", "INFO")
            except Exception as e:
                log_message(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {material.file_path} - {str(e)}", "WARNING")
        
        # åˆ é™¤æ•°æ®åº“è®°å½•
        db.session.delete(material)
        db.session.commit()
        
        # ä½¿ææ–™åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_materials_cache(client_id)
        
        log_message(f"ææ–™åˆ é™¤æˆåŠŸ: {material_name}", "SUCCESS")
        
        return jsonify({'success': True, 'message': f'ææ–™ {material_name} åˆ é™¤æˆåŠŸ'})
    except Exception as e:
        db.session.rollback()
        log_message(f"åˆ é™¤ææ–™å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': 'åˆ é™¤ææ–™å¤±è´¥'}), 500

@app.route('/api/clients/<client_id>/materials/translate', methods=['POST'])
@jwt_required()
def start_translation(client_id):
    """å¼€å§‹ç¿»è¯‘å®¢æˆ·çš„ææ–™ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰

    è¯·æ±‚ä½“ï¼ˆå¯é€‰ï¼‰:
    {
        "material_ids": ["id1", "id2"]  // å¦‚æœæä¾›ï¼Œåªç¿»è¯‘æŒ‡å®šçš„ææ–™ï¼›å¦åˆ™ç¿»è¯‘æ‰€æœ‰ææ–™
    }
    """
    try:
        user_id = get_jwt_identity()
        client = Client.query.filter_by(id=client_id, user_id=user_id).first()
        if not client:
            return jsonify({'success': False, 'error': 'å®¢æˆ·ä¸å­˜åœ¨'}), 404

        # ğŸ”§ ä¿®å¤ï¼šæ”¯æŒåªç¿»è¯‘æŒ‡å®šçš„ææ–™
        # ä½¿ç”¨silent=Trueé¿å…Content-Typeé”™è¯¯
        data = request.get_json(silent=True) or {}
        requested_material_ids = data.get('material_ids', [])

        if requested_material_ids:
            # åªç¿»è¯‘æŒ‡å®šçš„ææ–™
            log_message(f"æ”¶åˆ°ç¿»è¯‘è¯·æ±‚ï¼ŒæŒ‡å®šææ–™ID: {requested_material_ids}", "INFO")
            materials = Material.query.filter(
                Material.client_id == client_id,
                Material.id.in_(requested_material_ids),
                Material.type.in_(['image', 'webpage'])
            ).all()
        else:
            # ç¿»è¯‘æ‰€æœ‰ææ–™ï¼ˆåŸæœ‰è¡Œä¸ºï¼‰
            log_message(f"æ”¶åˆ°ç¿»è¯‘è¯·æ±‚ï¼Œç¿»è¯‘æ‰€æœ‰ææ–™", "INFO")
            materials = Material.query.filter(
                Material.client_id == client_id,
                Material.type.in_(['image', 'webpage'])
            ).all()

        # ç­›é€‰éœ€è¦ç¿»è¯‘çš„ææ–™ï¼ˆIDåˆ—è¡¨ï¼Œé¿å…åœ¨å¼‚æ­¥ä¸­ä½¿ç”¨å¯¹è±¡ï¼‰
        material_ids_to_translate = [m.id for m in materials if m.status in ['å·²ä¸Šä¼ ', 'å·²æ·»åŠ ', 'å¤„ç†ä¸­']]
        
        log_message(f"æ‰¾åˆ° {len(materials)} ä¸ªææ–™ï¼Œå…¶ä¸­ {len(material_ids_to_translate)} ä¸ªéœ€è¦ç¿»è¯‘", "INFO")
        
        if not material_ids_to_translate:
            return jsonify({
                'success': True,
                'message': 'æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„ææ–™',
                'translated_count': 0,
                'failed_count': 0,
                'translated_materials': []
            })
        
        # âœ… ä½¿ç”¨æ™®é€šçº¿ç¨‹å¼‚æ­¥ç¿»è¯‘ï¼ˆgeventä¼šè‡ªåŠ¨å¤„ç†ï¼‰
        import threading
        
        def translate_one_material(material_id):
            """ç¿»è¯‘å•ä¸ªææ–™"""
            print(f"[TRANSLATE] å¼€å§‹ç¿»è¯‘ææ–™: {material_id}", flush=True)
            with app.app_context():
                try:
                    # âœ… æ£€æŸ¥ç¿»è¯‘é”ï¼Œé˜²æ­¢é‡å¤ç¿»è¯‘
                    print(f"[TRANSLATE] æ£€æŸ¥ç¿»è¯‘é”: {material_id}", flush=True)
                    is_locked, locked_material = check_translation_lock(material_id)
                    if is_locked:
                        print(f"[TRANSLATE] ææ–™æ­£åœ¨ç¿»è¯‘ä¸­ï¼Œè·³è¿‡: {material_id}", flush=True)
                        log_message(f"ææ–™æ­£åœ¨ç¿»è¯‘ä¸­ï¼Œè·³è¿‡: {material_id}", "WARN")
                        return {'success': False, 'error': 'è¯¥ææ–™æ­£åœ¨ç¿»è¯‘ä¸­', 'skipped': True}

                    print(f"[TRANSLATE] æŸ¥è¯¢ææ–™: {material_id}", flush=True)
                    material = db.session.get(Material, material_id)
                    if not material:
                        print(f"[TRANSLATE] ææ–™ä¸å­˜åœ¨: {material_id}", flush=True)
                        return {'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}

                    print(f"[TRANSLATE] ææ–™åç§°: {material.name}, ç±»å‹: {material.type}, çŠ¶æ€: {material.status}", flush=True)
                    
                    # ç½‘é¡µç±»å‹çš„ç‰¹æ®Šå¤„ç†
                    if material.type == 'webpage':
                        log_message(f"å¼€å§‹ç½‘é¡µç¿»è¯‘: {material.name}", "INFO")
                        
                        # âœ… WebSocket æ¨é€ï¼šç¿»è¯‘å¼€å§‹
                        if WEBSOCKET_ENABLED:
                            emit_translation_started(client_id, material.id, f"å¼€å§‹ç¿»è¯‘ç½‘é¡µ {material.name}")
                        
                        try:
                            # 1. å…ˆç”ŸæˆåŸå§‹ç½‘é¡µçš„PDF
                            log_message(f"ç”ŸæˆåŸå§‹ç½‘é¡µPDF: {material.name}", "INFO")
                            original_pdf_path, original_pdf_filename = _capture_original_webpage_pdf(material.url)
                            material.original_pdf_path = original_pdf_filename
                            
                            # 2. ç”ŸæˆGoogleç¿»è¯‘çš„PDF
                            log_message(f"ç”Ÿæˆç¿»è¯‘ç½‘é¡µPDF: {material.name}", "INFO")
                            pdf_path, pdf_filename = _capture_google_translated_pdf(material.url)

                            # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
                            update_material_status(
                                material,
                                MaterialStatus.TRANSLATED,
                                translated_image_path=pdf_filename,
                                translation_error=None,
                                processing_progress=100
                            )

                            log_message(f"ç½‘é¡µç¿»è¯‘å®Œæˆ: {material.name}", "SUCCESS")

                            return {'success': True}
                            
                        except Exception as e:
                            # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
                            update_material_status(
                                material,
                                MaterialStatus.FAILED,
                                translation_error=str(e)
                            )
                            log_message(f"ç½‘é¡µç¿»è¯‘å¤±è´¥: {material.name} - {str(e)}", "ERROR")

                            return {'success': False, 'error': str(e)}
                    
                    # å›¾ç‰‡ç¿»è¯‘ï¼ˆç™¾åº¦APIï¼‰
                    print(f"[TRANSLATE] å¼€å§‹ç™¾åº¦ç¿»è¯‘: {material.name}", flush=True)
                    log_message(f"å¼€å§‹ç™¾åº¦ç¿»è¯‘: {material.name}", "INFO")
                    
                    # âœ… WebSocket æ¨é€ï¼šç¿»è¯‘å¼€å§‹
                    if WEBSOCKET_ENABLED:
                        print(f"[TRANSLATE] å‘é€ç¿»è¯‘å¼€å§‹äº‹ä»¶", flush=True)
                        emit_translation_started(client_id, material.id, f"å¼€å§‹ç¿»è¯‘ {material.name}")

                    try:
                        print(f"[TRANSLATE] è°ƒç”¨ translate_image_reference: {material.file_path}", flush=True)
                        # è°ƒç”¨ç™¾åº¦ç¿»è¯‘
                        result = translate_image_reference(
                            image_path=material.file_path,
                            source_lang='zh',
                            target_lang='en'
                        )
                        print(f"[TRANSLATE] ç™¾åº¦APIè¿”å›ï¼Œç»“æœé•¿åº¦: {len(str(result))}", flush=True)

                        # æ£€æŸ¥APIé”™è¯¯
                        error_code = result.get('error_code')
                        if error_code and error_code not in [0, '0', None]:
                            error_msg = result.get('error_msg', 'ç¿»è¯‘å¤±è´¥')
                            log_message(f"ç™¾åº¦APIé”™è¯¯: {material.name} - {error_msg}", "ERROR")
                            # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
                            update_material_status(
                                material,
                                MaterialStatus.FAILED,
                                translation_error=error_msg
                            )

                            return {'success': False, 'error': error_msg}

                        # è§£æregionsæ•°æ®
                        data = result.get('data', {})
                        content = data.get('content', [])

                        if not content:
                            log_message(f"ç™¾åº¦ç¿»è¯‘æœªè¯†åˆ«åˆ°æ–‡å­—: {material.name}", "WARN")
                            # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
                            update_material_status(
                                material,
                                MaterialStatus.FAILED,
                                translation_error='æœªè¯†åˆ«åˆ°æ–‡å­—åŒºåŸŸ'
                            )

                            return {'success': False, 'error': 'æœªè¯†åˆ«åˆ°æ–‡å­—åŒºåŸŸ'}

                        # æ„å»ºregionsæ ¼å¼
                        regions = [
                            {
                                'id': i,
                                'src': item.get('src', ''),
                                'dst': item.get('dst', ''),
                                'points': item.get('points', []),
                                'lineCount': item.get('lineCount', 1)
                            } for i, item in enumerate(content)
                        ]

                        # æ„å»ºå®Œæ•´çš„ç¿»è¯‘æ•°æ®ç»“æ„
                        translation_data = {
                            'regions': regions,
                            'sourceLang': data.get('from', 'zh'),
                            'targetLang': data.get('to', 'en'),
                            'statistics': {
                                'totalRegions': len(regions),
                                'totalSrcChars': sum(len(r['src']) for r in regions),
                                'totalDstChars': sum(len(r['dst']) for r in regions),
                                'translationRatio': sum(len(r['dst']) for r in regions) / sum(len(r['src']) for r in regions) if sum(len(r['src']) for r in regions) > 0 else 1
                            }
                        }

                        # ä¿å­˜ç¿»è¯‘æ•°æ®
                        # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
                        update_material_status(
                            material,
                            MaterialStatus.TRANSLATED,
                            translation_text_info=translation_data,
                            translation_error=None,
                            processing_step=ProcessingStep.TRANSLATED.value,  # ğŸ”§ ä¿®å¤ï¼šè®¾ç½®processing_step
                            processing_progress=100
                        )

                        log_message(f"ç™¾åº¦ç¿»è¯‘å®Œæˆ: {material.name}, è¯†åˆ«åˆ° {len(regions)} ä¸ªåŒºåŸŸ", "SUCCESS")

                        # å¦‚æœå¯ç”¨äº†å®ä½“è¯†åˆ«ï¼Œè‡ªåŠ¨è§¦å‘å®ä½“è¯†åˆ«
                        if material.entity_recognition_enabled:
                            # æ£€æŸ¥æ˜¯å¦ä¸ºPDF Session
                            if material.pdf_session_id:
                                log_message(f"æ£€æµ‹åˆ°PDF Session: {material.pdf_session_id}ï¼Œæ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¡µé¢å·²å®ŒæˆOCR", "INFO")

                                # è·å–è¯¥PDF Sessionçš„æ‰€æœ‰é¡µé¢
                                all_pages = Material.query.filter_by(pdf_session_id=material.pdf_session_id).all()

                                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¡µé¢éƒ½å®Œæˆäº†OCR
                                all_completed = all(p.translation_text_info for p in all_pages)

                                if all_completed:
                                    # æ£€æŸ¥æ˜¯å¦å·²ç»è§¦å‘è¿‡PDFæ•´ä½“è¯†åˆ«
                                    already_triggered = any(p.entity_recognition_triggered for p in all_pages)

                                    if not already_triggered:
                                        log_message(f"PDF Sessionæ‰€æœ‰é¡µé¢OCRå®Œæˆï¼Œè§¦å‘æ•´ä½“å®ä½“è¯†åˆ«: {material.pdf_session_id}", "INFO")

                                        # å¼‚æ­¥è§¦å‘PDF Sessionå®ä½“è¯†åˆ«
                                        try:
                                            from entity_recognition_service import EntityRecognitionService

                                            # åˆå¹¶æ‰€æœ‰é¡µé¢çš„OCRç»“æœ
                                            merged_ocr_result = {'regions': []}
                                            for page in all_pages:
                                                if page.translation_text_info:
                                                    page_ocr = json.loads(page.translation_text_info)
                                                    merged_ocr_result['regions'].extend(page_ocr.get('regions', []))

                                            # è®¾ç½®æ‰€æœ‰é¡µé¢çŠ¶æ€ä¸ºè¯†åˆ«ä¸­
                                            for page in all_pages:
                                                page.processing_step = ProcessingStep.ENTITY_RECOGNIZING.value
                                                page.entity_recognition_triggered = True
                                            db.session.commit()

                                            # è°ƒç”¨å®ä½“è¯†åˆ«æœåŠ¡
                                            entity_service = EntityRecognitionService()
                                            entity_result = entity_service.recognize_entities(merged_ocr_result, mode="fast")

                                            if entity_result.get('success'):
                                                # ä¿å­˜ç»“æœåˆ°æ‰€æœ‰é¡µé¢
                                                result_json = json.dumps(entity_result, ensure_ascii=False)
                                                for page in all_pages:
                                                    page.entity_recognition_result = result_json
                                                    page.processing_step = ProcessingStep.ENTITY_PENDING_CONFIRM.value
                                                    page.processing_progress = 100
                                                    page.entity_recognition_error = None

                                                db.session.commit()

                                                # WebSocketæ¨é€æ›´æ–°ï¼ˆåªæ¨é€ç¬¬ä¸€é¡µï¼‰
                                                first_page = all_pages[0]
                                                if WEBSOCKET_ENABLED:
                                                    emit_material_updated(
                                                        first_page.client_id,
                                                        first_page.id,
                                                        processing_step=ProcessingStep.ENTITY_PENDING_CONFIRM.value,
                                                        material=first_page.to_dict()
                                                    )

                                                log_message(f"PDF Sessionæ•´ä½“å®ä½“è¯†åˆ«å®Œæˆ: {material.pdf_session_id}, è¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“", "SUCCESS")
                                            else:
                                                # è¯†åˆ«å¤±è´¥ï¼Œæ¢å¤æ‰€æœ‰é¡µé¢çŠ¶æ€
                                                for page in all_pages:
                                                    page.entity_recognition_error = entity_result.get('error')
                                                    page.processing_step = ProcessingStep.TRANSLATED.value
                                                db.session.commit()
                                                log_message(f"PDF Sessionæ•´ä½“å®ä½“è¯†åˆ«å¤±è´¥: {material.pdf_session_id}, é”™è¯¯: {entity_result.get('error')}", "WARN")

                                        except Exception as e:
                                            log_message(f"PDF Sessionæ•´ä½“å®ä½“è¯†åˆ«å¼‚å¸¸: {material.pdf_session_id} - {str(e)}", "ERROR")
                                            import traceback
                                            traceback.print_exc()

                                            # æ¢å¤æ‰€æœ‰é¡µé¢çŠ¶æ€
                                            for page in all_pages:
                                                page.entity_recognition_error = str(e)
                                                page.processing_step = ProcessingStep.TRANSLATED.value
                                            db.session.commit()
                                    else:
                                        log_message(f"PDF Sessionå·²è§¦å‘è¿‡å®ä½“è¯†åˆ«ï¼Œè·³è¿‡: {material.pdf_session_id}", "INFO")
                                else:
                                    not_completed = [p.pdf_page_number for p in all_pages if not p.translation_text_info]
                                    log_message(f"PDF Sessionéƒ¨åˆ†é¡µé¢å°šæœªå®ŒæˆOCRï¼Œç­‰å¾…å…¶ä»–é¡µé¢: {not_completed}", "INFO")

                            else:
                                # å•ä¸ªå›¾ç‰‡ææ–™ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                                log_message(f"æ£€æµ‹åˆ°å¯ç”¨äº†å®ä½“è¯†åˆ«ï¼Œå¼€å§‹å®ä½“è¯†åˆ«: {material.name}", "INFO")
                                try:
                                    # æ›´æ–°çŠ¶æ€ä¸ºå®ä½“è¯†åˆ«ä¸­
                                    material.processing_step = ProcessingStep.ENTITY_RECOGNIZING.value
                                    material.processing_progress = 0
                                    db.session.commit()

                                    # è°ƒç”¨å®ä½“è¯†åˆ«æœåŠ¡
                                    from entity_recognition_service import EntityRecognitionService
                                    entity_service = EntityRecognitionService()
                                    entity_result = entity_service.recognize_entities(translation_data)

                                    if entity_result.get('success'):
                                        # ä¿å­˜å®ä½“è¯†åˆ«ç»“æœ
                                        material.entity_recognition_result = json.dumps(entity_result, ensure_ascii=False)
                                        material.processing_step = ProcessingStep.ENTITY_PENDING_CONFIRM.value
                                        material.processing_progress = 100
                                        material.entity_recognition_error = None

                                        # ä¿å­˜æ—¥å¿—
                                        entity_service.save_entity_recognition_log(
                                            material_id=material.id,
                                            material_name=material.name,
                                            ocr_result=translation_data,
                                            entity_result=entity_result
                                        )

                                        db.session.commit()

                                        log_message(f"å®ä½“è¯†åˆ«å®Œæˆ: {material.name}, è¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“ï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤", "INFO")
                                    else:
                                        # è¯†åˆ«å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸é˜»æ­¢æµç¨‹
                                        material.entity_recognition_error = entity_result.get('error')
                                        material.processing_step = ProcessingStep.TRANSLATED.value
                                        material.entity_recognition_triggered = True  # æ ‡è®°å·²å°è¯•è¿‡
                                        db.session.commit()
                                        log_message(f"å®ä½“è¯†åˆ«å¤±è´¥: {material.name}, é”™è¯¯: {entity_result.get('error')}", "WARN")

                                        # ğŸ”§ æ¨é€WebSocketæ›´æ–°ï¼Œå‘ŠçŸ¥å‰ç«¯å®ä½“è¯†åˆ«å¤±è´¥
                                        if WEBSOCKET_ENABLED:
                                            emit_material_updated(
                                                material.client_id,
                                                material.id,
                                                processing_step=material.processing_step,
                                                material=material.to_dict(),
                                                entity_recognition_error=entity_result.get('error')
                                            )

                                except Exception as e:
                                    # å®ä½“è¯†åˆ«å¼‚å¸¸ï¼Œè®°å½•é”™è¯¯ä½†ä¸é˜»æ­¢æµç¨‹
                                    log_message(f"å®ä½“è¯†åˆ«å¼‚å¸¸: {material.name} - {str(e)}", "ERROR")
                                    import traceback
                                    traceback.print_exc()
                                    material.entity_recognition_error = str(e)
                                    material.processing_step = ProcessingStep.TRANSLATED.value
                                    material.entity_recognition_triggered = True  # æ ‡è®°å·²å°è¯•è¿‡
                                    db.session.commit()

                                    # ğŸ”§ æ¨é€WebSocketæ›´æ–°ï¼Œå‘ŠçŸ¥å‰ç«¯å®ä½“è¯†åˆ«å¤±è´¥
                                    if WEBSOCKET_ENABLED:
                                        emit_material_updated(
                                            material.client_id,
                                            material.id,
                                            processing_step=material.processing_step,
                                            material=material.to_dict(),
                                            entity_recognition_error=str(e)
                                        )

                        return {'success': True}

                    except Exception as e:
                        log_message(f"ç™¾åº¦ç¿»è¯‘å¼‚å¸¸: {material.name} - {str(e)}", "ERROR")
                        # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
                        update_material_status(
                            material,
                            MaterialStatus.FAILED,
                            translation_error=str(e)
                        )

                        return {'success': False, 'error': str(e)}
                        
                except Exception as e:
                    log_message(f"ç¿»è¯‘ææ–™å¼‚å¸¸: {material_id} - {str(e)}", "ERROR")
                    return {'success': False, 'error': str(e)}
        
        def translate_all_materials_async():
            """å¼‚æ­¥ç¿»è¯‘æ‰€æœ‰ææ–™"""
            print(f"[ASYNC] ========== å¼€å§‹å¼‚æ­¥ç¿»è¯‘ {len(material_ids_to_translate)} ä¸ªææ–™ ==========", flush=True)
            log_message(f"å¼€å§‹å¼‚æ­¥ç¿»è¯‘ {len(material_ids_to_translate)} ä¸ªææ–™", "INFO")

            # ç›´æ¥é¡ºåºæ‰§è¡Œï¼ˆgeventä¼šè‡ªåŠ¨å¹¶å‘å¤„ç†ï¼‰
            translated_count = 0
            failed_count = 0
            skipped_count = 0

            for material_id in material_ids_to_translate:
                print(f"[ASYNC] ç¿»è¯‘ææ–™: ID {material_id}", flush=True)
                log_message(f"ç¿»è¯‘ææ–™: ID {material_id}", "INFO")
                result = translate_one_material(material_id)
                print(f"[ASYNC] ä»»åŠ¡å®Œæˆï¼Œç»“æœ: {result}", flush=True)
                if result.get('success'):
                    translated_count += 1
                elif result.get('skipped'):
                    skipped_count += 1
                else:
                    failed_count += 1

            status_msg = f"æˆåŠŸ {translated_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª"
            if skipped_count > 0:
                status_msg += f"ï¼Œè·³è¿‡ {skipped_count} ä¸ªï¼ˆæ­£åœ¨ç¿»è¯‘ä¸­ï¼‰"
            print(f"[ASYNC] æ‰€æœ‰ææ–™ç¿»è¯‘å®Œæˆï¼š{status_msg}", flush=True)
            log_message(f"æ‰€æœ‰ææ–™ç¿»è¯‘å®Œæˆï¼š{status_msg}", "SUCCESS")
            
            # âœ… WebSocket æ¨é€ï¼šæ‰€æœ‰ç¿»è¯‘å®Œæˆ
            if WEBSOCKET_ENABLED:
                emit_translation_completed(client_id, f'ç¿»è¯‘å®Œæˆï¼š{status_msg}', success_count=translated_count, failed_count=failed_count)
        
        # ä½¿ç”¨æ™®é€šçº¿ç¨‹å¯åŠ¨å¼‚æ­¥ä»»åŠ¡ï¼ˆgeventä¼šè‡ªåŠ¨å¤„ç†ï¼‰
        print(f"[MAIN] å‡†å¤‡å¯åŠ¨å¼‚æ­¥ç¿»è¯‘ä»»åŠ¡ï¼Œææ–™æ•°: {len(material_ids_to_translate)}", flush=True)
        thread = threading.Thread(target=translate_all_materials_async)
        thread.daemon = True
        thread.start()
        print(f"[MAIN] å·²å¯åŠ¨åå°çº¿ç¨‹ï¼Œå¼‚æ­¥ä»»åŠ¡æ­£åœ¨æ‰§è¡Œ", flush=True)
        log_message(f"âœ“ å·²æäº¤ {len(material_ids_to_translate)} ä¸ªææ–™åˆ°ç¿»è¯‘é˜Ÿåˆ—", "INFO")
        
        # âœ… ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…ç¿»è¯‘å®Œæˆ
        return jsonify({
            'success': True,
            'message': f'ç¿»è¯‘å®Œæˆï¼šæˆåŠŸ 0 ä¸ªï¼Œå¤±è´¥ 0 ä¸ª',
            'translated_count': 0,
            'failed_count': 0,
            'translated_materials': []
        })
        
    except Exception as e:
        db.session.rollback()
        log_message(f"å¯åŠ¨ç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': 'å¯åŠ¨ç¿»è¯‘å¤±è´¥'}), 500

@app.route('/api/materials/<material_id>/retry-latex', methods=['POST'])
@jwt_required()
def retry_latex_translation(material_id):
    """é‡è¯•LaTeXç¿»è¯‘"""
    try:
        user_id = get_jwt_identity()
        
        # é€šè¿‡materialæ‰¾åˆ°clientï¼ŒéªŒè¯ç”¨æˆ·æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()
        
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨æˆ–æ— æƒé™'}), 404
        
        if material.type != 'image' and material.type != 'pdf':
            return jsonify({'success': False, 'error': 'åªæœ‰å›¾ç‰‡æˆ–PDFææ–™æ”¯æŒLaTeXç¿»è¯‘'}), 400
        
        log_message(f"å¼€å§‹é‡è¯•LaTeXç¿»è¯‘: {material.name}", "INFO")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_base_name = f"poster_output/latex_retry_{material.id}_{timestamp}"
        
        # æ‰§è¡ŒLaTeXç¿»è¯‘ï¼ŒåŒ…å«é‡è¯•é€»è¾‘
        max_retries = 3
        retry_delay = 2  # ç§’
        
        for attempt in range(max_retries):
            try:
                log_message(f"LaTeXç¿»è¯‘å°è¯• {attempt + 1}/{max_retries}", "INFO")
                
                latex_result = poster_translator.translate_poster_complete(
                    image_path=material.file_path,
                    output_base_name=output_base_name,
                    clean_aux=True
                )
                
                if latex_result['success']:
                    # æ›´æ–°ææ–™çš„LaTeXç¿»è¯‘ç»“æœ
                    material.latex_translation_result = json.dumps({
                        'tex_file': latex_result.get('tex_file'),
                        'pdf_file': latex_result.get('pdf_file'),
                        'latex_code_length': latex_result.get('latex_code_length', 0)
                    }, ensure_ascii=False)
                    material.latex_translation_error = None
                    
                    # å¦‚æœä¹‹å‰å®Œå…¨å¤±è´¥ï¼Œç°åœ¨æ›´æ–°çŠ¶æ€ä¸ºç¿»è¯‘å®Œæˆ
                    if material.status in ['ç¿»è¯‘å¤±è´¥', get_legacy_status(ProcessingStep.FAILED.value)]:
                        material.status = get_legacy_status(ProcessingStep.TRANSLATED.value)
                        material.processing_step = ProcessingStep.TRANSLATED.value
                    
                    db.session.commit()
                    
                    log_message(f"LaTeXç¿»è¯‘é‡è¯•æˆåŠŸ: {material.name}", "SUCCESS")
                    
                    return jsonify({
                        'success': True,
                        'message': 'LaTeXç¿»è¯‘é‡è¯•æˆåŠŸ',
                        'material': material.to_dict(),
                        'latex_result': {
                            'tex_file': latex_result.get('tex_file'),
                            'pdf_file': latex_result.get('pdf_file')
                        }
                    })
                    
                else:
                    # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                    if attempt < max_retries - 1:
                        log_message(f"LaTeXç¿»è¯‘å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡è¯•: {latex_result.get('error')}", "WARNING")
                        time.sleep(retry_delay)
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        raise Exception(latex_result.get('error', 'LaTeXç¿»è¯‘å¤±è´¥'))
                        
            except Exception as e:
                if attempt < max_retries - 1:
                    log_message(f"LaTeXç¿»è¯‘å¼‚å¸¸ï¼Œ{retry_delay}ç§’åé‡è¯•: {str(e)}", "WARNING")
                    time.sleep(retry_delay)
                else:
                    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
                    material.latex_translation_error = str(e)
                    db.session.commit()
                    log_message(f"LaTeXç¿»è¯‘é‡è¯•å¤±è´¥: {material.name} - {str(e)}", "ERROR")
                    
                    return jsonify({
                        'success': False,
                        'error': f'LaTeXç¿»è¯‘å¤±è´¥: {str(e)}',
                        'material': material.to_dict()
                    }), 500
        
    except Exception as e:
        db.session.rollback()
        log_message(f"LaTeXç¿»è¯‘é‡è¯•å¼‚å¸¸: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': f'é‡è¯•å¤±è´¥: {str(e)}'}), 500

@app.route('/api/clients/<client_id>/materials/cancel', methods=['POST'])
@jwt_required()
def cancel_upload(client_id):
    """å–æ¶ˆä¸Šä¼ ï¼Œåˆ é™¤æœ€è¿‘ä¸Šä¼ çš„ææ–™"""
    try:
        user_id = get_jwt_identity()
        client = Client.query.filter_by(id=client_id, user_id=user_id).first()
        if not client:
            return jsonify({'success': False, 'error': 'å®¢æˆ·ä¸å­˜åœ¨'}), 404
        
        data = request.get_json()
        material_ids = data.get('material_ids', [])
        
        if not material_ids:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æŒ‡å®šè¦åˆ é™¤çš„ææ–™'}), 400
        
        deleted_count = 0
        
        for material_id in material_ids:
            material = Material.query.filter_by(id=material_id, client_id=client_id).first()
            if material:
                # åˆ é™¤å…³è”æ–‡ä»¶
                if material.file_path and os.path.exists(material.file_path):
                    try:
                        os.remove(material.file_path)
                        log_message(f"åˆ é™¤æ–‡ä»¶: {material.file_path}", "INFO")
                    except Exception as e:
                        log_message(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {material.file_path} - {str(e)}", "WARNING")
                
                # åˆ é™¤æ•°æ®åº“è®°å½•
                db.session.delete(material)
                deleted_count += 1
        
        db.session.commit()
        
        log_message(f"å–æ¶ˆä¸Šä¼ ï¼Œåˆ é™¤äº† {deleted_count} ä¸ªææ–™", "SUCCESS")
        
        return jsonify({
            'success': True,
            'message': f'å·²åˆ é™¤ {deleted_count} ä¸ªææ–™',
            'deleted_count': deleted_count
        })
        
    except Exception as e:
        db.session.rollback()
        log_message(f"å–æ¶ˆä¸Šä¼ å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'success': False, 'error': 'å–æ¶ˆä¸Šä¼ å¤±è´¥'}), 500

# ========== æ–‡ä»¶ä¸‹è½½ç«¯ç‚¹ ========== 

@app.route('/download/image/<path:filename>')
def download_image(filename):
    """ä¸‹è½½ç¿»è¯‘åçš„å›¾ç‰‡æˆ–ç¼–è¾‘åçš„å›¾ç‰‡"""
    try:
        # æ”¯æŒå®Œæ•´è·¯å¾„å’Œæ–‡ä»¶å
        if '/' in filename:
            # å¦‚æœåŒ…å«è·¯å¾„ï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®
            possible_paths = [
                filename,  # ç›´æ¥ä½¿ç”¨æä¾›çš„è·¯å¾„
                os.path.join('uploads', filename),  # uploadsç›®å½•
                os.path.join(app.root_path, 'uploads', filename),  # ç»å¯¹è·¯å¾„çš„uploadsç›®å½•
                os.path.join('image_translation_output', filename)  # åŸå§‹ç¿»è¯‘è¾“å‡ºç›®å½•
            ]
        else:
            # å¦åˆ™åœ¨å¤šä¸ªç›®å½•ä¸­æŸ¥æ‰¾
            possible_paths = [
                os.path.join('image_translation_output', filename),
                os.path.join('uploads', 'edited', filename),
                os.path.join(app.root_path, 'uploads', 'edited', filename)
            ]

        # å°è¯•æ‰¾åˆ°æ–‡ä»¶
        for path in possible_paths:
            if os.path.exists(path):
                log_message(f"æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {path}", "INFO")
                return send_file(path)

        # æ–‡ä»¶æœªæ‰¾åˆ°
        log_message(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è¿‡çš„è·¯å¾„: {possible_paths}", "ERROR")
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        log_message(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({'error': 'ä¸‹è½½å¤±è´¥'}), 500

def get_file_type(filename):
    """æ ¹æ®æ–‡ä»¶åè·å–æ–‡ä»¶ç±»å‹"""
    ext = filename.split('.').pop().lower()
    if ext in ['pdf']:
        return 'pdf'
    elif ext in ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff']:
        return 'image'
    elif ext in ['doc', 'docx', 'txt', 'rtf']:
        return 'document'
    else:
        return 'document'

# ========== é¢„è§ˆ/ä¸‹è½½åŠŸèƒ½ ==========

@app.route('/preview/translated/<path:filename>')
def preview_translated_file(filename):
    """é¢„è§ˆç¿»è¯‘åçš„PDFæ–‡ä»¶"""
    try:
        log_message(f"é¢„è§ˆPDFè¯·æ±‚ - åŸå§‹filenameå‚æ•°: {filename}", "INFO")

        # Flaskä¼šè‡ªåŠ¨è§£ç URLï¼Œæ‰€ä»¥filenameå·²ç»æ˜¯è§£ç åçš„
        file_path = os.path.join('translated_snapshot', filename)
        log_message(f"å®Œæ•´æ–‡ä»¶è·¯å¾„: {file_path}", "INFO")
        log_message(f"æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(file_path)}", "INFO")

        if not os.path.exists(file_path):
            log_message(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", "ERROR")
            # åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶ç”¨äºè°ƒè¯•
            if os.path.exists('translated_snapshot'):
                files = os.listdir('translated_snapshot')
                log_message(f"translated_snapshotç›®å½•ä¸­çš„æ–‡ä»¶: {files}", "INFO")
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨', 'path': file_path}), 404

        log_message(f"å‘é€æ–‡ä»¶: {file_path}", "SUCCESS")
        response = send_file(
            file_path,
            as_attachment=False,
            mimetype='application/pdf',
            conditional=True
        )

        # å…è®¸ iframe å’Œè·¨åŸŸ
        # ä½¿ç”¨RFC 2231æ ¼å¼å¤„ç†ä¸­æ–‡æ–‡ä»¶å
        encoded_filename = quote(filename.encode('utf-8'))
        response.headers['Content-Disposition'] = f"inline; filename*=UTF-8''{encoded_filename}"
        response.headers['Cache-Control'] = 'public, max-age=3600'
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = '*'

        # ç§»é™¤å¯èƒ½é˜»æ­¢iframeçš„å®‰å…¨å¤´
        for h in ['X-Frame-Options', 'Content-Security-Policy', 'X-Content-Type-Options']:
            if h in response.headers:
                del response.headers[h]

        return response
    except Exception as e:
        log_message(f"é¢„è§ˆPDFå¤±è´¥: {str(e)}", "ERROR")
        import traceback
        log_message(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}", "ERROR")
        return jsonify({'error': str(e)}), 500


# ========== ç³»ç»ŸåŠŸèƒ½ ========== 

@app.route('/')
def index():
    return jsonify({
        'message': 'æ™ºèƒ½æ–‡ä¹¦ç¿»è¯‘å¹³å° - å®Œæ•´ç‰ˆåç«¯API',
        'version': '4.0',
        'features': {
            'user_authentication': True,
            'client_management': True,
            'material_management': True,
            'translation_services': True,
            'poster_translation': OPENAI_AVAILABLE,
            'image_translation': True,
            'webpage_translation': True,
            'gpt_translation': OPENAI_AVAILABLE,
            'google_translation': SELENIUM_AVAILABLE
        },
        'dependencies': {
            'openai': OPENAI_AVAILABLE,
            'selenium': SELENIUM_AVAILABLE,
            'beautifulsoup4': True,
            'requests': True
        }
    })

@app.route('/health')
def health():
    try:
        from sqlalchemy import text
        db.session.execute(text('SELECT 1'))
        return jsonify({
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'database': 'connected',
            'version': '4.0',
            'translation_ready': OPENAI_AVAILABLE or SELENIUM_AVAILABLE
        })
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }), 500

# ========== æ•°æ®åº“åˆå§‹åŒ– ========== 

def init_database():
    with app.app_context():
        try:
            db.create_all()
            log_message("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ", "SUCCESS")
            
            if User.query.count() == 0:
                test_user = User(name="æµ‹è¯•ç”¨æˆ·", email="test@example.com")
                test_user.set_password("password123")
                db.session.add(test_user)
                db.session.commit()
                log_message("å·²åˆ›å»ºæµ‹è¯•ç”¨æˆ·: test@example.com / password123", "SUCCESS")
        except Exception as e:
            log_message(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}", "ERROR")

# ========== Phase 1: æ–°å¢çš„APIç«¯ç‚¹ ========== 

@app.route('/api/clients/<client_id>', methods=['PUT'])
@jwt_required()
def update_client(client_id):
    """æ›´æ–°å®¢æˆ·ä¿¡æ¯"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾å®¢æˆ·
        client = Client.query.filter_by(id=client_id, user_id=current_user_id).first()
        if not client:
            return jsonify({
                'success': False,
                'error': 'å®¢æˆ·ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›è¦æ›´æ–°çš„æ•°æ®'
            }), 400
        
        # æ›´æ–°å­—æ®µï¼ˆæ”¯æŒå‰ç«¯çš„é©¼å³°å‘½åï¼‰
        if 'name' in data:
            client.name = data['name']
        if 'case_type' in data:
            client.case_type = data['case_type']
        if 'caseType' in data:
            client.case_type = data['caseType']
        if 'case_date' in data:
            client.case_date = data['case_date']
        if 'caseDate' in data:
            client.case_date = data['caseDate']
        if 'phone' in data:
            client.phone = data['phone']
        if 'email' in data:
            client.email = data['email']
        if 'address' in data:
            client.address = data['address']
        if 'notes' in data:
            client.notes = data['notes']
        
        client.updated_at = datetime.utcnow()
        
        db.session.commit()
        log_message(f"å®¢æˆ·ä¿¡æ¯æ›´æ–°æˆåŠŸ: {client_id}")
        
        return jsonify({
            'success': True,
            'client': client.to_dict(),
            'message': 'å®¢æˆ·ä¿¡æ¯æ›´æ–°æˆåŠŸ'
        })
        
    except Exception as e:
        log_message(f"æ›´æ–°å®¢æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'æ›´æ–°å®¢æˆ·ä¿¡æ¯å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/clients/<client_id>/archive', methods=['PUT'])
@jwt_required()
def archive_client(client_id):
    """å½’æ¡£å®¢æˆ·"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾å®¢æˆ·
        client = Client.query.filter_by(id=client_id, user_id=current_user_id).first()
        if not client:
            return jsonify({
                'success': False,
                'error': 'å®¢æˆ·ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        reason = data.get('reason', 'ç”¨æˆ·æ‰‹åŠ¨å½’æ¡£')
        
        # è®¾ç½®å½’æ¡£çŠ¶æ€
        client.is_archived = True
        client.archived_at = datetime.utcnow()
        client.archived_reason = reason
        client.updated_at = datetime.utcnow()
        
        db.session.commit()
        log_message(f"å®¢æˆ·å½’æ¡£æˆåŠŸ: {client_id}")
        
        return jsonify({
            'success': True,
            'client': client.to_dict(),
            'message': 'å®¢æˆ·å·²å½’æ¡£'
        })
        
    except Exception as e:
        log_message(f"å½’æ¡£å®¢æˆ·å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'å½’æ¡£å®¢æˆ·å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/clients/<client_id>/unarchive', methods=['PUT'])
@jwt_required()
def unarchive_client(client_id):
    """å–æ¶ˆå½’æ¡£å®¢æˆ·"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾å®¢æˆ·
        client = Client.query.filter_by(id=client_id, user_id=current_user_id).first()
        if not client:
            return jsonify({
                'success': False,
                'error': 'å®¢æˆ·ä¸å­˜åœ¨'
            }), 404
        
        # å–æ¶ˆå½’æ¡£çŠ¶æ€
        client.is_archived = False
        client.archived_at = None
        client.archived_reason = None
        client.updated_at = datetime.utcnow()
        
        db.session.commit()
        log_message(f"å®¢æˆ·å–æ¶ˆå½’æ¡£æˆåŠŸ: {client_id}")
        
        return jsonify({
            'success': True,
            'client': client.to_dict(),
            'message': 'å®¢æˆ·å·²å–æ¶ˆå½’æ¡£'
        })
        
    except Exception as e:
        log_message(f"å–æ¶ˆå½’æ¡£å®¢æˆ·å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'å–æ¶ˆå½’æ¡£å®¢æˆ·å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>', methods=['PUT'])
@jwt_required()
def update_material(material_id):
    """æ›´æ–°ææ–™çŠ¶æ€"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == current_user_id
        ).first()
        
        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›è¦æ›´æ–°çš„æ•°æ®'
            }), 400
        
        # æ›´æ–°å­—æ®µ
        if 'status' in data:
            material.status = data['status']
        if 'confirmed' in data:
            material.confirmed = data['confirmed']
        if 'selectedResult' in data:
            material.selected_result = data['selectedResult']
        if 'selectedTranslationType' in data:
            material.selected_translation_type = data['selectedTranslationType']
        if 'translationConfirmed' in data:
            material.translation_confirmed = data['translationConfirmed']
        
        material.updated_at = datetime.utcnow()
        
        db.session.commit()
        log_message(f"ææ–™çŠ¶æ€æ›´æ–°æˆåŠŸ: {material_id}")
        
        return jsonify({
            'success': True,
            'material': material.to_dict(),
            'message': 'ææ–™çŠ¶æ€æ›´æ–°æˆåŠŸ'
        })
        
    except Exception as e:
        log_message(f"æ›´æ–°ææ–™çŠ¶æ€å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'æ›´æ–°ææ–™çŠ¶æ€å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/confirm', methods=['POST'])
@jwt_required()
def confirm_material(material_id):
    """ç¡®è®¤ææ–™ç¿»è¯‘ç»“æœ"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == current_user_id
        ).first()
        
        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        translation_type = data.get('translation_type') if data else None

        # å¦‚æœæ˜¯PDFææ–™ï¼Œç¡®è®¤æ•´ä¸ªPDFä¼šè¯çš„æ‰€æœ‰é¡µé¢
        if material.pdf_session_id:
            log_message(f"æ£€æµ‹åˆ°PDFææ–™ï¼Œå°†ç¡®è®¤æ•´ä¸ªPDFä¼šè¯: {material.pdf_session_id}", "INFO")

            # æŸ¥æ‰¾åŒä¸€PDFä¼šè¯çš„æ‰€æœ‰é¡µé¢
            pdf_pages = Material.query.filter_by(
                pdf_session_id=material.pdf_session_id
            ).all()

            confirmed_count = 0
            for page in pdf_pages:
                page.confirmed = True
                page.status = get_legacy_status(ProcessingStep.CONFIRMED.value)
                page.processing_step = ProcessingStep.CONFIRMED.value
                page.updated_at = datetime.utcnow()
                confirmed_count += 1

            log_message(f"å·²ç¡®è®¤PDFçš„ {confirmed_count} ä¸ªé¡µé¢", "SUCCESS")
        else:
            # éPDFææ–™ï¼Œåªç¡®è®¤å½“å‰ææ–™
            material.confirmed = True
            material.status = get_legacy_status(ProcessingStep.CONFIRMED.value)
            material.processing_step = ProcessingStep.CONFIRMED.value

            # å¦‚æœæŒ‡å®šäº†ç¿»è¯‘ç±»å‹ï¼Œè®¾ç½®é€‰æ‹©çš„ç¿»è¯‘ç±»å‹ï¼ˆä»…é™å›¾ç‰‡ææ–™ï¼‰
            if translation_type and translation_type in ['api', 'latex'] and material.type == 'image':
                material.selected_translation_type = translation_type
                material.selected_result = translation_type

            material.updated_at = datetime.utcnow()
            log_message(f"ææ–™ç¿»è¯‘ç»“æœç¡®è®¤æˆåŠŸ: {material_id}, ç±»å‹: {translation_type}", "SUCCESS")

        db.session.commit()
        
        return jsonify({
            'success': True,
            'material': material.to_dict(),
            'message': 'ç¿»è¯‘ç»“æœç¡®è®¤æˆåŠŸ'
        })
        
    except Exception as e:
        log_message(f"ç¡®è®¤ææ–™ç¿»è¯‘ç»“æœå¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'ç¡®è®¤ç¿»è¯‘ç»“æœå¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/edit', methods=['POST'])
@jwt_required()
def edit_material_latex(material_id):
    """ç¼–è¾‘ææ–™çš„LaTeXå†…å®¹"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == current_user_id
        ).first()
        
        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        if not data or 'description' not in data:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›ç¼–è¾‘æè¿°'
            }), 400
        
        description = data['description']
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ é‡æ–°ç”ŸæˆLaTeXçš„é€»è¾‘
        # ç›®å‰åªè®°å½•ç¼–è¾‘è¯·æ±‚
        material.latex_translation_result = f"ç¼–è¾‘è¯·æ±‚: {description}"
        material.updated_at = datetime.utcnow()
        
        db.session.commit()
        log_message(f"LaTeXç¼–è¾‘è¯·æ±‚å·²è®°å½•: {material_id}")
        
        return jsonify({
            'success': True,
            'material': material.to_dict(),
            'message': 'LaTeXç¼–è¾‘è¯·æ±‚å·²æäº¤'
        })
        
    except Exception as e:
        log_message(f"ç¼–è¾‘LaTeXå¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'ç¼–è¾‘LaTeXå¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/select', methods=['POST'])
@jwt_required()
def select_translation_result(material_id):
    """é€‰æ‹©ç¿»è¯‘ç»“æœ"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == current_user_id
        ).first()
        
        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        if not data or 'resultType' not in data:
            return jsonify({
                'success': False,
                'error': 'è¯·æŒ‡å®šè¦é€‰æ‹©çš„ç¿»è¯‘ç»“æœç±»å‹'
            }), 400
        
        result_type = data['resultType']
        if result_type not in ['api', 'latex']:
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„ç¿»è¯‘ç»“æœç±»å‹'
            }), 400
        
        # è®¾ç½®é€‰æ‹©çš„ç¿»è¯‘ç±»å‹
        material.selected_translation_type = result_type
        material.selected_result = result_type
        material.updated_at = datetime.utcnow()
        
        db.session.commit()
        log_message(f"ç¿»è¯‘ç»“æœé€‰æ‹©æˆåŠŸ: {material_id}, ç±»å‹: {result_type}")
        
        return jsonify({
            'success': True,
            'material': material.to_dict(),
            'message': f'å·²é€‰æ‹©{result_type}ç¿»è¯‘ç»“æœ'
        })
        
    except Exception as e:
        log_message(f"é€‰æ‹©ç¿»è¯‘ç»“æœå¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'é€‰æ‹©ç¿»è¯‘ç»“æœå¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/unconfirm', methods=['POST'])
@jwt_required()
def unconfirm_material(material_id):
    """å–æ¶ˆç¡®è®¤ææ–™ç¿»è¯‘ç»“æœ"""
    try:
        log_message(f"å¼€å§‹å–æ¶ˆç¡®è®¤ææ–™: {material_id}", "INFO")
        current_user_id = get_jwt_identity()
        log_message(f"å½“å‰ç”¨æˆ·ID: {current_user_id}", "INFO")

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == current_user_id
        ).first()

        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨'
            }), 404

        # å¦‚æœæ˜¯PDFææ–™ï¼Œå–æ¶ˆç¡®è®¤æ•´ä¸ªPDFä¼šè¯çš„æ‰€æœ‰é¡µé¢
        if material.pdf_session_id:
            log_message(f"æ£€æµ‹åˆ°PDFææ–™ï¼Œå°†å–æ¶ˆç¡®è®¤æ•´ä¸ªPDFä¼šè¯: {material.pdf_session_id}", "INFO")

            # æŸ¥æ‰¾åŒä¸€PDFä¼šè¯çš„æ‰€æœ‰é¡µé¢
            pdf_pages = Material.query.filter_by(
                pdf_session_id=material.pdf_session_id
            ).all()

            unconfirmed_count = 0
            for page in pdf_pages:
                page.confirmed = False
                page.status = get_legacy_status(ProcessingStep.TRANSLATED.value)
                page.processing_step = ProcessingStep.TRANSLATED.value
                page.updated_at = datetime.utcnow()
                unconfirmed_count += 1

            log_message(f"å·²å–æ¶ˆç¡®è®¤PDFçš„ {unconfirmed_count} ä¸ªé¡µé¢", "SUCCESS")
        else:
            # éPDFææ–™ï¼Œåªå–æ¶ˆç¡®è®¤å½“å‰ææ–™
            material.confirmed = False
            material.status = get_legacy_status(ProcessingStep.TRANSLATED.value)
            material.processing_step = ProcessingStep.TRANSLATED.value
            material.updated_at = datetime.utcnow()
            log_message(f"å–æ¶ˆç¡®è®¤ææ–™: {material_id}", "SUCCESS")

        # æ³¨æ„ï¼šä¸è¦é‡ç½® edited_image_path å’Œ has_edited_version
        # è¿™äº›å­—æ®µåº”è¯¥ä¿æŒä¸å˜ï¼Œå› ä¸ºç¼–è¾‘å†…å®¹åº”è¯¥è¢«ä¿ç•™

        db.session.commit()

        return jsonify({
            'success': True,
            'material': material.to_dict(),
            'message': 'å·²å–æ¶ˆç¡®è®¤'
        })

    except Exception as e:
        log_message(f"å–æ¶ˆç¡®è®¤ææ–™å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'å–æ¶ˆç¡®è®¤å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/save-edited-image', methods=['POST'])
@jwt_required()
def save_edited_image(material_id):
    """ä¿å­˜ç¼–è¾‘åçš„å›¾ç‰‡"""
    try:
        log_message(f"ä¿å­˜ç¼–è¾‘å›¾ç‰‡ - ææ–™ID: {material_id}", "INFO")

        user_id = get_jwt_identity()

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
            }), 404

        # è·å–ä¸Šä¼ çš„ä¸¤ä¸ªç‰ˆæœ¬çš„å›¾ç‰‡
        # 1. ä¸å¸¦æ–‡å­—ç‰ˆæœ¬ï¼ˆç”¨äºé¢„è§ˆï¼‰
        if 'edited_image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æœªæ‰¾åˆ°ç¼–è¾‘åçš„å›¾ç‰‡ï¼ˆä¸å¸¦æ–‡å­—ç‰ˆæœ¬ï¼‰'
            }), 400

        edited_image = request.files['edited_image']

        # 2. å¸¦æ–‡å­—ç‰ˆæœ¬ï¼ˆç”¨äºå¯¼å‡ºï¼‰
        if 'final_image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æœªæ‰¾åˆ°æœ€ç»ˆå›¾ç‰‡ï¼ˆå¸¦æ–‡å­—ç‰ˆæœ¬ï¼‰'
            }), 400

        final_image = request.files['final_image']

        if edited_image.filename == '' or final_image.filename == '':
            return jsonify({
                'success': False,
                'error': 'æœªé€‰æ‹©å®Œæ•´çš„æ–‡ä»¶'
            }), 400

        # è·å–ç¼–è¾‘çš„regionsçŠ¶æ€ï¼ˆå¯é€‰ï¼‰
        edited_regions = None
        if 'edited_regions' in request.form:
            try:
                edited_regions = request.form.get('edited_regions')
                log_message(f"æ¥æ”¶åˆ°ç¼–è¾‘regionsæ•°æ®", "INFO")
            except Exception as e:
                log_message(f"è§£æregionså¤±è´¥: {e}", "WARN")

        # åˆ›å»ºä¸¤ä¸ªä¿å­˜è·¯å¾„
        edited_dir = os.path.join(app.root_path, 'uploads', 'edited')
        final_dir = os.path.join(app.root_path, 'uploads', 'final')
        os.makedirs(edited_dir, exist_ok=True)
        os.makedirs(final_dir, exist_ok=True)

        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        edited_filename = f"edited_{material.id}_{timestamp}.jpg"
        final_filename = f"final_{material.id}_{timestamp}.jpg"

        edited_file_path = os.path.join(edited_dir, edited_filename)
        final_file_path = os.path.join(final_dir, final_filename)

        # ä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬çš„å›¾ç‰‡
        edited_image.save(edited_file_path)
        final_image.save(final_file_path)

        log_message(f"ç¼–è¾‘å›¾ç‰‡å·²ä¿å­˜ï¼ˆä¸å¸¦æ–‡å­—ï¼‰: {edited_file_path}", "INFO")
        log_message(f"æœ€ç»ˆå›¾ç‰‡å·²ä¿å­˜ï¼ˆå¸¦æ–‡å­—ï¼‰: {final_file_path}", "SUCCESS")

        # æ›´æ–°ææ–™è®°å½•ï¼Œä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬çš„è·¯å¾„å’Œregions
        material.edited_image_path = f"edited/{edited_filename}"
        material.final_image_path = f"final/{final_filename}"
        material.has_edited_version = True
        # ä¿å­˜ç¼–è¾‘å›¾ç‰‡æ—¶ï¼Œè‡ªåŠ¨å°†é€‰æ‹©ç»“æœè®¾ä¸º 'api'ï¼Œä»¥ä¾¿å¯¼å‡ºæ—¶ä½¿ç”¨ç¼–è¾‘åçš„å›¾ç‰‡
        material.selected_result = 'api'
        if edited_regions:
            material.edited_regions = edited_regions
        material.updated_at = datetime.utcnow()
        db.session.commit()

        return jsonify({
            'success': True,
            'message': 'ç¼–è¾‘å›¾ç‰‡ä¿å­˜æˆåŠŸ',
            'edited_image_path': material.edited_image_path,
            'final_image_path': material.final_image_path,
            'material': material.to_dict()
        })

    except Exception as e:
        log_message(f"ä¿å­˜ç¼–è¾‘å›¾ç‰‡å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'ä¿å­˜ç¼–è¾‘å›¾ç‰‡å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/save-regions', methods=['POST'])
@jwt_required()
def save_material_regions(material_id):
    """âœ… é‡æ„ï¼šåªä¿å­˜ææ–™çš„regionsæ•°æ®ï¼Œä¸ä¿å­˜å›¾ç‰‡æ–‡ä»¶"""
    try:
        log_message(f"ä¿å­˜regionsæ•°æ® - ææ–™ID: {material_id}", "INFO")

        user_id = get_jwt_identity()
        data = request.get_json()

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
            }), 404

        # è·å–regionsæ•°æ®
        regions = data.get('regions', [])

        if not regions:
            log_message(f"è­¦å‘Šï¼šä¿å­˜äº†ç©ºçš„regionsæ•°æ®", "WARN")

        # ä¿å­˜regionsæ•°æ®åˆ°æ•°æ®åº“
        material.edited_regions = json.dumps(regions, ensure_ascii=False)
        material.has_edited_version = True
        material.selected_result = 'api'  # æ ‡è®°ä¸ºä½¿ç”¨ç¼–è¾‘ç‰ˆæœ¬
        material.updated_at = datetime.utcnow()

        db.session.commit()

        log_message(f"âœ… Regionsä¿å­˜æˆåŠŸ: {len(regions)}ä¸ªåŒºåŸŸ", "SUCCESS")

        # ä½¿ææ–™åˆ—è¡¨ç¼“å­˜å¤±æ•ˆ
        invalidate_materials_cache(material.client_id)

        # æ¨é€WebSocketæ›´æ–°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if WEBSOCKET_ENABLED:
            emit_material_updated(
                material.client_id,
                material_id=material.id,
                edited_regions=regions,
                has_edited_version=True
            )

        return jsonify({
            'success': True,
            'message': f'æˆåŠŸä¿å­˜{len(regions)}ä¸ªç¼–è¾‘åŒºåŸŸ',
            'material': material.to_dict()
        })

    except Exception as e:
        log_message(f"ä¿å­˜regionså¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'ä¿å­˜regionså¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/materials/<material_id>/save-final-image', methods=['POST'])
@jwt_required()
def save_final_image(material_id):
    """ä¿å­˜å‰ç«¯ç”Ÿæˆçš„æœ€ç»ˆå›¾ç‰‡ï¼ˆç”¨äºå¯¼å‡ºï¼‰"""
    try:
        log_message(f"ä¿å­˜æœ€ç»ˆå›¾ç‰‡ - ææ–™ID: {material_id}", "INFO")

        user_id = get_jwt_identity()

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            return jsonify({
                'success': False,
                'error': 'ææ–™ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
            }), 404

        # è·å–ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
        if 'final_image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶'
            }), 400

        file = request.files['final_image']
        if not file or file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶åä¸ºç©º'
            }), 400

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"final_{material_id}_{timestamp}.jpg"

        # ä¿å­˜åˆ° uploads ç›®å½•
        upload_folder = os.path.join(app.root_path, 'uploads')
        os.makedirs(upload_folder, exist_ok=True)
        filepath = os.path.join(upload_folder, filename)

        file.save(filepath)
        log_message(f"æœ€ç»ˆå›¾ç‰‡å·²ä¿å­˜: {filepath}", "SUCCESS")

        # æ›´æ–°æ•°æ®åº“ï¼Œä¿å­˜ç›¸å¯¹è·¯å¾„
        relative_path = os.path.join('uploads', filename)
        material.final_image_path = relative_path
        material.has_edited_version = True
        material.updated_at = datetime.utcnow()

        db.session.commit()

        log_message(f"âœ… æœ€ç»ˆå›¾ç‰‡ä¿å­˜æˆåŠŸ: {relative_path}", "SUCCESS")

        return jsonify({
            'success': True,
            'message': 'æœ€ç»ˆå›¾ç‰‡ä¿å­˜æˆåŠŸ',
            'final_image_path': relative_path
        })

    except Exception as e:
        log_message(f"ä¿å­˜æœ€ç»ˆå›¾ç‰‡å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'ä¿å­˜æœ€ç»ˆå›¾ç‰‡å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/ai-revise-text', methods=['POST'])
@jwt_required()
def ai_revise_text():
    """ä½¿ç”¨AIä¿®æ”¹å•ä¸ªæˆ–å¤šä¸ªæ–‡æœ¬æ¡†çš„å†…å®¹"""
    try:
        data = request.get_json()
        texts = data.get('texts', [])  # æ–‡æœ¬åˆ—è¡¨ï¼Œæ”¯æŒå•ä¸ªæˆ–å¤šä¸ª
        instruction = data.get('instruction', '')
        mode = data.get('mode', 'unified')  # unified, merge, individual

        if not texts or not instruction:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            }), 400

        log_message(f"AIæ–‡æœ¬ä¿®æ”¹ - æ¨¡å¼: {mode}, æ–‡æœ¬æ•°é‡: {len(texts)}", "INFO")

        # æ£€æŸ¥OpenAIé…ç½®
        api_keys = load_api_keys()
        api_key = api_keys.get('OPENAI_API_KEY')
        if not api_key:
            return jsonify({
                'success': False,
                'error': 'OpenAI APIå¯†é’¥æœªé…ç½®'
            }), 500

        try:
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
        except ImportError:
            return jsonify({
                'success': False,
                'error': 'OpenAIåº“æœªå®‰è£…'
            }), 500

        results = []

        if mode == 'merge':
            # åˆå¹¶æ¨¡å¼ï¼šå…ˆåˆå¹¶æ‰€æœ‰æ–‡æœ¬ï¼Œå†ä¿®æ”¹
            merged_text = '\n'.join(texts)

            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘åŠ©æ‰‹ã€‚

åŸå§‹æ–‡æœ¬ï¼š
{merged_text}

ç”¨æˆ·çš„ä¿®æ”¹è¦æ±‚ï¼š
{instruction}

è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·çš„è¦æ±‚ä¿®æ”¹æ–‡æœ¬ï¼Œåªè¿”å›ä¿®æ”¹åçš„æ–‡æœ¬å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚
é‡è¦æç¤ºï¼š
1. å¿…é¡»ä¸¥æ ¼éµå¾ªç”¨æˆ·çš„æŒ‡ä»¤ï¼Œä¸è¦è¿›è¡Œä»»ä½•é¢å¤–çš„ä¼˜åŒ–æˆ–æ”¹åŠ¨
2. å¦‚æœç”¨æˆ·è¦æ±‚ä»…åšæ ¼å¼ä¿®æ”¹ï¼ˆå¦‚æ·»åŠ æ ‡ç‚¹ã€æ¢è¡Œã€ç©ºæ ¼ç­‰ï¼‰ï¼Œå¿…é¡»å®Œæ•´ä¿ç•™åŸæ–‡çš„æ‰€æœ‰å†…å®¹ï¼Œåªè°ƒæ•´æ ¼å¼
3. å¦‚æœç”¨æˆ·è¦æ±‚ä¿ç•™åŸæ–‡ï¼Œç»å¯¹ä¸èƒ½åˆ é™¤ã€æ›¿æ¢æˆ–æ”¹å†™ä»»ä½•åŸæ–‡å†…å®¹
4. ä¿æŒåŸæ–‡çš„è¯­è¨€ï¼ˆå¦‚æœæ˜¯ä¸­æ–‡å°±ç”¨ä¸­æ–‡ï¼Œè‹±æ–‡å°±ç”¨è‹±æ–‡ï¼‰"""

            response = client.chat.completions.create(
                model="gpt-5-mini",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘åŠ©æ‰‹ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚ä¿®æ”¹æ–‡æœ¬ï¼Œä¸åšä»»ä½•é¢å¤–çš„ä¼˜åŒ–æˆ–æ”¹åŠ¨ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=5000
            )

            # è®°å½• token ä½¿ç”¨æƒ…å†µ
            usage = response.usage
            log_message(f"Tokenä½¿ç”¨æƒ…å†µ - prompt: {usage.prompt_tokens}, completion: {usage.completion_tokens}, reasoning: {getattr(usage.completion_tokens_details, 'reasoning_tokens', 0)}, total: {usage.total_tokens}", "INFO")
            log_message(f"å®ŒæˆåŸå› : {response.choices[0].finish_reason}", "INFO")

            revised_text = response.choices[0].message.content.strip() if response.choices[0].message.content else ""
            log_message(f"AIè¿”å›å†…å®¹ - åŸæ–‡é•¿åº¦: {len(merged_text)}, ä¿®æ”¹åé•¿åº¦: {len(revised_text)}, å†…å®¹é¢„è§ˆ: {revised_text[:100] if revised_text else '(ç©º)'}", "INFO")
            results.append({
                'original': merged_text,
                'revised': revised_text
            })

        else:
            # unified æˆ– individual æ¨¡å¼ï¼šåˆ†åˆ«å¤„ç†æ¯ä¸ªæ–‡æœ¬
            for original_text in texts:
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘åŠ©æ‰‹ã€‚

åŸå§‹æ–‡æœ¬ï¼š
{original_text}

ç”¨æˆ·çš„ä¿®æ”¹è¦æ±‚ï¼š
{instruction}

è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·çš„è¦æ±‚ä¿®æ”¹æ–‡æœ¬ï¼Œåªè¿”å›ä¿®æ”¹åçš„æ–‡æœ¬å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚
é‡è¦æç¤ºï¼š
1. å¿…é¡»ä¸¥æ ¼éµå¾ªç”¨æˆ·çš„æŒ‡ä»¤ï¼Œä¸è¦è¿›è¡Œä»»ä½•é¢å¤–çš„ä¼˜åŒ–æˆ–æ”¹åŠ¨
2. å¦‚æœç”¨æˆ·è¦æ±‚ä»…åšæ ¼å¼ä¿®æ”¹ï¼ˆå¦‚æ·»åŠ æ ‡ç‚¹ã€æ¢è¡Œã€ç©ºæ ¼ç­‰ï¼‰ï¼Œå¿…é¡»å®Œæ•´ä¿ç•™åŸæ–‡çš„æ‰€æœ‰å†…å®¹ï¼Œåªè°ƒæ•´æ ¼å¼
3. å¦‚æœç”¨æˆ·è¦æ±‚ä¿ç•™åŸæ–‡ï¼Œç»å¯¹ä¸èƒ½åˆ é™¤ã€æ›¿æ¢æˆ–æ”¹å†™ä»»ä½•åŸæ–‡å†…å®¹
4. ä¿æŒåŸæ–‡çš„è¯­è¨€ï¼ˆå¦‚æœæ˜¯ä¸­æ–‡å°±ç”¨ä¸­æ–‡ï¼Œè‹±æ–‡å°±ç”¨è‹±æ–‡ï¼‰"""

                response = client.chat.completions.create(
                    model="gpt-5-mini",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘åŠ©æ‰‹ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚ä¿®æ”¹æ–‡æœ¬ï¼Œä¸åšä»»ä½•é¢å¤–çš„ä¼˜åŒ–æˆ–æ”¹åŠ¨ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_completion_tokens=5000
                )

                # è®°å½• token ä½¿ç”¨æƒ…å†µ
                usage = response.usage
                log_message(f"Tokenä½¿ç”¨æƒ…å†µ - prompt: {usage.prompt_tokens}, completion: {usage.completion_tokens}, reasoning: {getattr(usage.completion_tokens_details, 'reasoning_tokens', 0)}, total: {usage.total_tokens}", "INFO")
                log_message(f"å®ŒæˆåŸå› : {response.choices[0].finish_reason}", "INFO")

                revised_text = response.choices[0].message.content.strip() if response.choices[0].message.content else ""
                log_message(f"AIè¿”å›å†…å®¹ - åŸæ–‡é•¿åº¦: {len(original_text)}, ä¿®æ”¹åé•¿åº¦: {len(revised_text)}, å†…å®¹é¢„è§ˆ: {revised_text[:100] if revised_text else '(ç©º)'}", "INFO")
                results.append({
                    'original': original_text,
                    'revised': revised_text
                })

        log_message(f"AIæ–‡æœ¬ä¿®æ”¹æˆåŠŸ - å¤„ç†äº†{len(results)}ä¸ªæ–‡æœ¬", "INFO")

        return jsonify({
            'success': True,
            'mode': mode,
            'results': results
        })

    except Exception as e:
        log_message(f"AIæ–‡æœ¬ä¿®æ”¹å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'æ–‡æœ¬ä¿®æ”¹å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/ai-global-optimize', methods=['POST'])
@jwt_required()
def ai_global_optimize():
    """å…¨å±€AIä¼˜åŒ–ï¼šæ£€æŸ¥æœ¯è¯­ä¸€è‡´æ€§ã€é£æ ¼ç»Ÿä¸€ç­‰"""
    try:
        data = request.get_json()
        texts = data.get('texts', [])  # æ‰€æœ‰æ–‡æœ¬æ¡†çš„å†…å®¹åˆ—è¡¨
        task_type = data.get('taskType', 'custom')  # terminology, style, custom
        instruction = data.get('instruction', '')

        if not texts:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘æ–‡æœ¬å†…å®¹'
            }), 400

        log_message(f"å…¨å±€AIä¼˜åŒ– - ä»»åŠ¡ç±»å‹: {task_type}, æ–‡æœ¬æ•°é‡: {len(texts)}", "INFO")

        # æ£€æŸ¥OpenAIé…ç½®
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return jsonify({
                'success': False,
                'error': 'OpenAI APIå¯†é’¥æœªé…ç½®'
            }), 500

        try:
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
        except ImportError:
            return jsonify({
                'success': False,
                'error': 'OpenAIåº“æœªå®‰è£…'
            }), 500

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompts = {
            'terminology': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å®¡æ ¡ä¸“å®¶ï¼Œæ“…é•¿æ£€æŸ¥å’Œç»Ÿä¸€æœ¯è¯­ä½¿ç”¨ã€‚',
            'style': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘ä¸“å®¶ï¼Œæ“…é•¿ç»Ÿä¸€æ–‡æœ¬é£æ ¼å’Œè¯­æ°”ã€‚',
            'custom': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·è¦æ±‚ä¼˜åŒ–æ–‡æœ¬ã€‚'
        }

        # æ„å»ºç”¨æˆ·æç¤º - ä½¿ç”¨æ›´ç´§å‡‘çš„æ ¼å¼
        texts_list = [{"i": i, "t": text} for i, text in enumerate(texts)]

        prompt = f"""ç”¨æˆ·è¦æ±‚ï¼š{instruction}

æ–‡æœ¬åˆ—è¡¨ï¼ˆå…±{len(texts)}ä¸ªï¼‰ï¼š
{json.dumps(texts_list, ensure_ascii=False)}

è¯·åˆ†æè¿™äº›æ–‡æœ¬ï¼Œæ ¹æ®ç”¨æˆ·è¦æ±‚æå‡ºä¿®æ”¹å»ºè®®ã€‚
è¿”å›JSONæ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
{{
  "suggestions": [
    {{"index": 0, "original": "åŸæ–‡", "revised": "ä¿®æ”¹å", "changes": "è¯´æ˜"}},
    ...
  ]
}}

æ³¨æ„ï¼š
1. indexå¯¹åº”æ–‡æœ¬åºå·
2. å¦‚æœä¸éœ€è¦ä¿®æ”¹ï¼Œrevisedä¸originalç›¸åŒï¼Œchangesä¸ºç©ºå­—ç¬¦ä¸²
3. changesç®€çŸ­è¯´æ˜ä¿®æ”¹åŸå› 
4. ç¡®ä¿è¿”å›å®Œæ•´æœ‰æ•ˆçš„JSON"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompts.get(task_type, system_prompts['custom'])},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=4000,
            response_format={"type": "json_object"}
        )

        result_text = response.choices[0].message.content.strip()
        log_message(f"AIè¿”å›å†…å®¹é•¿åº¦: {len(result_text)}", "INFO")

        try:
            result_json = json.loads(result_text)
        except json.JSONDecodeError as e:
            log_message(f"JSONè§£æå¤±è´¥: {str(e)}", "ERROR")
            log_message(f"è¿”å›å†…å®¹å‰500å­—ç¬¦: {result_text[:500]}", "ERROR")
            # å°è¯•ä¿®å¤å¸¸è§çš„JSONé—®é¢˜
            import re
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            result_text = re.sub(r'```json\s*', '', result_text)
            result_text = re.sub(r'```\s*$', '', result_text)
            result_json = json.loads(result_text)

        suggestions = result_json.get('suggestions', [])

        log_message(f"å…¨å±€AIä¼˜åŒ–æˆåŠŸ - ç”Ÿæˆäº†{len(suggestions)}æ¡å»ºè®®", "INFO")

        return jsonify({
            'success': True,
            'taskType': task_type,
            'suggestions': suggestions
        })

    except Exception as e:
        log_message(f"å…¨å±€AIä¼˜åŒ–å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'å…¨å±€ä¼˜åŒ–å¤±è´¥',
            'message': str(e)
        }), 500

# ============================================================================
# å®ä½“è¯†åˆ«ç›¸å…³è·¯ç”±ï¼ˆé¢„ç•™æ¥å£ï¼‰
# ============================================================================

@app.route('/api/materials/<material_id>/enable-entity-recognition', methods=['POST'])
@jwt_required()
def toggle_entity_recognition(material_id):
    """
    å¯ç”¨/ç¦ç”¨ææ–™çš„å®ä½“è¯†åˆ«åŠŸèƒ½

    è¯·æ±‚ä½“:
        {
            "enabled": true/false,
            "mode": "standard" æˆ– "deep" (å¯é€‰ï¼Œé»˜è®¤ä¸º"standard")
        }
    """
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤ææ–™'}), 403

        data = request.get_json()
        enabled = data.get('enabled', False)
        mode = data.get('mode', 'standard')  # é»˜è®¤ä¸ºstandardæ¨¡å¼

        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ¥æ”¶åˆ°çš„å‚æ•°
        print(f"\n{'='*60}")
        print(f"[DEBUG] enable-entity-recognition æ¥å£è°ƒç”¨")
        print(f"ææ–™ID: {material_id}")
        print(f"æ¥æ”¶å‚æ•°: enabled={enabled}, mode={mode}")
        print(f"å½“å‰çŠ¶æ€: processing_step={material.processing_step}")
        print(f"{'='*60}\n")

        # éªŒè¯modeå€¼
        if mode not in ['standard', 'deep']:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„modeå€¼ï¼Œå¿…é¡»ä¸ºstandardæˆ–deep'}), 400

        material.entity_recognition_enabled = enabled
        if enabled:
            # å¦‚æœå¯ç”¨ï¼Œè®¾ç½®æ¨¡å¼
            material.entity_recognition_mode = mode
            print(f"[DEBUG] âœ… å·²è®¾ç½® entity_recognition_mode = {mode}")
        else:
            # å¦‚æœç¦ç”¨ï¼Œæ¸…é™¤ç›¸å…³æ•°æ®
            material.entity_recognition_mode = None
            material.entity_recognition_result = None
            material.entity_recognition_confirmed = False
            material.entity_recognition_triggered = False
            material.entity_user_edits = None
            material.entity_recognition_error = None

        db.session.commit()

        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šä¿å­˜åçš„å€¼
        print(f"[DEBUG] æ•°æ®åº“æäº¤å:")
        print(f"  entity_recognition_enabled = {material.entity_recognition_enabled}")
        print(f"  entity_recognition_mode = {material.entity_recognition_mode}")
        print(f"  to_dict()åŒ…å«çš„å€¼:")
        material_dict = material.to_dict()
        print(f"    entityRecognitionEnabled = {material_dict.get('entityRecognitionEnabled')}")
        print(f"    entityRecognitionMode = {material_dict.get('entityRecognitionMode')}")
        print(f"    processingStep = {material_dict.get('processingStep')}")

        log_message(f"ææ–™ {material.name} å®ä½“è¯†åˆ«å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}" +
                   (f"ï¼Œæ¨¡å¼: {mode}" if enabled else ""), "INFO")

        return jsonify({
            'success': True,
            'enabled': enabled,
            'mode': mode,  # âœ… è¿”å›modeç»™å‰ç«¯
            'material': material_dict,  # âœ… è¿”å›å®Œæ•´materialå¯¹è±¡
            'message': f"å®ä½“è¯†åˆ«å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}"
        })

    except Exception as e:
        log_message(f"åˆ‡æ¢å®ä½“è¯†åˆ«å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'åˆ‡æ¢å®ä½“è¯†åˆ«å¤±è´¥',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/entity-recognition', methods=['POST'])
@jwt_required()
def start_entity_recognition(material_id):
    """
    å¼€å§‹å®ä½“è¯†åˆ«ï¼ˆOCRå®Œæˆåè°ƒç”¨ï¼‰

    è¿™æ˜¯ä¸€ä¸ªå¡å…³æ­¥éª¤ï¼š
    1. è°ƒç”¨å®ä½“è¯†åˆ«API
    2. è¿”å›è¯†åˆ«ç»“æœç»™å‰ç«¯
    3. ç­‰å¾…å‰ç«¯ç”¨æˆ·ç¡®è®¤/ç¼–è¾‘å®ä½“
    4. ç”¨æˆ·ç¡®è®¤åæ‰èƒ½ç»§ç»­è¿›è¡ŒLLMç¿»è¯‘
    """
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤ææ–™'}), 403

        # æ£€æŸ¥æ˜¯å¦å·²å¯ç”¨å®ä½“è¯†åˆ«
        if not material.entity_recognition_enabled:
            return jsonify({
                'success': False,
                'error': 'å®ä½“è¯†åˆ«æœªå¯ç”¨',
                'message': 'è¯·å…ˆå¯ç”¨å®ä½“è¯†åˆ«åŠŸèƒ½'
            }), 400

        # æ£€æŸ¥æ˜¯å¦å·²å®ŒæˆOCRç¿»è¯‘
        if not material.translation_text_info:
            return jsonify({
                'success': False,
                'error': 'OCRç¿»è¯‘æœªå®Œæˆ',
                'message': 'è¯·å…ˆå®ŒæˆOCRç¿»è¯‘å†è¿›è¡Œå®ä½“è¯†åˆ«'
            }), 400

        log_message(f"å¼€å§‹å®ä½“è¯†åˆ«: {material.name}", "INFO")

        # æ›´æ–°çŠ¶æ€ä¸ºå®ä½“è¯†åˆ«ä¸­
        material.processing_step = ProcessingStep.ENTITY_RECOGNIZING.value
        material.processing_progress = 0
        db.session.commit()

        # è§£æOCRç»“æœ
        ocr_result = json.loads(material.translation_text_info)

        # è°ƒç”¨å®ä½“è¯†åˆ«æœåŠ¡
        from entity_recognition_service import EntityRecognitionService
        entity_service = EntityRecognitionService()
        entity_result = entity_service.recognize_entities(ocr_result)

        if entity_result.get('success'):
            # ä¿å­˜å®ä½“è¯†åˆ«ç»“æœ
            material.entity_recognition_result = json.dumps(entity_result, ensure_ascii=False)
            material.processing_step = ProcessingStep.ENTITY_PENDING_CONFIRM.value
            material.processing_progress = 100
            material.entity_recognition_error = None

            # ä¿å­˜æ—¥å¿—
            entity_service.save_entity_recognition_log(
                material_id=material.id,
                material_name=material.name,
                ocr_result=ocr_result,
                entity_result=entity_result
            )

            db.session.commit()

            log_message(f"å®ä½“è¯†åˆ«å®Œæˆ: {material.name}, è¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“", "INFO")

            return jsonify({
                'success': True,
                'result': entity_result,
                'message': 'å®ä½“è¯†åˆ«å®Œæˆï¼Œè¯·ç¡®è®¤è¯†åˆ«ç»“æœ'
            })
        else:
            # è¯†åˆ«å¤±è´¥
            material.entity_recognition_error = entity_result.get('error')

            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯æ¢å¤é”™è¯¯
            if entity_result.get('recoverable'):
                # å¯æ¢å¤é”™è¯¯ï¼Œå…è®¸ç»§ç»­ç¿»è¯‘æµç¨‹
                material.entity_recognition_enabled = False
                material.processing_step = ProcessingStep.TRANSLATED.value
                db.session.commit()

                log_message(f"å®ä½“è¯†åˆ«æœåŠ¡ä¸å¯ç”¨ï¼Œå·²ç¦ç”¨: {material.name}, é”™è¯¯: {entity_result.get('error')}", "WARN")

                return jsonify({
                    'success': False,
                    'error': 'å®ä½“è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
                    'message': entity_result.get('error'),
                    'recoverable': True,
                    'canContinue': True
                }), 503  # Service Unavailable
            else:
                # ä¸å¯æ¢å¤é”™è¯¯
                material.processing_step = ProcessingStep.FAILED.value
                db.session.commit()

                log_message(f"å®ä½“è¯†åˆ«å¤±è´¥: {material.name}, é”™è¯¯: {entity_result.get('error')}", "ERROR")

                return jsonify({
                    'success': False,
                    'error': 'å®ä½“è¯†åˆ«å¤±è´¥',
                    'message': entity_result.get('error')
                }), 500

    except Exception as e:
        log_message(f"å®ä½“è¯†åˆ«å¼‚å¸¸: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()

        # æ›´æ–°é”™è¯¯çŠ¶æ€
        try:
            material.entity_recognition_error = str(e)
            material.processing_step = ProcessingStep.FAILED.value
            db.session.commit()
        except:
            pass

        return jsonify({
            'success': False,
            'error': 'å®ä½“è¯†åˆ«å¼‚å¸¸',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/entity-recognition-result', methods=['GET'])
@jwt_required()
def get_entity_recognition_result(material_id):
    """è·å–ææ–™çš„å®ä½“è¯†åˆ«ç»“æœ"""
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™è®¿é—®æ­¤ææ–™'}), 403

        # è§£æå®ä½“è¯†åˆ«ç»“æœ
        entity_result = None
        if material.entity_recognition_result:
            try:
                entity_result = json.loads(material.entity_recognition_result)
            except:
                entity_result = None

        # è§£æç”¨æˆ·ç¼–è¾‘çš„å®ä½“ä¿¡æ¯
        entity_edits = None
        if material.entity_user_edits:
            try:
                entity_edits = json.loads(material.entity_user_edits)
            except:
                entity_edits = None

        return jsonify({
            'success': True,
            'enabled': material.entity_recognition_enabled,
            'confirmed': material.entity_recognition_confirmed,
            'result': entity_result,
            'userEdits': entity_edits,
            'error': material.entity_recognition_error,
            'processingStep': material.processing_step,
            'processingProgress': material.processing_progress
        })

    except Exception as e:
        log_message(f"è·å–å®ä½“è¯†åˆ«ç»“æœå¤±è´¥: {str(e)}", "ERROR")
        return jsonify({
            'success': False,
            'error': 'è·å–å®ä½“è¯†åˆ«ç»“æœå¤±è´¥',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/confirm-entities', methods=['POST'])
@jwt_required()
def confirm_entities(material_id):
    """
    ç”¨æˆ·ç¡®è®¤/ç¼–è¾‘å®ä½“è¯†åˆ«ç»“æœï¼ˆå¡å…³æ­¥éª¤çš„ç¡®è®¤ï¼‰

    è¯·æ±‚ä½“:
        {
            "entities": [
                {
                    "region_id": 0,
                    "entities": [
                        {
                            "type": "PERSON",
                            "value": "å¼ ä¸‰",
                            "translation_instruction": "translate as 'Zhang San'"
                        }
                    ]
                }
            ],
            "translationGuidance": {
                "persons": ["å¼ ä¸‰ -> Zhang San"],
                "locations": ["åŒ—äº¬ -> Beijing"],
                "organizations": ["åŒ—äº¬å¤§å­¦ -> Peking University"],
                "terms": ["æœºå™¨å­¦ä¹  -> Machine Learning"]
            }
        }
    """
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤ææ–™'}), 403

        # æ£€æŸ¥æ˜¯å¦åœ¨ç­‰å¾…ç¡®è®¤çŠ¶æ€
        if material.processing_step != ProcessingStep.ENTITY_PENDING_CONFIRM.value:
            return jsonify({
                'success': False,
                'error': 'çŠ¶æ€é”™è¯¯',
                'message': 'å½“å‰ä¸åœ¨ç­‰å¾…å®ä½“ç¡®è®¤çŠ¶æ€'
            }), 400

        data = request.get_json()
        entities = data.get('entities', [])
        translation_guidance = data.get('translationGuidance', {})

        # ä¿å­˜ç”¨æˆ·ç¼–è¾‘çš„å®ä½“ä¿¡æ¯
        user_edits = {
            'entities': entities,
            'translationGuidance': translation_guidance,
            'confirmedAt': datetime.utcnow().isoformat()
        }
        material.entity_user_edits = json.dumps(user_edits, ensure_ascii=False)
        material.entity_recognition_confirmed = True
        material.processing_step = ProcessingStep.ENTITY_CONFIRMED.value

        # â­ å…³é”®åŠŸèƒ½ï¼šå¦‚æœæ˜¯PDFï¼Œå°†translationGuidanceåº”ç”¨åˆ°æ‰€æœ‰åŒä¸€Sessionçš„é¡µé¢
        if material.pdf_session_id:
            log_message(f"PDF Sessionæ£€æµ‹åˆ°: {material.pdf_session_id}ï¼Œåº”ç”¨translationGuidanceåˆ°æ‰€æœ‰é¡µé¢", "INFO")
            session_materials = Material.query.filter_by(
                pdf_session_id=material.pdf_session_id
            ).all()

            affected_count = 0
            for mat in session_materials:
                if mat.id != material.id:  # è·³è¿‡å½“å‰ææ–™ï¼ˆå·²ç»è®¾ç½®è¿‡äº†ï¼‰
                    mat.entity_user_edits = json.dumps(user_edits, ensure_ascii=False)
                    mat.entity_recognition_confirmed = True
                    if mat.processing_step == ProcessingStep.ENTITY_PENDING_CONFIRM.value:
                        mat.processing_step = ProcessingStep.ENTITY_CONFIRMED.value
                    affected_count += 1

            log_message(f"å·²ä¸º {affected_count} ä¸ªPDFé¡µé¢åº”ç”¨ç›¸åŒçš„translationGuidance", "INFO")

        db.session.commit()

        log_message(f"å®ä½“è¯†åˆ«å·²ç¡®è®¤: {material.name}", "INFO")

        # â­ è‡ªåŠ¨è§¦å‘LLMç¿»è¯‘
        try:
            from threading import Thread
            log_message(f"è‡ªåŠ¨è§¦å‘LLMç¿»è¯‘: {material.name}", "INFO")

            # åˆ›å»ºçº¿ç¨‹å¼‚æ­¥æ‰§è¡ŒLLMç¿»è¯‘
            def trigger_llm_translation():
                with app.app_context():
                    try:
                        # æ›´æ–°çŠ¶æ€ä¸ºLLMç¿»è¯‘ä¸­
                        mat = Material.query.get(material_id)
                        if mat:
                            mat.processing_step = ProcessingStep.LLM_TRANSLATING.value
                            db.session.commit()

                            # WebSocketæ¨é€
                            if WEBSOCKET_ENABLED:
                                emit_llm_started(material_id, progress=70)

                        # æ‰§è¡ŒLLMç¿»è¯‘
                        baidu_result = json.loads(mat.translation_text_info)
                        regions = baidu_result.get('regions', [])

                        # è¯»å–å®ä½“è¯†åˆ«æŒ‡å¯¼
                        entity_guidance = None
                        if mat.entity_user_edits:
                            entity_data = json.loads(mat.entity_user_edits)
                            entity_guidance = entity_data.get('translationGuidance', {})

                        from llm_service import LLMTranslationService
                        llm_service = LLMTranslationService(output_folder='outputs')
                        llm_translations = llm_service.optimize_translations(regions, entity_guidance=entity_guidance)

                        # ä¿å­˜ç»“æœ
                        mat.llm_translation_result = json.dumps(llm_translations, ensure_ascii=False)
                        mat.processing_step = ProcessingStep.LLM_TRANSLATED.value
                        mat.processing_progress = 100
                        mat.status = MaterialStatus.TRANSLATED.value
                        db.session.commit()

                        # WebSocketæ¨é€å®Œæˆ
                        if WEBSOCKET_ENABLED:
                            emit_llm_completed(material_id, llm_translations, progress=100)

                        log_message(f"è‡ªåŠ¨LLMç¿»è¯‘å®Œæˆ: {mat.name}", "SUCCESS")

                    except Exception as e:
                        log_message(f"è‡ªåŠ¨è§¦å‘LLMç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
                        import traceback
                        traceback.print_exc()

                        # æ ‡è®°å¤±è´¥
                        mat = Material.query.get(material_id)
                        if mat:
                            mat.status = MaterialStatus.FAILED.value
                            mat.processing_step = ProcessingStep.FAILED.value
                            mat.translation_error = f"LLMç¿»è¯‘å¤±è´¥: {str(e)}"
                            db.session.commit()

            thread = Thread(target=trigger_llm_translation)
            thread.daemon = True
            thread.start()

        except Exception as e:
            log_message(f"å¯åŠ¨LLMç¿»è¯‘çº¿ç¨‹å¤±è´¥: {str(e)}", "WARNING")

        return jsonify({
            'success': True,
            'message': 'å®ä½“è¯†åˆ«å·²ç¡®è®¤ï¼ŒLLMç¿»è¯‘å·²è‡ªåŠ¨å¯åŠ¨',
            'canProceedToLLM': True,
            'autoStartedLLM': True
        })

    except Exception as e:
        log_message(f"ç¡®è®¤å®ä½“å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'ç¡®è®¤å®ä½“å¤±è´¥',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/entity-recognition/fast', methods=['POST'])
@jwt_required()
def entity_recognition_fast(material_id):
    """
    å¿«é€Ÿå®ä½“è¯†åˆ«æŸ¥è¯¢
    ä»…è¯†åˆ«å®ä½“ï¼Œä¸è¿›è¡Œæ·±åº¦æœç´¢
    """
    try:
        print(f"\n{'='*80}")
        print(f"[DEBUG] ========== å¿«é€Ÿå®ä½“è¯†åˆ«å¼€å§‹ ==========")
        print(f"[DEBUG] ææ–™ID: {material_id}")
        print(f"{'='*80}\n")

        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šå½“å‰çŠ¶æ€
        print(f"[DEBUG] å½“å‰çŠ¶æ€:")
        print(f"  processing_step = {material.processing_step}")
        print(f"  entity_recognition_enabled = {material.entity_recognition_enabled}")
        print(f"  entity_recognition_mode = {material.entity_recognition_mode}")
        print(f"  entity_recognition_triggered = {material.entity_recognition_triggered}")

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤ææ–™'}), 403

        # ç¡®ä¿æœ‰OCRç»“æœ
        if not material.translation_text_info:
            return jsonify({'success': False, 'error': 'è¯·å…ˆå®ŒæˆOCRè¯†åˆ«'}), 400

        # è§£æOCRç»“æœ
        ocr_result = json.loads(material.translation_text_info)

        # â­ 1. è®¾ç½®çŠ¶æ€ä¸ºè¯†åˆ«ä¸­
        material.processing_step = ProcessingStep.ENTITY_RECOGNIZING.value
        material.entity_recognition_triggered = True
        db.session.commit()

        # WebSocketæ¨é€çŠ¶æ€æ›´æ–°
        if WEBSOCKET_ENABLED:
            emit_material_updated(
                material.client_id,
                material.id,
                processing_step=material.processing_step,
                material=material.to_dict()  # âœ… ä¼ é€’å®Œæ•´çš„materialå¯¹è±¡
            )

        # 2. è°ƒç”¨å¿«é€Ÿå®ä½“è¯†åˆ«æœåŠ¡
        from entity_recognition_service import EntityRecognitionService
        entity_service = EntityRecognitionService()
        entity_result = entity_service.recognize_entities(ocr_result, mode="fast")

        if entity_result.get('success'):
            print(f"\n[DEBUG] ========== è®¾ç½®çŠ¶æ€ä¸º entity_pending_confirm ==========")

            # â­ 3. ä¿å­˜ç»“æœå¹¶è®¾ç½®çŠ¶æ€ä¸ºç­‰å¾…ç¡®è®¤
            material.entity_recognition_result = json.dumps(entity_result, ensure_ascii=False)
            material.processing_step = ProcessingStep.ENTITY_PENDING_CONFIRM.value  # âœ… å…³é”®ï¼šè®¾ç½®ä¸ºå¾…ç¡®è®¤
            db.session.commit()

            print(f"[DEBUG] âœ… å·²è®¾ç½®: processing_step = {material.processing_step}")
            print(f"[DEBUG] âœ… å·²ä¿å­˜: entity_recognition_mode = {material.entity_recognition_mode}")
            print(f"[DEBUG] âœ… å·²ä¿å­˜: entity_recognition_result åŒ…å« {entity_result.get('total_entities', 0)} ä¸ªå®ä½“")

            # â­ 4. WebSocketæ¨é€æ›´æ–°ï¼ˆåŒ…å«å®Œæ•´materialå¯¹è±¡ï¼‰
            material_dict = material.to_dict()

            print(f"\n[DEBUG] ========== å‡†å¤‡æ¨é€ WebSocket ==========")
            print(f"[DEBUG] æ¨é€æ•°æ®:")
            print(f"  processingStep = {material_dict.get('processingStep')}")
            print(f"  entityRecognitionMode = {material_dict.get('entityRecognitionMode')}")
            print(f"  entityRecognitionEnabled = {material_dict.get('entityRecognitionEnabled')}")
            print(f"  entityRecognitionResult åŒ…å«å®ä½“æ•°: {len(material_dict.get('entityRecognitionResult', {}).get('entities', []))}")
            print(f"  client_id = {material.client_id}")
            print(f"  material_id = {material.id}")

            if WEBSOCKET_ENABLED:
                emit_material_updated(
                    material.client_id,
                    material.id,
                    processing_step=material.processing_step,
                    material=material_dict  # âœ… ä¼ é€’å®Œæ•´çš„materialå¯¹è±¡
                )
                print(f"[DEBUG] âœ… WebSocketå·²æ¨é€")

            log_message(f"å¿«é€Ÿå®ä½“è¯†åˆ«å®Œæˆ: {material.name}, è¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“", "INFO")

            return jsonify({
                'success': True,
                'result': entity_result,
                'mode': 'fast',
                'material': material.to_dict(),  # âœ… è¿”å›å®Œæ•´materialå¯¹è±¡
                'message': 'å¿«é€Ÿè¯†åˆ«å®Œæˆï¼Œæ‚¨å¯ä»¥é€‰æ‹©AIæ·±åº¦æŸ¥è¯¢æˆ–äººå·¥è°ƒæ•´'
            })
        else:
            log_message(f"å¿«é€Ÿå®ä½“è¯†åˆ«å¤±è´¥: {material.name}, é”™è¯¯: {entity_result.get('error')}", "ERROR")

            return jsonify({
                'success': False,
                'error': entity_result.get('error', 'å¿«é€Ÿè¯†åˆ«å¤±è´¥'),
                'recoverable': entity_result.get('recoverable', False)
            }), 500

    except Exception as e:
        log_message(f"å¿«é€Ÿå®ä½“è¯†åˆ«å¼‚å¸¸: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'å¿«é€Ÿå®ä½“è¯†åˆ«å¼‚å¸¸',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/entity-recognition/deep', methods=['POST'])
@jwt_required()
def entity_recognition_deep(material_id):
    """
    æ·±åº¦å®ä½“è¯†åˆ«æŸ¥è¯¢ï¼ˆå…¨è‡ªåŠ¨ï¼‰
    è¿›è¡Œå®Œæ•´çš„Googleæœç´¢å’Œå®˜ç½‘åˆ†æï¼Œè·å–å‡†ç¡®çš„å®˜æ–¹è‹±æ–‡åç§°
    """
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤ææ–™'}), 403

        # ç¡®ä¿æœ‰OCRç»“æœ
        if not material.translation_text_info:
            return jsonify({'success': False, 'error': 'è¯·å…ˆå®ŒæˆOCRè¯†åˆ«'}), 400

        # è§£æOCRç»“æœ
        ocr_result = json.loads(material.translation_text_info)

        # â­ 1. è®¾ç½®çŠ¶æ€ä¸ºè¯†åˆ«ä¸­
        material.processing_step = ProcessingStep.ENTITY_RECOGNIZING.value
        material.entity_recognition_triggered = True
        db.session.commit()

        # WebSocketæ¨é€çŠ¶æ€æ›´æ–°
        if WEBSOCKET_ENABLED:
            emit_material_updated(
                material.client_id,
                material.id,
                processing_step=material.processing_step,
                material=material.to_dict()  # âœ… ä¼ é€’å®Œæ•´çš„materialå¯¹è±¡
            )

        # 2. è°ƒç”¨æ·±åº¦å®ä½“è¯†åˆ«æœåŠ¡
        from entity_recognition_service import EntityRecognitionService
        entity_service = EntityRecognitionService()
        entity_result = entity_service.recognize_entities(ocr_result, mode="deep")

        if entity_result.get('success'):
            # â­ 3. ä¿å­˜æ·±åº¦è¯†åˆ«ç»“æœå¹¶è‡ªåŠ¨ç¡®è®¤
            material.entity_recognition_result = json.dumps(entity_result, ensure_ascii=False)
            material.entity_recognition_confirmed = True  # æ·±åº¦æŸ¥è¯¢è‡ªåŠ¨ç¡®è®¤
            material.processing_step = ProcessingStep.ENTITY_CONFIRMED.value

            # ä¿å­˜translationGuidanceï¼ˆä»å®ä½“ç»“æœä¸­æå–ï¼‰
            if entity_result.get('translationGuidance'):
                user_edits = {
                    'entities': entity_result.get('entities', []),
                    'translationGuidance': entity_result.get('translationGuidance', {}),
                    'confirmedAt': datetime.utcnow().isoformat()
                }
                material.entity_user_edits = json.dumps(user_edits, ensure_ascii=False)

            db.session.commit()

            # â­ 4. WebSocketæ¨é€æ›´æ–°
            if WEBSOCKET_ENABLED:
                emit_material_updated(
                    material.client_id,
                    material.id,
                    processing_step=material.processing_step,
                    material=material.to_dict()  # âœ… ä¼ é€’å®Œæ•´çš„materialå¯¹è±¡
                )

            # ä¿å­˜æ—¥å¿—
            entity_service.save_entity_recognition_log(
                material_id=material.id,
                material_name=material.name,
                ocr_result=ocr_result,
                entity_result=entity_result
            )

            log_message(f"æ·±åº¦å®ä½“è¯†åˆ«å®Œæˆ: {material.name}, è¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“", "INFO")

            # â­ 5. è‡ªåŠ¨è§¦å‘LLMç¿»è¯‘ï¼ˆæ·±åº¦æ¨¡å¼å…¨è‡ªåŠ¨ï¼‰
            try:
                from threading import Thread
                log_message(f"æ·±åº¦æ¨¡å¼ï¼šè‡ªåŠ¨è§¦å‘LLMç¿»è¯‘: {material.name}", "INFO")

                def trigger_llm_translation():
                    with app.app_context():
                        try:
                            mat = Material.query.get(material_id)
                            if mat:
                                mat.processing_step = ProcessingStep.LLM_TRANSLATING.value
                                db.session.commit()

                                if WEBSOCKET_ENABLED:
                                    emit_llm_started(material_id, progress=70)

                            baidu_result = json.loads(mat.translation_text_info)
                            regions = baidu_result.get('regions', [])

                            entity_guidance = None
                            if mat.entity_user_edits:
                                entity_data = json.loads(mat.entity_user_edits)
                                entity_guidance = entity_data.get('translationGuidance', {})

                            from llm_service import LLMTranslationService
                            llm_service = LLMTranslationService(output_folder='outputs')
                            llm_translations = llm_service.optimize_translations(regions, entity_guidance=entity_guidance)

                            mat.llm_translation_result = json.dumps(llm_translations, ensure_ascii=False)
                            mat.processing_step = ProcessingStep.LLM_TRANSLATED.value
                            mat.processing_progress = 100
                            mat.status = MaterialStatus.TRANSLATED.value
                            db.session.commit()

                            if WEBSOCKET_ENABLED:
                                emit_llm_completed(material_id, llm_translations, progress=100)

                            log_message(f"æ·±åº¦æ¨¡å¼ï¼šè‡ªåŠ¨LLMç¿»è¯‘å®Œæˆ: {mat.name}", "SUCCESS")

                        except Exception as e:
                            log_message(f"æ·±åº¦æ¨¡å¼ï¼šè‡ªåŠ¨LLMç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
                            import traceback
                            traceback.print_exc()

                            mat = Material.query.get(material_id)
                            if mat:
                                mat.status = MaterialStatus.FAILED.value
                                mat.processing_step = ProcessingStep.FAILED.value
                                mat.translation_error = f"LLMç¿»è¯‘å¤±è´¥: {str(e)}"
                                db.session.commit()

                thread = Thread(target=trigger_llm_translation)
                thread.daemon = True
                thread.start()

            except Exception as e:
                log_message(f"æ·±åº¦æ¨¡å¼ï¼šå¯åŠ¨LLMç¿»è¯‘çº¿ç¨‹å¤±è´¥: {str(e)}", "WARNING")

            return jsonify({
                'success': True,
                'result': entity_result,
                'mode': 'deep',
                'material': material.to_dict(),  # âœ… è¿”å›å®Œæ•´materialå¯¹è±¡
                'autoStartedLLM': True,  # âœ… å‘ŠçŸ¥å‰ç«¯å·²è‡ªåŠ¨å¯åŠ¨LLM
                'message': 'æ·±åº¦è¯†åˆ«å®Œæˆï¼Œå·²è‡ªåŠ¨ç¡®è®¤ï¼ŒLLMç¿»è¯‘å·²è‡ªåŠ¨å¯åŠ¨'
            })
        else:
            log_message(f"æ·±åº¦å®ä½“è¯†åˆ«å¤±è´¥: {material.name}, é”™è¯¯: {entity_result.get('error')}", "ERROR")

            return jsonify({
                'success': False,
                'error': entity_result.get('error', 'æ·±åº¦è¯†åˆ«å¤±è´¥'),
                'recoverable': entity_result.get('recoverable', False)
            }), 500

    except Exception as e:
        log_message(f"æ·±åº¦å®ä½“è¯†åˆ«å¼‚å¸¸: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'æ·±åº¦å®ä½“è¯†åˆ«å¼‚å¸¸',
            'message': str(e)
        }), 500


@app.route('/api/pdf-sessions/<session_id>/entity-recognition/fast', methods=['POST'])
@jwt_required()
def pdf_session_entity_recognition_fast(session_id):
    """
    PDF Session æ•´ä½“å®ä½“è¯†åˆ«
    ä½¿ç”¨æ•´ä¸ªPDFæ‰€æœ‰é¡µé¢çš„OCRç»“æœä¸€èµ·è¿›è¡Œå®ä½“è¯†åˆ«
    """
    try:
        print(f"\n{'='*80}")
        print(f"[PDF Entity] PDF Session æ•´ä½“å®ä½“è¯†åˆ«å¼€å§‹")
        print(f"[PDF Entity] Session ID: {session_id}")
        print(f"{'='*80}\n")

        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        # è·å–è¯¥PDF Sessionçš„æ‰€æœ‰é¡µé¢
        pages = Material.query.filter_by(pdf_session_id=session_id).order_by(Material.pdf_page_number).all()

        if not pages:
            return jsonify({'success': False, 'error': 'PDF Sessionä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™ï¼ˆæ£€æŸ¥ç¬¬ä¸€é¡µï¼‰
        client = Client.query.get(pages[0].client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤PDF'}), 403

        print(f"[PDF Entity] æ‰¾åˆ° {len(pages)} ä¸ªé¡µé¢")

        # æ£€æŸ¥æ‰€æœ‰é¡µé¢æ˜¯å¦éƒ½å®Œæˆäº†OCR
        all_ocr_completed = all(p.translation_text_info for p in pages)
        if not all_ocr_completed:
            not_completed = [p.pdf_page_number for p in pages if not p.translation_text_info]
            print(f"[PDF Entity] éƒ¨åˆ†é¡µé¢æœªå®ŒæˆOCR: {not_completed}")
            return jsonify({
                'success': False,
                'error': f'éƒ¨åˆ†é¡µé¢æœªå®ŒæˆOCR: {not_completed}',
                'not_completed_pages': not_completed
            }), 400

        # åˆå¹¶æ‰€æœ‰é¡µé¢çš„OCRç»“æœ
        print(f"[PDF Entity] åˆå¹¶æ‰€æœ‰é¡µé¢çš„OCRç»“æœ...")
        merged_ocr_result = {'regions': []}

        for page in pages:
            ocr_result = json.loads(page.translation_text_info)
            regions = ocr_result.get('regions', [])
            merged_ocr_result['regions'].extend(regions)

        total_regions = len(merged_ocr_result['regions'])
        print(f"[PDF Entity] åˆå¹¶åå…± {total_regions} ä¸ªæ–‡æœ¬åŒºåŸŸ")

        # è®¾ç½®æ‰€æœ‰é¡µé¢çŠ¶æ€ä¸ºè¯†åˆ«ä¸­
        for page in pages:
            page.processing_step = ProcessingStep.ENTITY_RECOGNIZING.value
            page.entity_recognition_triggered = True
        db.session.commit()

        # WebSocketæ¨é€çŠ¶æ€æ›´æ–°ï¼ˆç¬¬ä¸€é¡µï¼‰
        if WEBSOCKET_ENABLED:
            emit_material_updated(
                pages[0].client_id,
                pages[0].id,
                processing_step=ProcessingStep.ENTITY_RECOGNIZING.value,
                material=pages[0].to_dict()
            )

        # è°ƒç”¨å¿«é€Ÿå®ä½“è¯†åˆ«æœåŠ¡
        from entity_recognition_service import EntityRecognitionService
        entity_service = EntityRecognitionService()
        entity_result = entity_service.recognize_entities(merged_ocr_result, mode="fast")

        if entity_result.get('success'):
            print(f"[PDF Entity] è¯†åˆ«æˆåŠŸï¼Œè¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“")

            # ä¿å­˜ç»“æœåˆ°æ‰€æœ‰é¡µé¢
            result_json = json.dumps(entity_result, ensure_ascii=False)
            for page in pages:
                page.entity_recognition_result = result_json
                page.processing_step = ProcessingStep.ENTITY_PENDING_CONFIRM.value

            db.session.commit()

            # WebSocketæ¨é€æ›´æ–°ï¼ˆåªæ¨é€ç¬¬ä¸€é¡µï¼Œå‰ç«¯ä¼šæ˜¾ç¤ºModalï¼‰
            if WEBSOCKET_ENABLED:
                emit_material_updated(
                    pages[0].client_id,
                    pages[0].id,
                    processing_step=ProcessingStep.ENTITY_PENDING_CONFIRM.value,
                    material=pages[0].to_dict()
                )

            log_message(f"PDF Sessionæ•´ä½“å®ä½“è¯†åˆ«å®Œæˆ: {session_id}, å…±{len(pages)}é¡µ, è¯†åˆ«åˆ° {entity_result.get('total_entities', 0)} ä¸ªå®ä½“", "INFO")

            return jsonify({
                'success': True,
                'result': entity_result,
                'session_id': session_id,
                'total_pages': len(pages),
                'total_regions': total_regions,
                'message': f'PDFæ•´ä½“è¯†åˆ«å®Œæˆï¼ˆ{len(pages)}é¡µï¼‰ï¼Œè¯†åˆ«åˆ°{entity_result.get("total_entities", 0)}ä¸ªå®ä½“'
            })
        else:
            log_message(f"PDF Sessionæ•´ä½“å®ä½“è¯†åˆ«å¤±è´¥: {session_id}, é”™è¯¯: {entity_result.get('error')}", "ERROR")

            # æ¢å¤æ‰€æœ‰é¡µé¢çŠ¶æ€
            for page in pages:
                page.processing_step = ProcessingStep.TRANSLATED.value
            db.session.commit()

            return jsonify({
                'success': False,
                'error': entity_result.get('error', 'PDFæ•´ä½“è¯†åˆ«å¤±è´¥'),
                'recoverable': entity_result.get('recoverable', False)
            }), 500

    except Exception as e:
        log_message(f"PDF Sessionæ•´ä½“å®ä½“è¯†åˆ«å¼‚å¸¸: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'PDFæ•´ä½“è¯†åˆ«å¼‚å¸¸',
            'message': str(e)
        }), 500


@app.route('/api/pdf-sessions/<session_id>/entity-recognition/deep', methods=['POST'])
@jwt_required()
def pdf_session_entity_recognition_deep(session_id):
    """
    PDF Session æ•´ä½“æ·±åº¦å®ä½“è¯†åˆ«ï¼ˆAIä¼˜åŒ–ï¼‰
    å¯¹æ•´ä¸ªPDFçš„å®ä½“è¿›è¡Œæ·±åº¦æŸ¥è¯¢ï¼ŒæŸ¥æ‰¾å®˜æ–¹è‹±æ–‡åç§°
    """
    try:
        print(f"\n{'='*80}")
        print(f"[PDF Entity Deep] PDF Session æ•´ä½“æ·±åº¦è¯†åˆ«å¼€å§‹")
        print(f"[PDF Entity Deep] Session ID: {session_id}")
        print(f"{'='*80}\n")

        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        # è·å–è¯¥PDF Sessionçš„æ‰€æœ‰é¡µé¢
        pages = Material.query.filter_by(pdf_session_id=session_id).order_by(Material.pdf_page_number).all()

        if not pages:
            return jsonify({'success': False, 'error': 'PDF Sessionä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™ï¼ˆæ£€æŸ¥ç¬¬ä¸€é¡µï¼‰
        client = Client.query.get(pages[0].client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤PDF'}), 403

        print(f"[PDF Entity Deep] æ‰¾åˆ° {len(pages)} ä¸ªé¡µé¢")

        # è·å–è¯·æ±‚ä¸­çš„å®ä½“åˆ—è¡¨
        data = request.get_json()
        entities = data.get('entities', [])

        if not entities:
            return jsonify({'success': False, 'error': 'æœªæä¾›å®ä½“åˆ—è¡¨'}), 400

        print(f"[PDF Entity Deep] æ”¶åˆ° {len(entities)} ä¸ªå®ä½“å¾…ä¼˜åŒ–")

        # è°ƒç”¨æ·±åº¦å®ä½“è¯†åˆ«æœåŠ¡
        from entity_recognition_service import EntityRecognitionService
        entity_service = EntityRecognitionService()

        # æå–ä¸­æ–‡å®ä½“åç§°åˆ—è¡¨
        entity_names = []
        for entity in entities:
            chinese_name = entity.get('chinese_name') or entity.get('entity')
            if chinese_name:
                entity_names.append(chinese_name)

        # ä½¿ç”¨æ·±åº¦æ¨¡å¼è¿›è¡Œè¯†åˆ«
        entity_result = entity_service.deep_query_entities(entity_names)

        if entity_result.get('success'):
            print(f"[PDF Entity Deep] æ·±åº¦è¯†åˆ«æˆåŠŸï¼Œä¼˜åŒ–äº† {len(entity_result.get('entities', []))} ä¸ªå®ä½“")

            # ä¿å­˜ç»“æœåˆ°æ‰€æœ‰é¡µé¢
            result_json = json.dumps(entity_result, ensure_ascii=False)
            for page in pages:
                page.entity_recognition_result = result_json

            db.session.commit()

            # WebSocketæ¨é€æ›´æ–°ï¼ˆåªæ¨é€ç¬¬ä¸€é¡µï¼‰
            if WEBSOCKET_ENABLED:
                emit_material_updated(
                    pages[0].client_id,
                    pages[0].id,
                    processing_step=ProcessingStep.ENTITY_PENDING_CONFIRM.value,
                    material=pages[0].to_dict()
                )

            log_message(f"PDF Sessionæ•´ä½“æ·±åº¦è¯†åˆ«å®Œæˆ: {session_id}, å…±{len(pages)}é¡µ, ä¼˜åŒ–äº† {len(entity_result.get('entities', []))} ä¸ªå®ä½“", "INFO")

            return jsonify({
                'success': True,
                'result': entity_result,
                'session_id': session_id,
                'total_pages': len(pages),
                'message': f'PDFæ•´ä½“æ·±åº¦è¯†åˆ«å®Œæˆï¼ˆ{len(pages)}é¡µï¼‰'
            })
        else:
            log_message(f"PDF Sessionæ•´ä½“æ·±åº¦è¯†åˆ«å¤±è´¥: {session_id}, é”™è¯¯: {entity_result.get('error')}", "ERROR")
            return jsonify({
                'success': False,
                'error': entity_result.get('error', 'PDFæ•´ä½“æ·±åº¦è¯†åˆ«å¤±è´¥'),
                'recoverable': entity_result.get('recoverable', False)
            }), 500

    except Exception as e:
        log_message(f"PDF Sessionæ•´ä½“æ·±åº¦è¯†åˆ«å¼‚å¸¸: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'PDFæ•´ä½“æ·±åº¦è¯†åˆ«å¼‚å¸¸',
            'message': str(e)
        }), 500


@app.route('/api/pdf-sessions/<session_id>/confirm-entities', methods=['POST'])
@jwt_required()
def pdf_session_confirm_entities(session_id):
    """
    PDF Session ç¡®è®¤å®ä½“è¯†åˆ«ç»“æœ
    ä¸ºæ•´ä¸ªPDF Sessionçš„æ‰€æœ‰é¡µé¢åº”ç”¨ç›¸åŒçš„å®ä½“ç¿»è¯‘æŒ‡å¯¼ï¼Œå¹¶è§¦å‘æ‰€æœ‰é¡µé¢çš„LLMç¿»è¯‘
    """
    try:
        print(f"\n{'='*80}")
        print(f"[PDF Entity Confirm] PDF Session ç¡®è®¤å®ä½“å¼€å§‹")
        print(f"[PDF Entity Confirm] Session ID: {session_id}")
        print(f"{'='*80}\n")

        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        # è·å–è¯¥PDF Sessionçš„æ‰€æœ‰é¡µé¢
        pages = Material.query.filter_by(pdf_session_id=session_id).order_by(Material.pdf_page_number).all()

        if not pages:
            return jsonify({'success': False, 'error': 'PDF Sessionä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™ï¼ˆæ£€æŸ¥ç¬¬ä¸€é¡µï¼‰
        client = Client.query.get(pages[0].client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤PDF'}), 403

        print(f"[PDF Entity Confirm] æ‰¾åˆ° {len(pages)} ä¸ªé¡µé¢")

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        entities = data.get('entities', [])
        translation_guidance = data.get('translationGuidance', {})

        # ä¿å­˜ç”¨æˆ·ç¼–è¾‘çš„å®ä½“ä¿¡æ¯
        user_edits = {
            'entities': entities,
            'translationGuidance': translation_guidance,
            'confirmedAt': datetime.utcnow().isoformat()
        }
        user_edits_json = json.dumps(user_edits, ensure_ascii=False)

        # ä¸ºæ‰€æœ‰é¡µé¢åº”ç”¨ç›¸åŒçš„å®ä½“æ•°æ®
        for page in pages:
            page.entity_user_edits = user_edits_json
            page.entity_recognition_confirmed = True
            page.processing_step = ProcessingStep.ENTITY_CONFIRMED.value

        db.session.commit()

        log_message(f"PDF Sessionå®ä½“ç¡®è®¤å®Œæˆ: {session_id}, å…±{len(pages)}é¡µ", "INFO")

        # â­ è‡ªåŠ¨è§¦å‘æ‰€æœ‰é¡µé¢çš„LLMç¿»è¯‘
        try:
            from threading import Thread
            log_message(f"è‡ªåŠ¨è§¦å‘PDF Sessionæ‰€æœ‰é¡µé¢çš„LLMç¿»è¯‘: {session_id}", "INFO")

            def trigger_all_llm_translations():
                with app.app_context():
                    try:
                        session_pages = Material.query.filter_by(pdf_session_id=session_id).order_by(Material.pdf_page_number).all()

                        for page in session_pages:
                            try:
                                print(f"[PDF LLM] å¼€å§‹ç¿»è¯‘é¡µé¢ {page.pdf_page_number}/{len(session_pages)}")

                                # æ›´æ–°çŠ¶æ€ä¸ºLLMç¿»è¯‘ä¸­
                                page.processing_step = ProcessingStep.LLM_TRANSLATING.value
                                db.session.commit()

                                # WebSocketæ¨é€
                                if WEBSOCKET_ENABLED:
                                    emit_llm_started(page.id, progress=70)

                                # æ‰§è¡ŒLLMç¿»è¯‘
                                baidu_result = json.loads(page.translation_text_info)
                                regions = baidu_result.get('regions', [])

                                # è¯»å–å®ä½“è¯†åˆ«æŒ‡å¯¼
                                entity_guidance = None
                                if page.entity_user_edits:
                                    entity_data = json.loads(page.entity_user_edits)
                                    entity_guidance = entity_data.get('translationGuidance', {})

                                from llm_service import LLMTranslationService
                                llm_service = LLMTranslationService(output_folder='outputs')
                                llm_translations = llm_service.optimize_translations(regions, entity_guidance=entity_guidance)

                                # ä¿å­˜ç»“æœ
                                page.llm_translation_result = json.dumps(llm_translations, ensure_ascii=False)
                                page.processing_step = ProcessingStep.LLM_TRANSLATED.value
                                page.processing_progress = 100
                                page.status = MaterialStatus.TRANSLATED.value
                                db.session.commit()

                                # WebSocketæ¨é€å®Œæˆ
                                if WEBSOCKET_ENABLED:
                                    emit_llm_completed(page.id, llm_translations, progress=100)

                                print(f"[PDF LLM] é¡µé¢ {page.pdf_page_number} ç¿»è¯‘å®Œæˆ")

                            except Exception as page_error:
                                log_message(f"é¡µé¢ {page.pdf_page_number} LLMç¿»è¯‘å¤±è´¥: {str(page_error)}", "ERROR")
                                import traceback
                                traceback.print_exc()

                                # æ ‡è®°å¤±è´¥
                                page.status = MaterialStatus.FAILED.value
                                page.processing_step = ProcessingStep.FAILED.value
                                page.translation_error = f"LLMç¿»è¯‘å¤±è´¥: {str(page_error)}"
                                db.session.commit()

                        log_message(f"PDF Sessionæ‰€æœ‰é¡µé¢LLMç¿»è¯‘å®Œæˆ: {session_id}", "SUCCESS")

                    except Exception as e:
                        log_message(f"PDF Session LLMç¿»è¯‘å¼‚å¸¸: {str(e)}", "ERROR")
                        import traceback
                        traceback.print_exc()

            thread = Thread(target=trigger_all_llm_translations)
            thread.daemon = True
            thread.start()

        except Exception as e:
            log_message(f"å¯åŠ¨PDF Session LLMç¿»è¯‘çº¿ç¨‹å¤±è´¥: {str(e)}", "WARNING")

        return jsonify({
            'success': True,
            'message': f'PDF Sessionå®ä½“ç¡®è®¤æˆåŠŸï¼ˆ{len(pages)}é¡µï¼‰ï¼ŒLLMç¿»è¯‘å·²è‡ªåŠ¨å¯åŠ¨',
            'session_id': session_id,
            'total_pages': len(pages),
            'autoStartedLLM': True
        })

    except Exception as e:
        log_message(f"PDF Sessionç¡®è®¤å®ä½“å¤±è´¥: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'PDF Sessionç¡®è®¤å®ä½“å¤±è´¥',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/entity-recognition/manual-adjust', methods=['POST'])
@jwt_required()
def entity_recognition_manual_adjust(material_id):
    """
    äººå·¥è°ƒæ•´æ¨¡å¼ï¼ˆAIä¼˜åŒ–ï¼‰
    åŸºäºfastæŸ¥è¯¢ç»“æœè¿›è¡ŒAIä¼˜åŒ–

    è¯·æ±‚ä½“:
        {
            "fast_results": [...]  # fastæŸ¥è¯¢çš„ç»“æœ
        }
    """
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        if not user:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

        material = Material.query.get(material_id)
        if not material:
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        # éªŒè¯æƒé™
        client = Client.query.get(material.client_id)
        if not client or client.user_id != current_user_id:
            return jsonify({'success': False, 'error': 'æ— æƒé™æ“ä½œæ­¤ææ–™'}), 403

        # ç¡®ä¿æœ‰OCRç»“æœ
        if not material.translation_text_info:
            return jsonify({'success': False, 'error': 'è¯·å…ˆå®ŒæˆOCRè¯†åˆ«'}), 400

        # è§£æOCRç»“æœ
        ocr_result = json.loads(material.translation_text_info)

        # è·å–fastæŸ¥è¯¢ç»“æœ
        data = request.get_json()
        fast_results = data.get('fast_results', [])
        ocr_result['fast_results'] = fast_results  # å°†fastç»“æœæ·»åŠ åˆ°OCRç»“æœä¸­

        # è°ƒç”¨äººå·¥è°ƒæ•´æ¨¡å¼æœåŠ¡
        from entity_recognition_service import EntityRecognitionService
        entity_service = EntityRecognitionService()
        entity_result = entity_service.recognize_entities(ocr_result, mode="manual_adjust")

        if entity_result.get('success'):
            log_message(f"äººå·¥è°ƒæ•´æ¨¡å¼å®Œæˆ: {material.name}, ä¼˜åŒ–äº† {entity_result.get('total_entities', 0)} ä¸ªå®ä½“", "INFO")

            return jsonify({
                'success': True,
                'result': entity_result,
                'mode': 'manual_adjust',
                'message': 'AIä¼˜åŒ–å®Œæˆï¼Œè¯·ç¡®è®¤åè¿›è¡ŒLLMç¿»è¯‘'
            })
        else:
            log_message(f"äººå·¥è°ƒæ•´æ¨¡å¼å¤±è´¥: {material.name}, é”™è¯¯: {entity_result.get('error')}", "ERROR")

            return jsonify({
                'success': False,
                'error': entity_result.get('error', 'äººå·¥è°ƒæ•´æ¨¡å¼å¤±è´¥'),
                'recoverable': entity_result.get('recoverable', False)
            }), 500

    except Exception as e:
        log_message(f"äººå·¥è°ƒæ•´æ¨¡å¼å¼‚å¸¸: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'äººå·¥è°ƒæ•´æ¨¡å¼å¼‚å¸¸',
            'message': str(e)
        }), 500


@app.route('/api/materials/<material_id>/llm-translate', methods=['POST'])
@jwt_required()
def llm_translate_material(material_id):
    """ä½¿ç”¨LLMä¼˜åŒ–ææ–™çš„ç¿»è¯‘"""
    try:
        log_message(f"========== å¼€å§‹LLMç¿»è¯‘ä¼˜åŒ– ==========", "INFO")
        log_message(f"ææ–™ID: {material_id}", "INFO")

        # âœ… æ£€æŸ¥ç¿»è¯‘é”ï¼Œé˜²æ­¢é‡å¤LLMä¼˜åŒ–è¯·æ±‚
        is_locked, locked_material = check_translation_lock(material_id)
        if is_locked:
            log_message(f"ææ–™æ­£åœ¨ç¿»è¯‘ä¸­ï¼Œæ‹’ç»LLMä¼˜åŒ–è¯·æ±‚: {material_id}", "WARN")
            return jsonify({
                'success': False,
                'error': 'è¯¥ææ–™æ­£åœ¨ç¿»è¯‘ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•',
                'status': locked_material.status
            }), 409

        user_id = get_jwt_identity()
        log_message(f"ç”¨æˆ·ID: {user_id}", "INFO")

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            log_message(f"ææ–™ä¸å­˜åœ¨æˆ–æ— æƒé™: {material_id}", "ERROR")
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        log_message(f"ææ–™åç§°: {material.name}", "INFO")

        # å¦‚æœå·²ç»æœ‰LLMç¿»è¯‘ç»“æœï¼Œç›´æ¥è¿”å›ï¼ˆé¿å…é‡å¤è°ƒç”¨ï¼‰
        if material.llm_translation_result:
            log_message(f"ææ–™ {material.name} å·²æœ‰LLMç¿»è¯‘ç»“æœï¼Œç›´æ¥è¿”å›", "INFO")
            llm_translations = json.loads(material.llm_translation_result)
            return jsonify({
                'success': True,
                'llm_translations': llm_translations,
                'message': f'å·²æœ‰ {len(llm_translations)} ä¸ªä¼˜åŒ–ç»“æœï¼ˆæ¥è‡ªç¼“å­˜ï¼‰',
                'from_cache': True
            })

        # æ£€æŸ¥å®ä½“è¯†åˆ«çŠ¶æ€ï¼ˆå¦‚æœå¯ç”¨äº†å®ä½“è¯†åˆ«ï¼Œå¿…é¡»å…ˆç¡®è®¤å®ä½“ï¼‰
        if material.entity_recognition_enabled:
            if not material.entity_recognition_confirmed:
                log_message(f"ææ–™ {material.name} å¯ç”¨äº†å®ä½“è¯†åˆ«ä½†å°šæœªç¡®è®¤ï¼Œæ‹’ç»LLMç¿»è¯‘", "ERROR")
                return jsonify({
                    'success': False,
                    'error': 'è¯·å…ˆå®Œæˆå®ä½“è¯†åˆ«ç¡®è®¤',
                    'message': 'å®ä½“è¯†åˆ«å·²å¯ç”¨ï¼Œéœ€è¦å…ˆç¡®è®¤å®ä½“ä¿¡æ¯åæ‰èƒ½è¿›è¡ŒLLMç¿»è¯‘',
                    'requireEntityConfirmation': True,
                    'processingStep': material.processing_step
                }), 400

        # è·å–ç™¾åº¦ç¿»è¯‘ç»“æœ
        if not material.translation_text_info:
            log_message("ææ–™ç¼ºå°‘ç™¾åº¦ç¿»è¯‘ç»“æœ", "ERROR")
            return jsonify({
                'success': False,
                'error': 'è¯·å…ˆå®Œæˆç™¾åº¦ç¿»è¯‘'
            }), 400

        baidu_result = json.loads(material.translation_text_info)
        regions = baidu_result.get('regions', [])
        log_message(f"ç™¾åº¦ç¿»è¯‘regionsæ•°é‡: {len(regions)}", "INFO")

        if not regions:
            log_message("ç™¾åº¦ç¿»è¯‘ç»“æœä¸ºç©º", "ERROR")
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰å¯ç¿»è¯‘çš„æ–‡æœ¬åŒºåŸŸ'
            }), 400

        # ä½¿ç”¨LLMä¼˜åŒ–
        log_message(f"å¼€å§‹è°ƒç”¨LLMæœåŠ¡ä¼˜åŒ–ç¿»è¯‘...", "INFO")

        # âœ… WebSocket æ¨é€ï¼šLLM ç¿»è¯‘å¼€å§‹
        if WEBSOCKET_ENABLED:
            emit_llm_started(material_id, progress=66)

        # è·å–å®ä½“ä¿¡æ¯ï¼ˆå¦‚æœå·²ç¡®è®¤ï¼‰
        entity_guidance = None
        if material.entity_recognition_enabled and material.entity_recognition_confirmed:
            if material.entity_user_edits:
                try:
                    entity_data = json.loads(material.entity_user_edits)
                    entity_guidance = entity_data.get('translationGuidance', {})
                    log_message(f"ä½¿ç”¨å®ä½“è¯†åˆ«ä¿¡æ¯æŒ‡å¯¼LLMç¿»è¯‘: {len(entity_guidance)} ç±»å®ä½“", "INFO")
                except:
                    log_message("è§£æå®ä½“ä¿¡æ¯å¤±è´¥ï¼Œå¿½ç•¥", "WARN")

        from llm_service import LLMTranslationService
        llm_service = LLMTranslationService(output_folder='outputs')

        log_message(f"LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹ä¼˜åŒ– {len(regions)} ä¸ªåŒºåŸŸ", "INFO")
        llm_translations = llm_service.optimize_translations(regions, entity_guidance=entity_guidance)
        log_message(f"LLMä¼˜åŒ–å®Œæˆï¼Œè¿”å› {len(llm_translations)} ä¸ªç¿»è¯‘ç»“æœ", "SUCCESS")

        # ä¿å­˜LLMç¿»è¯‘æ—¥å¿—å’Œå¯¹æ¯”æŠ¥å‘Šï¼ˆä¸Referenceé¡¹ç›®ä¸€è‡´ï¼‰
        log_files = llm_service.save_llm_translation_log(
            material.name,
            regions,
            llm_translations
        )

        # ä¿å­˜LLMç¿»è¯‘ç»“æœåˆ°æ•°æ®åº“
        # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€ï¼ˆä¼šè‡ªåŠ¨æ¨é€WebSocketï¼‰
        update_material_status(
            material,
            MaterialStatus.TRANSLATED,
            llm_translation_result=json.dumps(llm_translations, ensure_ascii=False),
            processing_step=ProcessingStep.TRANSLATED.value,
            processing_progress=100
        )

        log_message(f"LLMç¿»è¯‘å®Œæˆ: {material_id}, ä¼˜åŒ–äº† {len(llm_translations)} ä¸ªåŒºåŸŸ")

        # âœ… é¢å¤–æ¨é€LLMå®Œæˆäº‹ä»¶ï¼ˆä¿ç•™ç‰¹æ®Šäº‹ä»¶ï¼‰
        if WEBSOCKET_ENABLED:
            emit_llm_completed(material_id, llm_translations, progress=100)

        result = {
            'success': True,
            'llm_translations': llm_translations,
            'message': f'æˆåŠŸä¼˜åŒ– {len(llm_translations)} ä¸ªç¿»è¯‘åŒºåŸŸ'
        }

        # æ·»åŠ æ—¥å¿—æ–‡ä»¶ä¿¡æ¯ï¼ˆä¸Referenceé¡¹ç›®ä¸€è‡´ï¼‰
        if log_files:
            result['log_files'] = log_files

        return jsonify(result)

    except Exception as e:
        db.session.rollback()
        import traceback
        error_traceback = traceback.format_exc()
        log_message(f"LLMç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
        log_message(f"é”™è¯¯å †æ ˆ:\n{error_traceback}", "ERROR")
        
        # âœ… WebSocket æ¨é€ï¼šLLM ç¿»è¯‘å¤±è´¥
        if WEBSOCKET_ENABLED:
            emit_llm_error(material_id, str(e))

        # è¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯ç»™å‰ç«¯
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__,
            'traceback': error_traceback
        }), 500

@app.route('/api/materials/<material_id>/retranslate', methods=['POST'])
@jwt_required()
def retranslate_material(material_id):
    """
    é‡æ–°ç¿»è¯‘å•ä¸ªææ–™

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. å®Œæ•´é‡æ–°ç¿»è¯‘ï¼šç™¾åº¦ç¿»è¯‘ â†’ å®ä½“è¯†åˆ«(å¯é€‰) â†’ LLMä¼˜åŒ–
    2. ä¿ç•™å®ä½“ç»“æœï¼šç™¾åº¦ç¿»è¯‘ â†’ ä½¿ç”¨ä¹‹å‰çš„å®ä½“ç»“æœ â†’ LLMä¼˜åŒ–

    è¯·æ±‚å‚æ•°ï¼š
    - preserveEntityData: bool, æ˜¯å¦ä¿ç•™ä¹‹å‰çš„å®ä½“è¯†åˆ«ç»“æœï¼ˆé»˜è®¤falseï¼‰
    - skipLLM: bool, æ˜¯å¦è·³è¿‡LLMä¼˜åŒ–ï¼Œåªåšç™¾åº¦ç¿»è¯‘ï¼ˆé»˜è®¤falseï¼Œç”¨äºéœ€è¦å…ˆåšå®ä½“è¯†åˆ«çš„æƒ…å†µï¼‰
    """
    try:
        log_message(f"========== å¼€å§‹é‡æ–°ç¿»è¯‘ææ–™ ==========", "INFO")
        log_message(f"ææ–™ID: {material_id}", "INFO")

        # è·å–è¯·æ±‚å‚æ•°
        data = request.get_json() or {}
        log_message(f"æ”¶åˆ°è¯·æ±‚æ•°æ®: {data}", "INFO")
        preserve_entity_data = data.get('preserveEntityData', False)
        skip_llm = data.get('skipLLM', False)

        log_message(f"è§£æå‚æ•°: preserveEntityData={preserve_entity_data}, skipLLM={skip_llm}", "INFO")

        # âœ… æ£€æŸ¥ç¿»è¯‘é”ï¼Œé˜²æ­¢é‡å¤ç¿»è¯‘
        is_locked, locked_material = check_translation_lock(material_id)
        if is_locked:
            log_message(f"ææ–™æ­£åœ¨ç¿»è¯‘ä¸­ï¼Œæ‹’ç»é‡å¤è¯·æ±‚: {material_id}", "WARN")
            return jsonify({
                'success': False,
                'error': 'è¯¥ææ–™æ­£åœ¨ç¿»è¯‘ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•',
                'status': locked_material.status
            }), 409

        user_id = get_jwt_identity()

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            log_message(f"ææ–™ä¸å­˜åœ¨æˆ–æ— æƒé™: {material_id}", "ERROR")
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        if material.type not in ['image', 'pdf']:
            return jsonify({'success': False, 'error': 'åªæ”¯æŒå›¾ç‰‡å’ŒPDFææ–™'}), 400

        log_message(f"ææ–™åç§°: {material.name}, ç±»å‹: {material.type}", "INFO")

        # ä¿å­˜ä¹‹å‰çš„å®ä½“æ•°æ®ï¼ˆå¦‚æœéœ€è¦ä¿ç•™ï¼‰
        previous_entity_data = None
        if preserve_entity_data:
            previous_entity_data = {
                'entity_recognition_enabled': material.entity_recognition_enabled,
                'entity_recognition_mode': material.entity_recognition_mode,
                'entity_recognition_result': material.entity_recognition_result,
                'entity_user_edits': material.entity_user_edits,
                'entity_recognition_confirmed': material.entity_recognition_confirmed,
            }
            log_message(f"ä¿ç•™ä¹‹å‰çš„å®ä½“æ•°æ®: enabled={previous_entity_data['entity_recognition_enabled']}", "INFO")

        # è°ƒç”¨Referenceæ–¹å¼çš„ç™¾åº¦ç¿»è¯‘ï¼ˆå‡½æ•°åœ¨app.pyå†…éƒ¨å®šä¹‰ï¼‰
        result = translate_image_reference(
            image_path=material.file_path,
            source_lang='zh',
            target_lang='en'
        )

        # æ£€æŸ¥APIé”™è¯¯
        error_code = result.get('error_code')
        if error_code and error_code not in [0, '0', None]:
            error_msg = result.get('error_msg', 'ç¿»è¯‘å¤±è´¥')
            log_message(f"ç™¾åº¦APIé”™è¯¯: {material.name} - {error_msg}", "ERROR")
            # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€
            update_material_status(
                material,
                MaterialStatus.FAILED,
                translation_error=error_msg
            )
            return jsonify({'success': False, 'error': error_msg}), 500

        # è§£æregionsæ•°æ®
        api_data = result.get('data', {})
        content = api_data.get('content', [])

        if not content:
            log_message(f"ç™¾åº¦ç¿»è¯‘æœªè¯†åˆ«åˆ°æ–‡å­—: {material.name}", "WARN")
            # âœ… ä½¿ç”¨ç»Ÿä¸€å‡½æ•°æ›´æ–°çŠ¶æ€
            update_material_status(
                material,
                MaterialStatus.FAILED,
                translation_error='æœªè¯†åˆ«åˆ°æ–‡å­—åŒºåŸŸ'
            )
            return jsonify({'success': False, 'error': 'æœªè¯†åˆ«åˆ°æ–‡å­—åŒºåŸŸ'}), 400

        # æ¸…é™¤æ—§çš„ç¼–è¾‘å†…å®¹ï¼Œä»åŸå§‹å›¾ç‰‡é‡æ–°å¼€å§‹
        material.edited_image_path = None
        material.final_image_path = None
        material.has_edited_version = False
        material.edited_regions = None

        # æ¸…é™¤æˆ–æ¢å¤å®ä½“æ•°æ®
        if preserve_entity_data and previous_entity_data:
            # æ¢å¤ä¹‹å‰çš„å®ä½“æ•°æ®
            material.entity_recognition_enabled = previous_entity_data['entity_recognition_enabled']
            material.entity_recognition_mode = previous_entity_data['entity_recognition_mode']
            material.entity_recognition_result = previous_entity_data['entity_recognition_result']
            material.entity_user_edits = previous_entity_data['entity_user_edits']
            material.entity_recognition_confirmed = previous_entity_data['entity_recognition_confirmed']
            log_message(f"å·²æ¢å¤ä¹‹å‰çš„å®ä½“æ•°æ®", "INFO")
        else:
            # æ¸…é™¤å®ä½“æ•°æ®
            material.entity_recognition_enabled = False
            material.entity_recognition_mode = None
            material.entity_recognition_result = None
            material.entity_user_edits = None
            material.entity_recognition_confirmed = False
            material.entity_recognition_error = None
            log_message(f"å·²æ¸…é™¤å®ä½“æ•°æ®", "INFO")

        # ä¿å­˜æ–°çš„ç™¾åº¦ç¿»è¯‘ç»“æœ
        regions_data = {'regions': content}

        # å¦‚æœè·³è¿‡LLMï¼Œåªä¿å­˜ç™¾åº¦ç¿»è¯‘ç»“æœï¼Œç­‰å¾…å®ä½“è¯†åˆ«
        if skip_llm:
            update_material_status(
                material,
                MaterialStatus.TRANSLATED,
                translation_text_info=regions_data,
                translation_error=None,
                llm_translation_result=None,  # æ¸…é™¤æ—§çš„LLMç»“æœ
                processing_step=ProcessingStep.TRANSLATED.value,
                processing_progress=66
            )

            log_message(f"ç™¾åº¦ç¿»è¯‘å®Œæˆï¼ˆè·³è¿‡LLMï¼‰: {material.name}, è¯†åˆ«äº† {len(content)} ä¸ªåŒºåŸŸ", "SUCCESS")

            return jsonify({
                'success': True,
                'material': {
                    'id': material.id,
                    'name': material.name,
                    'status': material.status,
                    'filePath': material.file_path,
                    'translationTextInfo': regions_data,
                    'llmTranslationResult': None,
                    'processingProgress': 66,
                    'processingStep': ProcessingStep.TRANSLATED.value,
                    'entityRecognitionEnabled': material.entity_recognition_enabled,
                    'entityRecognitionResult': material.entity_recognition_result,
                    'entityUserEdits': material.entity_user_edits,
                    'pdfSessionId': material.pdf_session_id,
                    'pdfPageNumber': material.pdf_page_number,
                    'pdfTotalPages': material.pdf_total_pages
                },
                'message': 'ç™¾åº¦ç¿»è¯‘å®Œæˆï¼Œç­‰å¾…å®ä½“è¯†åˆ«',
                'needEntityRecognition': True  # æç¤ºå‰ç«¯éœ€è¦è§¦å‘å®ä½“è¯†åˆ«æµç¨‹
            })

        # æ­£å¸¸æµç¨‹ï¼šç™¾åº¦ç¿»è¯‘ + LLMä¼˜åŒ–
        update_material_status(
            material,
            MaterialStatus.TRANSLATED,
            translation_text_info=regions_data,
            translation_error=None,
            processing_step=ProcessingStep.TRANSLATED.value,
            processing_progress=66
        )

        log_message(f"ç™¾åº¦ç¿»è¯‘æˆåŠŸ: {material.name}, è¯†åˆ«äº† {len(content)} ä¸ªåŒºåŸŸ", "SUCCESS")

        # è‡ªåŠ¨è§¦å‘LLMä¼˜åŒ–
        log_message(f"å¼€å§‹LLMä¼˜åŒ–ç¿»è¯‘...", "INFO")
        from llm_service import LLMTranslationService
        llm_service = LLMTranslationService(output_folder='outputs')

        # å¦‚æœæœ‰ä¿ç•™çš„å®ä½“æ•°æ®ï¼Œä½¿ç”¨å®ƒæ¥æŒ‡å¯¼LLMç¿»è¯‘
        entity_guidance = None
        if preserve_entity_data and previous_entity_data and previous_entity_data.get('entity_user_edits'):
            try:
                entity_edits = previous_entity_data['entity_user_edits']
                if isinstance(entity_edits, str):
                    entity_edits = json.loads(entity_edits)
                entity_guidance = entity_edits.get('translationGuidance')
                log_message(f"ä½¿ç”¨ä¿ç•™çš„å®ä½“æŒ‡å¯¼è¿›è¡ŒLLMç¿»è¯‘", "INFO")
            except Exception as e:
                log_message(f"è§£æå®ä½“æŒ‡å¯¼æ•°æ®å¤±è´¥: {e}", "WARN")

        llm_translations = llm_service.optimize_translations(content, entity_guidance=entity_guidance)
        log_message(f"LLMä¼˜åŒ–å®Œæˆï¼Œè¿”å› {len(llm_translations)} ä¸ªç¿»è¯‘ç»“æœ", "SUCCESS")

        # ä¿å­˜LLMç¿»è¯‘ç»“æœ
        update_material_status(
            material,
            MaterialStatus.TRANSLATED,
            llm_translation_result=json.dumps(llm_translations, ensure_ascii=False),
            processing_step=ProcessingStep.LLM_TRANSLATED.value,
            processing_progress=100
        )

        log_message(f"é‡æ–°ç¿»è¯‘å®Œæˆ: {material.name}", "SUCCESS")

        return jsonify({
            'success': True,
            'material': {
                'id': material.id,
                'name': material.name,
                'status': material.status,
                'filePath': material.file_path,
                'translationTextInfo': regions_data,
                'llmTranslationResult': llm_translations,
                'processingProgress': 100,
                'processingStep': ProcessingStep.LLM_TRANSLATED.value,
                'entityRecognitionEnabled': material.entity_recognition_enabled,
                'pdfSessionId': material.pdf_session_id,
                'pdfPageNumber': material.pdf_page_number,
                'pdfTotalPages': material.pdf_total_pages
            },
            'message': 'é‡æ–°ç¿»è¯‘æˆåŠŸ'
        })

    except Exception as e:
        db.session.rollback()
        import traceback
        error_traceback = traceback.format_exc()
        log_message(f"é‡æ–°ç¿»è¯‘å¤±è´¥: {str(e)}", "ERROR")
        log_message(f"é”™è¯¯å †æ ˆ:\n{error_traceback}", "ERROR")

        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500


@app.route('/api/materials/<material_id>/rotate', methods=['POST'])
@jwt_required()
def rotate_material(material_id):
    """æ—‹è½¬ææ–™å›¾ç‰‡90åº¦ï¼ˆåªæ—‹è½¬ï¼Œä¸é‡æ–°ç¿»è¯‘ï¼‰"""
    try:
        log_message(f"========== å¼€å§‹æ—‹è½¬å›¾ç‰‡ ==========", "INFO")
        log_message(f"ææ–™ID: {material_id}", "INFO")

        user_id = get_jwt_identity()

        # æŸ¥æ‰¾ææ–™å¹¶éªŒè¯æƒé™
        material = Material.query.join(Client).filter(
            Material.id == material_id,
            Client.user_id == user_id
        ).first()

        if not material:
            log_message(f"ææ–™ä¸å­˜åœ¨æˆ–æ— æƒé™: {material_id}", "ERROR")
            return jsonify({'success': False, 'error': 'ææ–™ä¸å­˜åœ¨'}), 404

        if material.type not in ['image', 'pdf']:
            return jsonify({'success': False, 'error': 'åªæ”¯æŒå›¾ç‰‡å’ŒPDFææ–™'}), 400

        log_message(f"ææ–™åç§°: {material.name}, ç±»å‹: {material.type}", "INFO")

        # è¯»å–åŸå§‹å›¾ç‰‡
        from PIL import Image
        import os

        # material.file_path å·²ç»åŒ…å«äº† 'uploads/' å‰ç¼€ï¼Œä¸éœ€è¦å†åŠ 
        original_path = material.file_path
        if not os.path.exists(original_path):
            log_message(f"æ–‡ä»¶ä¸å­˜åœ¨: {original_path}", "ERROR")
            return jsonify({'success': False, 'error': 'åŸå§‹å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨'}), 404

        # æ—‹è½¬å›¾ç‰‡90åº¦ï¼ˆé¡ºæ—¶é’ˆï¼‰
        img = Image.open(original_path)
        rotated_img = img.rotate(-90, expand=True)  # -90è¡¨ç¤ºé¡ºæ—¶é’ˆæ—‹è½¬90åº¦

        # ä¿å­˜æ—‹è½¬åçš„å›¾ç‰‡ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        rotated_img.save(original_path)
        log_message(f"å›¾ç‰‡å·²æ—‹è½¬90åº¦: {original_path}", "SUCCESS")

        # æ¸…é™¤æ—§çš„ç¿»è¯‘ç»“æœå’Œç¼–è¾‘å›¾ç‰‡ï¼Œè®©ç”¨æˆ·é‡æ–°ç‚¹å‡»ç¿»è¯‘æŒ‰é’®
        material.translation_text_info = None
        material.llm_translation_result = None
        material.edited_image_path = None
        material.final_image_path = None
        material.has_edited_version = False
        material.edited_regions = None
        material.status = get_legacy_status(ProcessingStep.UPLOADED.value)
        material.processing_step = ProcessingStep.UPLOADED.value
        material.processing_progress = 0
        material.updated_at = datetime.utcnow()

        db.session.commit()

        return jsonify({
            'success': True,
            'material': {
                'id': material.id,
                'name': material.name,
                'status': material.status,
                'filePath': material.file_path,
                'processingProgress': 0,
                'processingStep': None,
                # ä¿ç•™PDFç›¸å…³å­—æ®µï¼Œé¿å…å‰ç«¯æ›´æ–°æ—¶ä¸¢å¤±
                'pdfSessionId': material.pdf_session_id,
                'pdfPageNumber': material.pdf_page_number,
                'pdfTotalPages': material.pdf_total_pages
            },
            'message': 'å›¾ç‰‡å·²æ—‹è½¬90åº¦ï¼Œè¯·ç‚¹å‡»é‡æ–°ç¿»è¯‘æŒ‰é’®'
        })

    except Exception as e:
        db.session.rollback()
        import traceback
        error_traceback = traceback.format_exc()
        log_message(f"æ—‹è½¬å›¾ç‰‡å¤±è´¥: {str(e)}", "ERROR")
        log_message(f"é”™è¯¯å †æ ˆ:\n{error_traceback}", "ERROR")

        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500


@jwt_required()
def export_client_materials(client_id):
    """å¯¼å‡ºå®¢æˆ·çš„æ‰€æœ‰å·²ç¡®è®¤ææ–™"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥æ‰¾å®¢æˆ·å¹¶éªŒè¯æƒé™
        client = Client.query.filter_by(id=client_id, user_id=current_user_id).first()
        if not client:
            return jsonify({
                'success': False,
                'error': 'å®¢æˆ·ä¸å­˜åœ¨'
            }), 404
        
        # æŸ¥æ‰¾æ‰€æœ‰å·²ç¡®è®¤çš„ææ–™
        confirmed_materials = Material.query.filter_by(
            client_id=client_id,
            confirmed=True
        ).all()
        
        if not confirmed_materials:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰å·²ç¡®è®¤çš„ç¿»è¯‘ææ–™'
            }), 404
        
        # åˆ›å»ºå¯¼å‡ºæ–‡ä»¶åˆ—è¡¨
        export_data = []
        for material in confirmed_materials:
            material_data = {
                'id': material.id,
                'name': material.name,
                'type': material.type,
                'selected_type': material.selected_result,
                'confirmed_at': material.updated_at.isoformat() if material.updated_at else None
            }
            
            # æ ¹æ®é€‰æ‹©çš„ç¿»è¯‘ç±»å‹æä¾›æ–‡ä»¶è·¯å¾„
            if material.selected_result == 'api' and material.translated_image_path:
                material_data['file_path'] = material.translated_image_path
            elif material.selected_result == 'latex' and material.latex_translation_result:
                material_data['latex_content'] = material.latex_translation_result
            
            export_data.append(material_data)
        
        # åˆ›å»ºZIPæ–‡ä»¶
        zip_buffer = io.BytesIO()
        client_name = client.name.replace(' ', '_').replace('/', '_')
        # ä¿®æ”¹æ—¥æœŸæ ¼å¼ï¼šå¹´æœˆæ—¥å°æ—¶åˆ†é’Ÿ
        date_str = datetime.now().strftime('%Y%m%d_%H%M')
        
        # è·å–ä¸€æ¬¡ç™¾åº¦ç¿»è¯‘çš„access_tokenä¾›æœ¬æ¬¡å¯¼å‡ºä½¿ç”¨
        access_token = None
        api_keys = load_api_keys()
        baidu_api_key = api_keys.get('BAIDU_API_KEY')
        baidu_secret_key = api_keys.get('BAIDU_SECRET_KEY')
        
        if baidu_api_key and baidu_secret_key:
            access_token = get_baidu_access_token(baidu_api_key, baidu_secret_key)
            if access_token:
                log_message("è·å–ç™¾åº¦ç¿»è¯‘access_tokenæˆåŠŸï¼Œå°†ç”¨äºæœ¬æ¬¡å¯¼å‡ºçš„æ–‡ä»¶åç¿»è¯‘")
            else:
                log_message("è·å–ç™¾åº¦ç¿»è¯‘access_tokenå¤±è´¥ï¼Œæ–‡ä»¶åå°†ä¿æŒåŸæ–‡", "WARN")
        else:
            log_message("ç™¾åº¦ç¿»è¯‘APIæœªé…ç½®ï¼Œæ–‡ä»¶åå°†ä¿æŒåŸæ–‡", "WARN")
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # æ”¶é›†æ–‡ä»¶åå¯¹åº”å…³ç³»
            file_pairs = []

            # è¿½è¸ªå·²å¤„ç†çš„PDFä¼šè¯,é¿å…é‡å¤å¤„ç†
            processed_pdf_sessions = set()

            # æ·»åŠ å®é™…æ–‡ä»¶åˆ°materialsæ–‡ä»¶å¤¹
            for material in confirmed_materials:
                # å¦‚æœæ˜¯PDFå¤šé¡µçš„ä¸€éƒ¨åˆ†,ä¸”è¿˜æœªå¤„ç†è¿‡è¯¥ä¼šè¯
                if material.pdf_session_id and material.pdf_session_id not in processed_pdf_sessions:
                    # æ ‡è®°ä¸ºå·²å¤„ç†
                    processed_pdf_sessions.add(material.pdf_session_id)

                    # è·å–è¯¥PDFä¼šè¯çš„æ‰€æœ‰é¡µé¢
                    pdf_pages = Material.query.filter_by(
                        pdf_session_id=material.pdf_session_id,
                        client_id=client_id,
                        confirmed=True
                    ).order_by(Material.pdf_page_number).all()

                    if not pdf_pages:
                        continue

                    # è·å–åŸå§‹PDFåç§°(å»æ‰é¡µç )
                    pdf_base_name = material.name.rsplit(' - ', 1)[0] if ' - ç¬¬' in material.name else material.name

                    # ç¿»è¯‘PDFåç§°
                    if access_token:
                        pdf_name_en = translate_filename_with_token(pdf_base_name, access_token, 'en')
                    else:
                        pdf_name_en = pdf_base_name

                    # æ·»åŠ åŸå§‹PDFæ–‡ä»¶
                    if material.pdf_original_file and os.path.exists(material.pdf_original_file):
                        original_filename = f"{pdf_base_name}_åŸæ–‡.pdf"
                        zip_file.write(material.pdf_original_file, f"materials/{original_filename}")
                        log_message(f"æ·»åŠ åŸå§‹PDF: {original_filename}")

                    # åˆå¹¶æ‰€æœ‰é¡µé¢çš„ç¿»è¯‘å›¾ç‰‡ä¸ºPDF
                    try:
                        from PIL import Image
                        images = []

                        for page in pdf_pages:
                            log_message(f"å¤„ç†ç¬¬ {page.pdf_page_number} é¡µ", "DEBUG")

                            # âœ… ä¼˜å…ˆä½¿ç”¨å‰ç«¯ç”Ÿæˆçš„ final_image_pathï¼ˆ100%ä¸€è‡´ï¼‰
                            if page.final_image_path:
                                image_path = page.final_image_path
                                log_message(f"âœ“ ä½¿ç”¨å‰ç«¯ç”Ÿæˆçš„ final_image_path: {image_path}", "SUCCESS")

                                # å¤„ç†è·¯å¾„
                                if not os.path.isabs(image_path):
                                    image_path = os.path.join(app.root_path, image_path)

                                if not os.path.exists(image_path):
                                    log_message(f"final_image_path æ–‡ä»¶ä¸å­˜åœ¨: {image_path}", "ERROR")
                                    continue

                                try:
                                    img = Image.open(image_path)
                                    if img.mode == 'RGBA':
                                        img = img.convert('RGB')
                                    images.append(img)
                                    log_message(f"âœ“ ç¬¬ {page.pdf_page_number} é¡µä½¿ç”¨å‰ç«¯ç”Ÿæˆçš„å›¾ç‰‡", "SUCCESS")
                                    continue
                                except Exception as e:
                                    log_message(f"æ‰“å¼€ final_image å¤±è´¥: {e}", "ERROR")

                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» regions + åŸå›¾åŠ¨æ€ç”Ÿæˆ
                            if page.edited_regions and page.file_path:
                                try:
                                    log_message(f"ä» regions + åŸå›¾åŠ¨æ€ç”Ÿæˆ", "INFO")

                                    # è·å–åŸå›¾è·¯å¾„
                                    original_path = page.file_path
                                    if not os.path.isabs(original_path):
                                        original_path = os.path.join(app.root_path, original_path)

                                    if not os.path.exists(original_path):
                                        log_message(f"åŸå›¾ä¸å­˜åœ¨: {original_path}", "ERROR")
                                        continue

                                    # ä» regions ç”Ÿæˆå›¾ç‰‡
                                    generated_img = generate_image_from_regions(original_path, page.edited_regions)
                                    images.append(generated_img)
                                    log_message(f"âœ“ ç¬¬ {page.pdf_page_number} é¡µåŠ¨æ€ç”ŸæˆæˆåŠŸ", "SUCCESS")

                                except Exception as gen_error:
                                    log_message(f"ç¬¬ {page.pdf_page_number} é¡µç”Ÿæˆå¤±è´¥: {gen_error}", "ERROR")
                                    continue
                            else:
                                log_message(f"ç¬¬ {page.pdf_page_number} é¡µæ²¡æœ‰å¯ç”¨æ•°æ®ï¼Œè·³è¿‡", "WARN")
                                continue

                        # ä¸‹é¢ç»§ç»­å¤„ç†å›¾ç‰‡è·¯å¾„ï¼ˆè¿™æ®µä»£ç å·²ç»ä¸ä¼šè¢«æ‰§è¡Œï¼Œå› ä¸ºä¸Šé¢éƒ½æ˜¯continueï¼‰
                        # ä¿ç•™ä»£ç ç»“æ„é¿å…è¯­æ³•é”™è¯¯
                        if False:  # æ°¸è¿œä¸æ‰§è¡Œ
                            image_path = None
                            # å¤„ç†è·¯å¾„
                            if not os.path.isabs(image_path):
                                log_message(f"è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œå°è¯•æŸ¥æ‰¾: {image_path}", "DEBUG")
                                possible_paths = [
                                    image_path,
                                    os.path.join('uploads', image_path),
                                    os.path.join(app.root_path, 'uploads', image_path),
                                    os.path.join('image_translation_output', image_path)
                                ]
                                found = False
                                for possible_path in possible_paths:
                                    log_message(f"  å°è¯•è·¯å¾„: {possible_path}, å­˜åœ¨={os.path.exists(possible_path)}", "DEBUG")
                                    if os.path.exists(possible_path):
                                        image_path = possible_path
                                        found = True
                                        log_message(f"  âœ“ æ‰¾åˆ°æ–‡ä»¶: {image_path}", "DEBUG")
                                        break
                                if not found:
                                    log_message(f"  âœ— æ‰€æœ‰å¯èƒ½è·¯å¾„éƒ½ä¸å­˜åœ¨", "ERROR")

                            if os.path.exists(image_path):
                                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œè·³è¿‡ç©ºæ–‡ä»¶
                                file_size = os.path.getsize(image_path)
                                if file_size == 0:
                                    log_message(f"âœ— æ–‡ä»¶æ˜¯ç©ºçš„(0å­—èŠ‚): {image_path}", "ERROR")
                                    log_message(f"è·³è¿‡ç¬¬ {page.pdf_page_number} é¡µ", "WARN")
                                    continue

                                try:
                                    img = Image.open(image_path)
                                    if img.mode == 'RGBA':
                                        img = img.convert('RGB')
                                    images.append(img)
                                    log_message(f"âœ“ æ·»åŠ PDFé¡µé¢ {page.pdf_page_number}: {image_path} ({file_size/1024:.1f}KB)", "SUCCESS")
                                except Exception as img_error:
                                    log_message(f"âœ— æ— æ³•æ‰“å¼€å›¾ç‰‡: {image_path}, é”™è¯¯: {str(img_error)}", "ERROR")
                                    continue
                            else:
                                log_message(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {image_path}", "ERROR")

                        if images:
                            # ç”Ÿæˆåˆå¹¶åçš„PDF
                            merged_pdf_path = os.path.join(app.root_path, 'uploads', f"merged_{pdf_name_en}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pdf")
                            images[0].save(merged_pdf_path, save_all=True, append_images=images[1:] if len(images) > 1 else [], resolution=100.0, quality=95)

                            translated_filename = f"{pdf_name_en}_translated.pdf"
                            zip_file.write(merged_pdf_path, f"materials/{translated_filename}")
                            log_message(f"âœ“ åˆå¹¶PDFå®Œæˆ: {len(images)} é¡µ -> {translated_filename}")

                            # åˆ é™¤ä¸´æ—¶åˆå¹¶æ–‡ä»¶
                            try:
                                os.remove(merged_pdf_path)
                            except:
                                pass

                            # æ·»åŠ åˆ°æ–‡ä»¶å¯¹åº”å…³ç³»
                            if original_filename and translated_filename:
                                original_name = os.path.splitext(original_filename)[0]
                                translated_name = os.path.splitext(translated_filename)[0]
                                file_pairs.append(f"{original_name}\n{translated_name}")

                    except Exception as e:
                        log_message(f"PDFåˆå¹¶å¤±è´¥: {str(e)}", "ERROR")

                    # è·³è¿‡åç»­çš„å•é¡µå¤„ç†
                    continue

                # å¦‚æœæ˜¯PDFçš„å•ä¸ªé¡µé¢ä½†å·²ç»å¤„ç†è¿‡ä¼šè¯,è·³è¿‡
                if material.pdf_session_id:
                    continue

                original_filename = None
                translated_filename = None

                # ç¿»è¯‘ææ–™ååˆ°è‹±æ–‡ï¼ˆä»…ç”¨äºç¿»è¯‘æ–‡ä»¶ï¼‰ï¼Œå¤ç”¨access_token
                if access_token:
                    material_name_en = translate_filename_with_token(material.name, access_token, 'en')
                else:
                    material_name_en = material.name  # ç¿»è¯‘å¤±è´¥åˆ™ä½¿ç”¨åŸå
                
                # æ·»åŠ åŸå§‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- ä¿æŒä¸­æ–‡å
                if material.file_path and os.path.exists(material.file_path):
                    original_ext = os.path.splitext(material.original_filename)[1] if material.original_filename else os.path.splitext(material.file_path)[1]
                    original_filename = f"{material.name}_åŸæ–‡{original_ext}"
                    zip_file.write(material.file_path, f"materials/{original_filename}")
                
                # ç½‘é¡µææ–™ä½¿ç”¨åŸå§‹PDFä½œä¸º"åŸæ–‡"
                elif material.type == 'webpage' and material.original_pdf_path:
                    # åŸå§‹PDFæ–‡ä»¶è·¯å¾„
                    original_pdf_path = os.path.join('original_snapshot', material.original_pdf_path)
                    if os.path.exists(original_pdf_path):
                        original_filename = f"{material.name}_åŸæ–‡.pdf"
                        zip_file.write(original_pdf_path, f"materials/{original_filename}")
                        log_message(f"æ·»åŠ åŸå§‹ç½‘é¡µPDF: {original_pdf_path} -> {original_filename}")
                    else:
                        log_message(f"åŸå§‹ç½‘é¡µPDFä¸å­˜åœ¨: {original_pdf_path}", "WARN")
                        # å¦‚æœPDFä¸å­˜åœ¨ï¼Œåˆ›å»ºå¤‡ç”¨çš„URLæ–‡æœ¬æ–‡ä»¶
                        original_filename = f"{material.name}_ç½‘å€.txt"
                        url_content = f"ç½‘é¡µæ ‡é¢˜: {material.name}\nç½‘é¡µåœ°å€: {material.url}\n"
                        zip_file.writestr(f"materials/{original_filename}", url_content)
                
                # æ·»åŠ ç¿»è¯‘æ–‡ä»¶ - ä½¿ç”¨è‹±æ–‡å
                # å¤„ç†ç½‘é¡µç±»å‹ææ–™
                if material.type == 'webpage' and material.translated_image_path:
                    # ç½‘é¡µç¿»è¯‘çš„PDFæ–‡ä»¶
                    pdf_path = os.path.join('translated_snapshot', material.translated_image_path)
                    if os.path.exists(pdf_path):
                        translated_filename = f"{material_name_en}_translated.pdf"
                        zip_file.write(pdf_path, f"materials/{translated_filename}")
                        log_message(f"æ·»åŠ ç½‘é¡µç¿»è¯‘æ–‡ä»¶: {pdf_path} -> {translated_filename}")
                    else:
                        log_message(f"ç½‘é¡µç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}", "WARN")
                
                elif (material.selected_result == 'api' and
                    (material.final_image_path or material.edited_image_path or material.translated_image_path)):

                    # ä¼˜å…ˆçº§ï¼šfinal_image_pathï¼ˆå¸¦æ–‡å­—å®Œæ•´ç‰ˆï¼‰ > edited_image_pathï¼ˆä¸å¸¦æ–‡å­—ï¼‰ > translated_image_pathï¼ˆAPIåŸå§‹ç¿»è¯‘ï¼‰
                    if material.has_edited_version and material.final_image_path:
                        # æœ€ä¼˜å…ˆï¼šä½¿ç”¨å¸¦æ–‡å­—çš„å®Œæ•´ç‰ˆæœ¬ï¼ˆç”¨äºå¯¼å‡ºï¼‰
                        image_path = material.final_image_path
                        log_message(f"âœ… ä½¿ç”¨æœ€ç»ˆå›¾ç‰‡ï¼ˆå¸¦æ–‡å­—å®Œæ•´ç‰ˆï¼‰: {image_path}", "SUCCESS")

                        # å¦‚æœè·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œå°è¯•å‡ ä¸ªå¯èƒ½çš„ç›®å½•
                        if not os.path.isabs(image_path):
                            possible_paths = [
                                os.path.join('uploads', image_path),
                                os.path.join(app.root_path, 'uploads', image_path),
                                image_path
                            ]

                            found_path = None
                            for possible_path in possible_paths:
                                if os.path.exists(possible_path):
                                    found_path = possible_path
                                    log_message(f"æ‰¾åˆ°æœ€ç»ˆå›¾ç‰‡æ–‡ä»¶: {found_path}", "INFO")
                                    break

                            if not found_path:
                                log_message(f"âŒ æœ€ç»ˆå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾è·¯å¾„: {possible_paths}", "ERROR")
                            image_path = found_path

                    elif material.has_edited_version and material.edited_image_path:
                        # å¤‡é€‰ï¼šä½¿ç”¨ç¼–è¾‘åçš„å›¾ç‰‡ï¼ˆä¸å¸¦æ–‡å­—ç‰ˆæœ¬ï¼‰
                        image_path = material.edited_image_path
                        log_message(f"âš ï¸ ä½¿ç”¨ç¼–è¾‘åçš„å›¾ç‰‡ï¼ˆä¸å¸¦æ–‡å­—ç‰ˆï¼‰: {image_path}", "WARN")

                        # å¦‚æœè·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œå°è¯•å‡ ä¸ªå¯èƒ½çš„ç›®å½•
                        if not os.path.isabs(image_path):
                            possible_paths = [
                                os.path.join('uploads', image_path),
                                os.path.join(app.root_path, 'uploads', image_path),
                                image_path
                            ]

                            found_path = None
                            for possible_path in possible_paths:
                                if os.path.exists(possible_path):
                                    found_path = possible_path
                                    break
                            image_path = found_path
                    else:
                        # å…œåº•ï¼šä½¿ç”¨APIç¿»è¯‘çš„å›¾ç‰‡
                        image_path = material.translated_image_path
                        log_message(f"ä½¿ç”¨APIç¿»è¯‘å›¾ç‰‡: {image_path}", "INFO")

                        # å¦‚æœè·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œå°è¯•å‡ ä¸ªå¯èƒ½çš„ç›®å½•
                        if not os.path.isabs(image_path):
                            possible_paths = [
                                image_path,  # ç›´æ¥ä½¿ç”¨å­˜å‚¨çš„è·¯å¾„
                                os.path.join('image_translation_output', image_path),
                                os.path.join('translated_images', image_path),
                                os.path.join('web_translation_output', image_path)
                            ]

                            found_path = None
                            for possible_path in possible_paths:
                                if os.path.exists(possible_path):
                                    found_path = possible_path
                                    break
                            image_path = found_path

                    if image_path and os.path.exists(image_path):
                        # è·å–åŸå§‹æ–‡ä»¶æ‰©å±•åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨.jpg
                        original_ext = os.path.splitext(material.original_filename)[1] if material.original_filename else '.jpg'
                        translated_filename = f"{material_name_en}_translated{original_ext}"
                        zip_file.write(image_path, f"materials/{translated_filename}")
                        log_message(f"æ·»åŠ ç¿»è¯‘æ–‡ä»¶: {image_path} -> {translated_filename}")
                    else:
                        log_message(f"ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {image_path}", "WARN")
                    
                elif (material.selected_result == 'latex' and 
                      material.latex_translation_result):
                    
                    try:
                        latex_data = json.loads(material.latex_translation_result)
                        
                        # åªæ·»åŠ PDFæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if 'pdf_file' in latex_data:
                            pdf_path = latex_data['pdf_file']
                            if os.path.exists(pdf_path):
                                translated_filename = f"{material_name_en}_translated.pdf"
                                zip_file.write(pdf_path, f"materials/{translated_filename}")
                            
                    except json.JSONDecodeError:
                        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè·³è¿‡LaTeXç¿»è¯‘
                        pass
                
                # å¦‚æœæœ‰åŸæ–‡ä»¶å’Œç¿»è¯‘æ–‡ä»¶ï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                if original_filename and translated_filename:
                    # å»æ‰æ‰©å±•å
                    original_name = os.path.splitext(original_filename)[0]
                    translated_name = os.path.splitext(translated_filename)[0]
                    file_pairs.append(f"{original_name}\n{translated_name}")
            
            # åˆ›å»ºlist.txtæ–‡ä»¶
            list_content = '\n'.join(file_pairs)
            zip_file.writestr('list.txt', list_content)
        
        zip_buffer.seek(0)
        
        # è¿”å›ZIPæ–‡ä»¶ï¼Œä½¿ç”¨æ–°çš„æ–‡ä»¶åæ ¼å¼ï¼šå®¢æˆ·å_å¹´æœˆæ—¥å°æ—¶åˆ†é’Ÿ.zip
        filename = f"{client_name}_{date_str}.zip"
        
        # å°è¯•ä½¿ç”¨download_nameï¼ˆFlask 2.2+ï¼‰æˆ– attachment_filenameï¼ˆæ—§ç‰ˆæœ¬ï¼‰
        try:
            return send_file(
                zip_buffer,
                as_attachment=True,
                download_name=filename,
                mimetype='application/zip'
            )
        except TypeError:
            # å¦‚æœdownload_nameä¸è¢«æ”¯æŒï¼Œä½¿ç”¨attachment_filename
            zip_buffer.seek(0)
            return send_file(
                zip_buffer,
                as_attachment=True,
                attachment_filename=filename,
                mimetype='application/zip'
            )
        
    except Exception as e:
        log_message(f"å¯¼å‡ºå®¢æˆ·ææ–™å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({
            'success': False,
            'error': 'å¯¼å‡ºå¤±è´¥',
            'message': str(e)
        }), 500

# ========== ç”¨æˆ·è®¾ç½®ç›¸å…³API ==========

@app.route('/api/user/settings', methods=['GET'])
@jwt_required()
def get_user_settings():
    """è·å–ç”¨æˆ·è®¾ç½®"""
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        
        if not user:
            return jsonify({
                'success': False,
                'error': 'ç”¨æˆ·ä¸å­˜åœ¨'
            }), 404
        
        # è¿”å›ç”¨æˆ·è®¾ç½®
        settings = {
            'basicInfo': {
                'name': user.name,
                'email': user.email,
                'phone': user.phone,
                'lawFirm': user.law_firm
            },
            'notificationSettings': {
                'translationComplete': getattr(user, 'notification_translation_complete', True),
                'translationFailed': getattr(user, 'notification_translation_failed', False),
                'dailySummary': getattr(user, 'notification_daily_summary', False),
                'emailEnabled': user.email_notification if hasattr(user, 'email_notification') else True,
                'browserPushEnabled': getattr(user, 'browser_push_enabled', True)
            },
            'translationPreferences': {
                'retryCount': user.auto_retry_count if hasattr(user, 'auto_retry_count') else 3,
                'enginePriority': getattr(user, 'engine_priority', 'latex')
            }
        }
        
        return jsonify({
            'success': True,
            'settings': settings
        })
        
    except Exception as e:
        log_message(f"è·å–ç”¨æˆ·è®¾ç½®å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({
            'success': False,
            'error': 'è·å–è®¾ç½®å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/user/basic-info', methods=['PUT'])
@jwt_required()
def update_basic_info():
    """æ›´æ–°ç”¨æˆ·åŸºæœ¬ä¿¡æ¯"""
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        
        if not user:
            return jsonify({
                'success': False,
                'error': 'ç”¨æˆ·ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        
        # æ›´æ–°åŸºæœ¬ä¿¡æ¯
        if 'name' in data:
            user.name = data['name']
        if 'email' in data:
            user.email = data['email']
        if 'phone' in data:
            user.phone = data['phone']
        if 'lawFirm' in data:
            user.law_firm = data['lawFirm']
        
        user.updated_at = datetime.utcnow()
        db.session.commit()
        
        log_message(f"ç”¨æˆ·åŸºæœ¬ä¿¡æ¯æ›´æ–°æˆåŠŸ: {current_user_id}")
        
        return jsonify({
            'success': True,
            'message': 'åŸºæœ¬ä¿¡æ¯æ›´æ–°æˆåŠŸ',
            'user': user.to_dict()
        })
        
    except Exception as e:
        log_message(f"æ›´æ–°ç”¨æˆ·åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'æ›´æ–°å¤±è´¥',
            'message': str(e)
        }), 500

@app.route('/api/user/change-password', methods=['PUT'])
@jwt_required()
def change_password():
    """ä¿®æ”¹ç”¨æˆ·å¯†ç """
    try:
        current_user_id = get_jwt_identity()
        user = User.query.get(current_user_id)
        
        if not user:
            return jsonify({
                'success': False,
                'error': 'ç”¨æˆ·ä¸å­˜åœ¨'
            }), 404
        
        data = request.get_json()
        current_password = data.get('currentPassword')
        new_password = data.get('newPassword')
        
        if not current_password or not new_password:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›å½“å‰å¯†ç å’Œæ–°å¯†ç '
            }), 400
        
        # éªŒè¯å½“å‰å¯†ç 
        if not check_password_hash(user.password, current_password):
            return jsonify({
                'success': False,
                'error': 'å½“å‰å¯†ç ä¸æ­£ç¡®'
            }), 400
        
        # éªŒè¯æ–°å¯†ç é•¿åº¦
        if len(new_password) < 6:
            return jsonify({
                'success': False,
                'error': 'æ–°å¯†ç é•¿åº¦è‡³å°‘ä¸º6ä½'
            }), 400
        
        # æ›´æ–°å¯†ç 
        user.password = generate_password_hash(new_password)
        user.updated_at = datetime.utcnow()
        db.session.commit()
        
        log_message(f"ç”¨æˆ·å¯†ç ä¿®æ”¹æˆåŠŸ: {current_user_id}")
        
        return jsonify({
            'success': True,
            'message': 'å¯†ç ä¿®æ”¹æˆåŠŸ'
        })
        
    except Exception as e:
        log_message(f"ä¿®æ”¹å¯†ç å¤±è´¥: {str(e)}", "ERROR")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'å¯†ç ä¿®æ”¹å¤±è´¥',
            'message': str(e)
        }), 500

# ========== é”™è¯¯å¤„ç† ========== 

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'æ¥å£ä¸å­˜åœ¨'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    db.session.rollback()
    return jsonify({
        'success': False,
        'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
    }), 500

@app.errorhandler(Exception)
def handle_exception(e):
    log_message(f"æœªå¤„ç†çš„å¼‚å¸¸: {str(e)}", "ERROR")
    db.session.rollback()
    return jsonify({
        'success': False,
        'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯',
        'message': str(e)
    }), 500

# ========== è·¯ç”±æ˜ å°„ ==========
# æ·»åŠ æ‰€æœ‰è·¯ç”±æ˜ å°„
app.add_url_rule('/api/clients/<client_id>/export', 'export_client_materials',
                export_client_materials, methods=['GET'])

# ========== æ³¨å†Œè“å›¾ ==========
# å›¾ç‰‡èƒŒæ™¯æ–‡å­—åˆ†ç¦»åŠŸèƒ½
from routes.image_separation import image_separation_bp
app.register_blueprint(image_separation_bp)

if __name__ == '__main__':
    # ç¡®ä¿å·¥ä½œç›®å½•åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    
    print("å¯åŠ¨æ™ºèƒ½æ–‡ä¹¦ç¿»è¯‘å¹³å° - å®Œæ•´ç‰ˆåç«¯æœåŠ¡ v4.0...")
    print("åŠŸèƒ½: ç”¨æˆ·è®¤è¯ã€å®¢æˆ·ç®¡ç†ã€ææ–™ç®¡ç†ã€å®Œæ•´ç¿»è¯‘æœåŠ¡")
    print("è®¤è¯æ–¹å¼: JWT Bearer Token")
    print("æ•°æ®åº“: SQLite (translation_platform.db)")
    print("æµ‹è¯•ç”¨æˆ·: test@example.com / password123")
    print(f"OpenAIå¯ç”¨: {OPENAI_AVAILABLE}")
    print(f"Seleniumå¯ç”¨: {SELENIUM_AVAILABLE}")
    print()
    
    # åˆå§‹åŒ–æ•°æ®åº“å¹¶æ·»åŠ æ–°åˆ—
    with app.app_context():
        # å¼ºåˆ¶åˆ·æ–°å…ƒæ•°æ®è§£å†³ç¼“å­˜é—®é¢˜
        try:
            # 1. é‡Šæ”¾æ‰€æœ‰æ•°æ®åº“è¿æ¥
            db.engine.dispose()
            
            # 2. ä¸è¦æ¸…é™¤å…ƒæ•°æ®ï¼è¿™ä¼šç§»é™¤æ‰€æœ‰æ¨¡å‹å®šä¹‰
            # db.metadata.clear()  # è¿™æ˜¯é—®é¢˜æ‰€åœ¨ï¼
            
            # 3. é‡æ–°åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆåŸºäºæ¨¡å‹å®šä¹‰ï¼‰
            db.create_all()
            
            # 3.5 æ‰‹åŠ¨ç¡®ä¿Clientè¡¨æœ‰æ‰€æœ‰å¿…è¦çš„åˆ—
            # è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œç”¨äºè§£å†³SQLAlchemyå¯èƒ½çš„bug
            try:
                from sqlalchemy import text as sql_text
                with db.engine.begin() as conn:
                    # æ·»åŠ ç¼ºå¤±çš„åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    missing_columns = [
                        ("ALTER TABLE clients ADD COLUMN phone VARCHAR(50)", "phone"),
                        ("ALTER TABLE clients ADD COLUMN email VARCHAR(100)", "email"),
                        ("ALTER TABLE clients ADD COLUMN address TEXT", "address"),
                        ("ALTER TABLE clients ADD COLUMN notes TEXT", "notes"),
                        ("ALTER TABLE clients ADD COLUMN is_archived BOOLEAN DEFAULT 0", "is_archived"),
                        ("ALTER TABLE clients ADD COLUMN archived_at DATETIME", "archived_at"),
                        ("ALTER TABLE clients ADD COLUMN archived_reason VARCHAR(500)", "archived_reason"),
                        ("ALTER TABLE users ADD COLUMN phone VARCHAR(50)", "users.phone"),
                        ("ALTER TABLE users ADD COLUMN law_firm_id VARCHAR(36)", "users.law_firm_id"),
                        ("ALTER TABLE materials ADD COLUMN processing_step VARCHAR(50) DEFAULT 'uploaded'", "processing_step"),
                        ("ALTER TABLE materials ADD COLUMN processing_progress INTEGER DEFAULT 0", "processing_progress")
                    ]
                    
                    for sql, col_name in missing_columns:
                        try:
                            conn.execute(sql_text(sql))
                            log_message(f"æ·»åŠ åˆ—: {col_name}", "INFO")
                        except Exception as e:
                            if "duplicate column name" in str(e):
                                pass  # åˆ—å·²å­˜åœ¨ï¼Œå¿½ç•¥
                            else:
                                log_message(f"æ·»åŠ åˆ— {col_name} å¤±è´¥: {e}", "WARNING")
            except Exception as e:
                log_message(f"æ‰‹åŠ¨æ·»åŠ åˆ—æ—¶å‡ºé”™: {e}", "WARNING")
            
            # 4. å¼ºåˆ¶é‡æ–°åŠ è½½å…ƒæ•°æ®
            db.metadata.reflect(bind=db.engine)
            
            log_message("æ•°æ®åº“å…ƒæ•°æ®å·²å®Œå…¨é‡ç½®å¹¶åˆå§‹åŒ–æˆåŠŸ", "SUCCESS")
            
            # 5. éªŒè¯è¡¨ç»“æ„
            inspector = db.inspect(db.engine)
            tables = inspector.get_table_names()
            log_message(f"æ•°æ®åº“è¡¨: {tables}", "INFO")
            
            if 'clients' in tables:
                columns = [col['name'] for col in inspector.get_columns('clients')]
                log_message(f"clientsè¡¨åˆ—: {columns}", "INFO")
                
        except Exception as e:
            log_message(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}", "ERROR")
            import traceback
            traceback.print_exc()
        
        # æ·»åŠ æ–°åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN translated_image_path VARCHAR(500)"))
            log_message("æ·»åŠ translated_image_pathåˆ—", "SUCCESS")
        except Exception:
            pass  # åˆ—å·²å­˜åœ¨
        
        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN translation_text_info TEXT"))
            log_message("æ·»åŠ translation_text_infoåˆ—", "SUCCESS")
        except Exception:
            pass  # åˆ—å·²å­˜åœ¨
            
        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN translation_error TEXT"))
            log_message("æ·»åŠ translation_erroråˆ—", "SUCCESS")
        except Exception:
            pass  # åˆ—å·²å­˜åœ¨
            
        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN latex_translation_result TEXT"))
            log_message("æ·»åŠ latex_translation_resultåˆ—", "SUCCESS")
        except Exception:
            pass  # åˆ—å·²å­˜åœ¨
            
        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN latex_translation_error TEXT"))
            log_message("æ·»åŠ latex_translation_erroråˆ—", "SUCCESS")
        except Exception:
            pass  # åˆ—å·²å­˜åœ¨

        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN llm_translation_result TEXT"))
            log_message("æ·»åŠ llm_translation_resultåˆ—", "SUCCESS")
        except Exception:
            pass  # åˆ—å·²å­˜åœ¨

        # æ·»åŠ PDFå¤šé¡µç›¸å…³å­—æ®µ
        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN pdf_session_id VARCHAR(100)"))
            log_message("æ·»åŠ pdf_session_idåˆ—", "SUCCESS")
        except Exception:
            pass

        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN pdf_page_number INTEGER"))
            log_message("æ·»åŠ pdf_page_numberåˆ—", "SUCCESS")
        except Exception:
            pass

        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN pdf_total_pages INTEGER"))
            log_message("æ·»åŠ pdf_total_pagesåˆ—", "SUCCESS")
        except Exception:
            pass

        try:
            db.engine.execute(text("ALTER TABLE materials ADD COLUMN pdf_original_file VARCHAR(500)"))
            log_message("æ·»åŠ pdf_original_fileåˆ—", "SUCCESS")
        except Exception:
            pass


    # âœ… ä½¿ç”¨ SocketIO è¿è¡Œï¼ˆæ”¯æŒ WebSocketï¼‰
    if WEBSOCKET_ENABLED:
        print('[WebSocket] ä½¿ç”¨ SocketIO è¿è¡ŒæœåŠ¡å™¨')
        socketio.run(app, host='0.0.0.0', port=5010, debug=True)
    else:
        print('[WebSocket] WebSocket æœªå¯ç”¨ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼è¿è¡Œ')
        app.run(debug=True, host='0.0.0.0', port=5010)

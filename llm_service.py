"""LLMç¿»è¯‘ä¼˜åŒ–æœåŠ¡æ¨¡å— - ä¸Referenceé¡¹ç›®ä¿æŒä¸€è‡´"""
from openai import OpenAI
import os
import re
import json
import datetime

class LLMTranslationService:
    def __init__(self, api_key=None, output_folder='outputs'):
        self.api_key = api_key or self._load_api_key()
        self.client = OpenAI(api_key=self.api_key) if self.api_key else None
        self.output_folder = output_folder
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(os.path.join(output_folder, 'logs'), exist_ok=True)

    def _load_api_key(self):
        """åŠ è½½OpenAI APIå¯†é’¥"""
        key_path = 'config/openai_api_key.txt'
        if os.path.exists(key_path):
            with open(key_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return None

    def optimize_translations(self, regions, batch_size=30, entity_guidance=None):
        """
        ä¼˜åŒ–ç¿»è¯‘ç»“æœï¼ˆæ”¯æŒæ‰¹å¤„ç†ï¼Œé¿å…è¶…æ—¶ï¼‰
        Args:
            regions: ç™¾åº¦ç¿»è¯‘è¿”å›çš„åŒºåŸŸåˆ—è¡¨
                [
                    {
                        'id': 0,
                        'src': 'åŸæ–‡',
                        'dst': 'ç™¾åº¦ç¿»è¯‘',
                        'points': [{'x': x1, 'y': y1}, {'x': x2, 'y': y2}, ...],
                        ...
                    },
                    ...
                ]
            batch_size: æ¯æ‰¹å¤„ç†çš„regionsæ•°é‡ï¼ˆé»˜è®¤30ï¼Œé¿å…è¶…æ—¶å’Œtokené™åˆ¶ï¼‰
            entity_guidance: å®ä½“è¯†åˆ«çš„ç¿»è¯‘æŒ‡å¯¼ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                {
                    "persons": ["å¼ ä¸‰ -> Zhang San"],
                    "locations": ["åŒ—äº¬ -> Beijing"],
                    "organizations": ["åŒ—äº¬å¤§å­¦ -> Peking University"],
                    "terms": ["æœºå™¨å­¦ä¹  -> Machine Learning"]
                }
        Returns:
            ä¼˜åŒ–åçš„ç¿»è¯‘åˆ—è¡¨
                [
                    {
                        'id': 0,
                        'translation': 'LLMä¼˜åŒ–ç¿»è¯‘',
                        'original': 'ç™¾åº¦ç¿»è¯‘'
                    },
                    ...
                ]
        """
        if not self.client:
            raise Exception("OpenAI APIæœªé…ç½®ï¼Œè¯·åœ¨config/openai_api_key.txtä¸­æ·»åŠ APIå¯†é’¥")

        # å¦‚æœregionsæ•°é‡è¾ƒå°‘ï¼Œç›´æ¥å¤„ç†
        if len(regions) <= batch_size:
            return self._optimize_batch(regions, entity_guidance=entity_guidance)

        # å¤§é‡regionsæ—¶ï¼Œåˆ†æ‰¹å¤„ç†
        print(f"æ£€æµ‹åˆ° {len(regions)} ä¸ªåŒºåŸŸï¼Œå°†åˆ†æ‰¹å¤„ç†ï¼ˆæ¯æ‰¹ {batch_size} ä¸ªï¼‰")
        all_translations = []

        for i in range(0, len(regions), batch_size):
            batch = regions[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(regions) + batch_size - 1) // batch_size

            print(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ˆ{len(batch)} ä¸ªåŒºåŸŸï¼‰...")

            try:
                batch_translations = self._optimize_batch(batch, entity_guidance=entity_guidance)
                all_translations.extend(batch_translations)
                print(f"ç¬¬ {batch_num} æ‰¹å®Œæˆï¼Œå·²ä¼˜åŒ– {len(batch_translations)} ä¸ªåŒºåŸŸ")
            except Exception as e:
                print(f"ç¬¬ {batch_num} æ‰¹å¤„ç†å¤±è´¥: {str(e)}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œè€Œä¸æ˜¯å®Œå…¨å¤±è´¥
                continue

        return all_translations

    def _optimize_batch(self, regions, entity_guidance=None):
        """
        ä¼˜åŒ–å•æ‰¹ç¿»è¯‘ç»“æœ
        Args:
            regions: åŒºåŸŸåˆ—è¡¨
            entity_guidance: å®ä½“ç¿»è¯‘æŒ‡å¯¼ï¼ˆå¯é€‰ï¼‰
        """
        # å‡†å¤‡æ‰¹é‡ç¿»è¯‘æ–‡æœ¬
        source_texts = []
        region_id_list = []

        for region in regions:
            if region.get('src'):
                region_id = region.get('id', len(source_texts))
                source_texts.append(f"[{region_id}] {region['src']}")
                region_id_list.append(region_id)

        if not source_texts:
            return []

        # æ„å»ºGPTæç¤º
        prompt = self._build_optimization_prompt(source_texts, len(source_texts), entity_guidance=entity_guidance)

        try:
            # è°ƒç”¨GPT APIï¼ˆå¢åŠ max_tokensä»¥æ”¯æŒæ›´å¤šç¿»è¯‘ï¼‰
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a professional Chinese-English translator."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000  # å¢åŠ tokené™åˆ¶ä»¥æ”¯æŒæ›´å¤šç¿»è¯‘
            )

            # è§£æç»“æœ
            llm_output = response.choices[0].message.content
            translations = self._parse_llm_output(llm_output, regions)

            # ğŸ”§ éªŒè¯è¾“å‡ºå®Œæ•´æ€§
            input_ids = {r.get('id') for r in regions if r.get('src')}
            output_ids = {t['id'] for t in translations}
            missing_ids = input_ids - output_ids

            if missing_ids:
                print(f"âš ï¸ è­¦å‘Šï¼š{len(missing_ids)} ä¸ªç¿»è¯‘ç¼ºå¤±: {sorted(missing_ids)}")
                # å¯¹ç¼ºå¤±çš„ç¿»è¯‘ä½¿ç”¨ç™¾åº¦ç¿»è¯‘ä½œä¸ºfallback
                for region in regions:
                    if region.get('id') in missing_ids:
                        fallback_text = region.get('dst', region.get('src', ''))
                        translations.append({
                            'id': region['id'],
                            'translation': fallback_text,
                            'original': region.get('dst', '')
                        })
                        print(f"  â†’ ID {region['id']} ä½¿ç”¨ç™¾åº¦ç¿»è¯‘ä½œä¸ºfallback: {fallback_text[:50]}...")

            # ğŸ”§ éªŒè¯ç¿»è¯‘æ˜¯å¦é”™ä½ï¼ˆLLMå¯èƒ½æŠŠç¿»è¯‘å’ŒIDææ··ï¼‰
            # æ„å»ºç™¾åº¦ç¿»è¯‘åˆ°region_idçš„æ˜ å°„
            baidu_to_id = {r.get('dst', '').strip().lower(): r.get('id') for r in regions if r.get('dst')}

            for t in translations:
                llm_trans = t.get('translation', '').strip().lower()
                expected_id = t['id']

                # æ£€æŸ¥LLMç¿»è¯‘æ˜¯å¦ä¸å…¶ä»–åŒºåŸŸçš„ç™¾åº¦ç¿»è¯‘å®Œå…¨åŒ¹é…
                if llm_trans in baidu_to_id:
                    actual_id = baidu_to_id[llm_trans]
                    if actual_id != expected_id:
                        # LLMè¿”å›äº†é”™è¯¯åŒºåŸŸçš„ç¿»è¯‘ï¼ä½¿ç”¨æ­£ç¡®çš„ç™¾åº¦ç¿»è¯‘æ›¿ä»£
                        correct_region = next((r for r in regions if r.get('id') == expected_id), None)
                        if correct_region and correct_region.get('dst'):
                            print(f"âš ï¸ æ£€æµ‹åˆ°ç¿»è¯‘é”™ä½: ID {expected_id} çš„LLMç¿»è¯‘å®é™…ä¸Šæ˜¯ID {actual_id}çš„ç™¾åº¦ç¿»è¯‘")
                            print(f"  â†’ ä½¿ç”¨æ­£ç¡®çš„ç™¾åº¦ç¿»è¯‘æ›¿ä»£: {correct_region['dst'][:50]}...")
                            t['translation'] = correct_region['dst']

            return translations

        except Exception as e:
            raise Exception(f"LLMç¿»è¯‘è°ƒç”¨å¤±è´¥: {str(e)}")

    def _build_optimization_prompt(self, source_texts, count, entity_guidance=None):
        """
        æ„å»ºä¼˜åŒ–æç¤ºè¯
        Args:
            source_texts: æºæ–‡æœ¬åˆ—è¡¨
            count: æ–‡æœ¬æ•°é‡
            entity_guidance: å®ä½“ç¿»è¯‘æŒ‡å¯¼ï¼ˆå¯é€‰ï¼‰
        """
        # åŸºç¡€è§„åˆ™
        base_rules = """TRANSLATION RULES:
- Chinese characters (ä¸­æ–‡) â†’ Translate to English
- English text â†’ Keep unchanged
- Mixed Chinese-English â†’ Translate only Chinese parts
- Names/Proper nouns â†’ Translate appropriately
- Maintain professional and accurate translation"""

        # å¦‚æœæœ‰å®ä½“è¯†åˆ«æŒ‡å¯¼ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
        entity_guidance_text = ""
        if entity_guidance:
            entity_guidance_text = "\n\nSPECIAL TRANSLATION GUIDANCE (from Entity Recognition):\n"

            if entity_guidance.get('persons'):
                entity_guidance_text += "\nPerson Names:\n"
                for item in entity_guidance.get('persons', []):
                    entity_guidance_text += f"  - {item}\n"

            if entity_guidance.get('locations'):
                entity_guidance_text += "\nLocation Names:\n"
                for item in entity_guidance.get('locations', []):
                    entity_guidance_text += f"  - {item}\n"

            if entity_guidance.get('organizations'):
                entity_guidance_text += "\nOrganization Names:\n"
                for item in entity_guidance.get('organizations', []):
                    entity_guidance_text += f"  - {item}\n"

            if entity_guidance.get('terms'):
                entity_guidance_text += "\nSpecial Terms:\n"
                for item in entity_guidance.get('terms', []):
                    entity_guidance_text += f"  - {item}\n"

            entity_guidance_text += "\nIMPORTANT: When you encounter any of the above entities in the text, use the exact translation provided.\n"

        prompt = f"""You are a Chinese-English translator. For each input text:

{base_rules}{entity_guidance_text}

MANDATORY OUTPUT FORMAT:
1. You MUST output exactly {count} lines
2. Each line MUST start with [number] matching the input
3. Never skip any input
4. Format: [ID] Translation

INPUT TEXTS TO TRANSLATE:
{chr(10).join(source_texts)}

OUTPUT INSTRUCTIONS: Provide exactly {count} translated lines, each starting with the corresponding [ID] number."""

        return prompt

    def _parse_llm_output(self, llm_output, original_regions):
        """è§£æLLMè¾“å‡º"""
        lines = llm_output.strip().split('\n')
        translations = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æå–IDå’Œç¿»è¯‘æ–‡æœ¬
            match = re.match(r'\[(\d+)\]\s*(.+)', line)
            if match:
                region_id = int(match.group(1))
                translation = match.group(2).strip()

                # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹åŒºåŸŸ
                original = next(
                    (r['dst'] for r in original_regions if r.get('id') == region_id),
                    ''
                )

                translations.append({
                    'id': region_id,
                    'translation': translation,
                    'original': original
                })

        # ğŸ”§ æŒ‰IDæ’åºç¡®ä¿é¡ºåºæ­£ç¡®
        translations.sort(key=lambda t: t['id'])

        return translations

    def save_llm_translation_log(self, filename, baidu_regions, llm_translations):
        """ä¿å­˜LLMç¿»è¯‘ç»“æœå’Œå¯¹æ¯”æ—¥å¿—ï¼ˆä¸Referenceé¡¹ç›®ä¸€è‡´ï¼‰"""
        try:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

            # 1. ä¿å­˜LLMç¿»è¯‘æ—¥å¿—
            llm_log_filename = f"llm_translation_log_{timestamp}_{filename}.txt"
            llm_log_path = os.path.join(self.output_folder, 'logs', llm_log_filename)

            with open(llm_log_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write(f"LLMç¿»è¯‘æ—¥å¿— (ChatGPTä¼˜åŒ–)\n")
                f.write(f"æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"åŸå§‹æ–‡ä»¶: {filename}\n")
                f.write("=" * 80 + "\n\n")

                f.write("ã€LLMç¿»è¯‘ç»Ÿè®¡ã€‘\n")
                f.write(f"æ€»åŒºåŸŸæ•°: {len(llm_translations)}\n")
                total_src_chars = sum(len(r.get('src', '')) for r in baidu_regions)
                total_llm_chars = sum(len(t.get('translation', '')) for t in llm_translations)
                f.write(f"æºæ–‡æœ¬æ€»å­—ç¬¦: {total_src_chars}\n")
                f.write(f"LLMè¯‘æ–‡æ€»å­—ç¬¦: {total_llm_chars}\n")
                f.write(f"ç¿»è¯‘æ¯”ä¾‹: {total_llm_chars / total_src_chars if total_src_chars > 0 else 1:.2f}\n")
                f.write("\n")

                f.write("ã€LLMè¯¦ç»†ç¿»è¯‘å†…å®¹ã€‘\n")
                for i, translation in enumerate(llm_translations):
                    region_id = translation.get('id', i)
                    # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹åŒºåŸŸ
                    original_region = next((r for r in baidu_regions if r.get('id') == region_id), {})

                    f.write(f"\n--- åŒºåŸŸ {i+1} (ID: {region_id}) ---\n")
                    f.write(f"åŸæ–‡: {original_region.get('src', '')}\n")
                    f.write(f"LLMè¯‘æ–‡: {translation.get('translation', '')}\n")
                    if original_region.get('points'):
                        f.write(f"ä½ç½®: {original_region.get('points')}\n")

            # 2. ä¿å­˜ä¸‰ç§ç¿»è¯‘å¯¹æ¯”æ–‡ä»¶
            comparison_filename = f"translation_comparison_{timestamp}_{filename}.txt"
            comparison_path = os.path.join(self.output_folder, 'logs', comparison_filename)

            with open(comparison_path, 'w', encoding='utf-8') as f:
                f.write("=" * 100 + "\n")
                f.write(f"ç¿»è¯‘å¯¹æ¯”æŠ¥å‘Š\n")
                f.write(f"æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"åŸå§‹æ–‡ä»¶: {filename}\n")
                f.write("=" * 100 + "\n\n")

                f.write("æœ¬æŠ¥å‘Šå¯¹æ¯”ä¸‰ç§ç¿»è¯‘ç»“æœï¼š\n")
                f.write("1. åŸæ–‡ (Chinese)\n")
                f.write("2. ç™¾åº¦APIç¿»è¯‘ (Baidu API Translation)\n")
                f.write("3. GPTä¼˜åŒ–ç¿»è¯‘ (GPT Optimized Translation)\n")
                f.write("\n" + "=" * 100 + "\n\n")

                # åˆ›å»ºç¿»è¯‘æ˜ å°„
                llm_map = {t.get('id'): t.get('translation', '') for t in llm_translations}

                for i, region in enumerate(baidu_regions):
                    region_id = region.get('id', i)
                    src_text = region.get('src', '')
                    baidu_dst = region.get('dst', '')
                    llm_dst = llm_map.get(region_id, '')

                    f.write(f"ã€åŒºåŸŸ {i+1}ã€‘\n")
                    f.write(f"åŸæ–‡: {src_text}\n")
                    f.write(f"ç™¾åº¦ç¿»è¯‘: {baidu_dst}\n")
                    f.write(f"GPTç¿»è¯‘: {llm_dst}\n")
                    f.write("-" * 80 + "\n\n")

            print(f"LLMç¿»è¯‘æ—¥å¿—å·²ä¿å­˜: {llm_log_path}")
            print(f"ç¿»è¯‘å¯¹æ¯”æ–‡ä»¶å·²ä¿å­˜: {comparison_path}")

            return {
                'llm_log': llm_log_filename,
                'comparison': comparison_filename
            }

        except Exception as e:
            print(f"ä¿å­˜LLMæ—¥å¿—å¤±è´¥: {str(e)}")
            return None
